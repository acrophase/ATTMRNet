{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-30 19:25:14.409183: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-30 19:25:15.047400: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-30 19:25:15.048051: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-30 19:25:15.097175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-30 19:25:15.097520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:2d:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-08-30 19:25:15.097533: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-30 19:25:15.099017: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-30 19:25:15.099041: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-30 19:25:15.099525: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-30 19:25:15.099649: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-30 19:25:15.100058: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-08-30 19:25:15.100390: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-08-30 19:25:15.100475: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-30 19:25:15.100528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-30 19:25:15.100879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-30 19:25:15.101198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-08-30 19:25:15.101217: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-30 19:25:15.377936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-30 19:25:15.377970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-08-30 19:25:15.377976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-08-30 19:25:15.378150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-30 19:25:15.378475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-30 19:25:15.378774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-30 19:25:15.379057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7424 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:2d:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "#from numpy.random import seed\n",
    "#seed(42)\n",
    "#import tensorflow\n",
    "#tensorflow.random.set_seed(42)\n",
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']= \"-1\"\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "# for later versions: \n",
    "# tf.compat.v1.set_random_seed(seed_value)\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess =tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_extraction import *\n",
    "from resp_signal_extraction import *\n",
    "from rr_extration import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "from tf_model import *\n",
    "from tf_model_evi import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber\n",
    "import evidential_deep_learning as edl\n",
    "import matplotlib.pyplot as plt\n",
    "from filters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_conf = 'conff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-30 19:25:16.141560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-30 19:25:16.141926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:2d:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-08-30 19:25:16.141968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-30 19:25:16.142249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-30 19:25:16.142507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-08-30 19:25:16.142733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-30 19:25:16.142999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:2d:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-08-30 19:25:16.143028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-30 19:25:16.143303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-30 19:25:16.143556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-08-30 19:25:16.143580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-30 19:25:16.143583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-08-30 19:25:16.143586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-08-30 19:25:16.143634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-30 19:25:16.143913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-30 19:25:16.144190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7424 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:2d:00.0, compute capability: 8.6)\n",
      "2021-08-30 19:25:16.165501: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 95428608 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "with open('output','rb') as f:\n",
    "    output_data = pkl.load(f)\n",
    "\n",
    "with open('input','rb') as f:\n",
    "    input_data = pkl.load(f)\n",
    "\n",
    "with open('raw_signal.pkl','rb') as f:\n",
    "    raw_data = pkl.load(f)\n",
    "\n",
    "input_data = np.transpose(input_data, (0,2,1))\n",
    "raw_data = np.transpose(raw_data, (0,2,1))\n",
    "annotation = pd.read_pickle('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/annotation.pkl')\n",
    "reference_rr = (annotation['Reference_RR'].values).reshape(-1,1)\n",
    "\n",
    "input_data = np.around(input_data , decimals = 4)\n",
    "raw_data = np.around(raw_data , decimals = 4)\n",
    "output_data = np.around(output_data , decimals = 4)\n",
    "reference_rr = np.around(reference_rr , decimals = 4)\n",
    "\n",
    "tensor_input = tf.convert_to_tensor(input_data, dtype = 'float32')\n",
    "tensor_output = tf.convert_to_tensor(output_data, dtype = 'float32')\n",
    "tensor_ref_rr = tf.convert_to_tensor(reference_rr, dtype = 'float32')\n",
    "tensor_raw_data = tf.convert_to_tensor(raw_data, dtype = 'float32')\n",
    "training_ids = annotation['patient_id'] < 13\n",
    "\n",
    "x_train_data = tensor_input[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_data = tensor_input[tf.convert_to_tensor(~(training_ids.values))]\n",
    "x_train_ref_rr = tensor_ref_rr[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_ref_rr = tensor_ref_rr[tf.convert_to_tensor(~(training_ids.values))]\n",
    "x_train_raw_sig = tensor_raw_data[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_raw_sig = tensor_raw_data[tf.convert_to_tensor(~(training_ids.values))]\n",
    "\n",
    "y_train_data = tensor_output[tf.convert_to_tensor(training_ids.values)]\n",
    "y_test_data = tensor_output[tf.convert_to_tensor(~(training_ids.values))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-30 19:25:16.273622: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 75423744 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confc':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , y_train_data))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , y_test_data))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confb':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confd':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , y_train_data, x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , y_test_data, x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "if input_conf == 'confa':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_raw_sig)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confe':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , y_train_data))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_raw_sig)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , y_test_data))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "if input_conf == 'conff':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , y_train_data, x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , y_test_data, x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-30 19:25:16.786515: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-30 19:25:17.138126: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101\n",
      "2021-08-30 19:25:17.601683: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-30 19:25:17.907623: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-30 19:25:17.914027: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confc':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODELS/confc/best_model_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step,(x_batch_test , y_batch_test) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = loss_fn(y_batch_test,output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confd':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Multi_resp(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODELS/confd/best_model_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,y_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr = model(x_batch_test)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "            \n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confb':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Encoder(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODELS/confb/best_model_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confe':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODELS/confe/best_model_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw,y_batch_test) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(y_batch_test , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "        \n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confa':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_encoder(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODELS/confa/best_model_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw, x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_multi(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODELS/conff/best_model_100.h5')        \n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw , y_batch_test , x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr = model(x_batch_test_raw)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extremas_extraction(signal):\n",
    "    avg_breath_duration = np.array([])\n",
    "    extrema_relevent = []\n",
    "    for item in signal:\n",
    "        amplitude = np.array([])\n",
    "        pos_peaks , _ = scipy.signal.find_peaks(item , height = [-3000,3000])\n",
    "        neg_peaks , _ = scipy.signal.find_peaks(-1*item , height = [-3000 , 3000])\n",
    "        extremas = np.concatenate((pos_peaks , neg_peaks))\n",
    "        extremas = np.sort(extremas)\n",
    "        for i in range(len(extremas)):\n",
    "            amplitude = np.append(amplitude , item[int(extremas[i])])\n",
    "        amplitude_diff = np.abs(np.diff(amplitude))\n",
    "        q3 = np.percentile(amplitude_diff , 75)\n",
    "        threshold = 0.3*q3\n",
    "        eliminate_pairs_of_extrema = 1\n",
    "        while(eliminate_pairs_of_extrema):\n",
    "            amps = np.array([])\n",
    "            if len(extremas)<3:\n",
    "                eliminate_pairs_of_extrema = 0\n",
    "                continue\n",
    "            for i in range(len(extremas)):\n",
    "                amps = np.append(amps , item[int(extremas[i])])\n",
    "            amp_diff = np.abs(np.diff(amps)) \n",
    "            min_amp_diff , index = min(amp_diff) , np.argmin(amp_diff)\n",
    "            #print(min_amp_diff)\n",
    "            if min_amp_diff > threshold:\n",
    "                eliminate_pairs_of_extrema = 0\n",
    "                #extrema_relevent = extremas\n",
    "            else:\n",
    "                extremas = np.concatenate((extremas[0:index] , extremas[index+2 :]))\n",
    "                #amplitude_diff = np.delete(amplitude_diff , index)\n",
    "        if item[int(extremas[0])] < item[int(extremas[1])]:\n",
    "            extremas = extremas[1:]\n",
    "        if item[int(extremas[-1])] < item[int(extremas[-2])]:\n",
    "            extremas = extremas[:-1]\n",
    "        no_of_breaths = (len(extremas)-1)/2\n",
    "        breath_duration = extremas[-1] - extremas[0]\n",
    "        avg_breath_duration = np.append(avg_breath_duration , breath_duration/no_of_breaths)\n",
    "        extrema_relevent.append(extremas)\n",
    "    return avg_breath_duration , extrema_relevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sig = y_test_data.numpy()\n",
    "fbpB , fbpA = band_pass(0.1,0.8,8)\n",
    "final_ref_resp_sig = []\n",
    "for item in ref_sig:\n",
    "    final_ref_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "final_ref_resp_sig = np.array(final_ref_resp_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confa':\n",
    "    final_output_rr = final_output.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "#----------------------------------------------------------------------------------------------------------------   \n",
    "if input_conf == 'confb':\n",
    "    final_output_rr = final_output.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Absolute Error for confa is: 2.5189870106871095\n",
    "#Root Mean Square Error for confa is: 3.1476790448298395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "\n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------    \n",
    "if input_conf == 'confe':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error average wise for conff is: 2.4992719930504177\n",
      "Root Mean Square Error average wise for conff is: 3.14139896080554\n",
      "Mean Absolute Error instantaneous wise for conff is: 3.3456864738628216\n",
      "Root Mean Square Error instantaneous wise for conff is: 4.141871369709381\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confd':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_rr = final_output_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_rr = final_output_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITH EVIDENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_evi(model_input_shape)\n",
    "    coeff_val = 0.01\n",
    "    #loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODEL_WITH_EVI/confc/best_model__coeff_0.01.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step,(x_batch_test , y_batch_test) in enumerate(test_dataset):\n",
    "        y_batch_test = tf.expand_dims(y_batch_test , axis = -1)\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = edl.losses.EvidentialRegression(y_batch_test,output, coeff = coeff_val)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confe':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_evi(model_input_shape)\n",
    "    coeff_val = 0.01\n",
    "    #loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODEL_WITH_EVI/confe/best_model___coeff_0.01.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw,y_batch_test) in enumerate(test_dataset):\n",
    "        y_batch_test = tf.expand_dims(y_batch_test , axis = -1)\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = edl.losses.EvidentialRegression(y_batch_test,output, coeff = coeff_val)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confb':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Encoder_evi(model_input_shape)\n",
    "    coeff_val = 0.005\n",
    "    #loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODEL_WITH_EVI/confb/best_model___coeff_0.005.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        x_batch_test_ref_rr = tf.expand_dims(x_batch_test_ref_rr , axis = -1)\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = edl.losses.EvidentialRegression(x_batch_test_ref_rr , output , coeff = coeff_val)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confa':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_encoder_evi(model_input_shape)\n",
    "    #loss_fn = Huber()\n",
    "    coeff_val = 0.01\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODEL_WITH_EVI/confa/best_model___coeff_0.01.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw, x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        x_batch_test_ref_rr = tf.expand_dims(x_batch_test_ref_rr , axis = -1)\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = edl.losses.EvidentialRegression(x_batch_test_ref_rr , output, coeff = coeff_val)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)  \n",
    "        \n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_multi_evi(model_input_shape)\n",
    "    #loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    coeff_val = 0.05\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODEL_WITH_EVI/conff/best_model___coeff_0.05.h5')        \n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw , y_batch_test , x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        y_batch_test = tf.expand_dims(y_batch_test , axis = -1)\n",
    "        x_batch_test_ref_rr = tf.expand_dims(x_batch_test_ref_rr , axis = -1)\n",
    "        test_output,test_out_rr = model(x_batch_test_raw)\n",
    "        test_loss_resp = edl.losses.EvidentialRegression(y_batch_test  , test_output , coeff = coeff_val)\n",
    "        test_loss_rr = edl.losses.EvidentialRegression(x_batch_test_ref_rr , test_out_rr , coeff = coeff_val)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss) \n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confd':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Multi_resp_evi(model_input_shape)\n",
    "    #loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    coeff_val = 0.005\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODEL_WITH_EVI/confd/best_model___coeff_0.005.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,y_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        x_batch_test_ref_rr = tf.expand_dims(x_batch_test_ref_rr , axis = -1)\n",
    "        y_batch_test = tf.expand_dims(y_batch_test , axis = -1)\n",
    "        test_output,test_out_rr = model(x_batch_test)\n",
    "        test_loss_resp = edl.losses.EvidentialRegression(y_batch_test  , test_output, coeff = coeff_val)\n",
    "        test_loss_rr = edl.losses.EvidentialRegression(x_batch_test_ref_rr , test_out_rr,coeff = coeff_val)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma, lamda, alpha, beta = tf.split(final_output, 4, axis=-1)\n",
    "output = gamma.numpy()\n",
    "output = output.reshape(output.shape[0] , output.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error average wise for conff is: 2.8352133878826997\n",
      "Root Mean Square Error average wise for conff is: 3.630215124981139\n",
      "Mean Absolute Error instantaneous wise for conff is: 2.8318278164599793\n",
      "Root Mean Square Error instantaneous wise for conff is: 3.5526148372394277\n",
      "[[ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 25.468857]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 24.533361]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.761845]\n",
      " [ 24.076927]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.941452]\n",
      " [ 24.349894]\n",
      " [ 23.89644 ]\n",
      " [ 23.941452]\n",
      " [ 24.349894]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 24.304218]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 27.535383]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 24.95056 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 39.54878 ]\n",
      " [ 23.89644 ]\n",
      " [ 24.579414]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 24.213081]\n",
      " [ 24.16763 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 24.764378]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 37.092304]\n",
      " [ 24.81082 ]\n",
      " [ 23.89644 ]\n",
      " [ 32.643715]\n",
      " [ 27.94524 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 25.090998]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 25.279312]\n",
      " [ 25.279312]\n",
      " [ 23.89644 ]\n",
      " [ 24.625544]\n",
      " [ 23.89644 ]\n",
      " [ 27.586327]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 25.184998]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 24.441475]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 25.468857]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 25.996523]\n",
      " [ 23.89644 ]\n",
      " [ 24.304218]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 26.093485]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 26.98045 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.941452]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 26.930487]\n",
      " [ 23.85151 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 27.231464]\n",
      " [ 26.435337]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 26.044968]\n",
      " [ 34.152634]\n",
      " [ 38.78315 ]\n",
      " [ 29.422304]\n",
      " [ 32.34914 ]\n",
      " [ 31.02425 ]\n",
      " [ 43.58512 ]\n",
      " [ 33.11998 ]\n",
      " [ 31.594263]\n",
      " [ 43.355713]\n",
      " [ 38.2347  ]\n",
      " [ 29.638819]\n",
      " [ 35.916115]\n",
      " [ 40.90332 ]\n",
      " [ 36.762173]\n",
      " [ 52.706364]\n",
      " [ 33.060116]\n",
      " [ 46.587585]\n",
      " [ 60.682964]\n",
      " [ 24.764378]\n",
      " [ 26.484491]\n",
      " [ 31.882729]\n",
      " [ 32.056934]\n",
      " [ 30.296854]\n",
      " [ 28.360447]\n",
      " [ 30.686632]\n",
      " [ 35.277184]\n",
      " [ 26.880611]\n",
      " [ 28.517538]\n",
      " [ 28.048538]\n",
      " [ 24.903906]\n",
      " [ 31.479525]\n",
      " [ 29.747606]\n",
      " [ 28.993427]\n",
      " [ 22.622612]\n",
      " [ 36.1098  ]\n",
      " [ 42.225006]\n",
      " [ 29.260818]\n",
      " [ 39.830544]\n",
      " [ 40.256577]\n",
      " [ 36.17457 ]\n",
      " [ 30.241526]\n",
      " [ 22.967993]\n",
      " [ 31.82485 ]\n",
      " [ 22.881224]\n",
      " [ 65.85335 ]\n",
      " [ 25.899881]\n",
      " [ 44.202225]\n",
      " [ 28.781067]\n",
      " [ 25.279312]\n",
      " [ 29.046734]\n",
      " [ 41.339687]\n",
      " [ 32.34914 ]\n",
      " [ 48.15814 ]\n",
      " [ 37.35831 ]\n",
      " [ 36.49997 ]\n",
      " [ 28.57007 ]\n",
      " [ 44.827248]\n",
      " [ 41.559425]\n",
      " [ 36.369503]\n",
      " [ 50.03677 ]\n",
      " [ 48.242123]\n",
      " [ 25.996523]\n",
      " [ 26.63243 ]\n",
      " [ 36.696465]\n",
      " [ 29.207165]\n",
      " [ 33.179955]\n",
      " [ 26.830818]\n",
      " [ 33.179955]\n",
      " [ 44.27993 ]\n",
      " [ 33.060116]\n",
      " [ 43.432068]\n",
      " [ 50.824387]\n",
      " [ 35.150627]\n",
      " [ 37.291653]\n",
      " [ 32.40786 ]\n",
      " [ 45.699726]\n",
      " [ 27.48453 ]\n",
      " [ 25.996523]\n",
      " [ 31.194296]\n",
      " [ 29.856747]\n",
      " [ 30.911352]\n",
      " [ 32.584606]\n",
      " [ 31.65177 ]\n",
      " [ 39.268806]\n",
      " [ 79.28008 ]\n",
      " [ 33.420776]\n",
      " [ 37.026066]\n",
      " [ 53.903107]\n",
      " [ 72.39952 ]\n",
      " [ 56.95578 ]\n",
      " [ 50.736324]\n",
      " [ 49.43191 ]\n",
      " [ 42.002083]\n",
      " [ 34.461746]\n",
      " [ 74.12789 ]\n",
      " [ 50.824387]\n",
      " [ 53.717377]\n",
      " [ 45.14275 ]\n",
      " [ 35.595383]\n",
      " [ 42.523895]\n",
      " [ 35.78751 ]\n",
      " [ 27.586327]\n",
      " [ 36.959946]\n",
      " [ 29.802134]\n",
      " [ 30.74268 ]\n",
      " [ 33.360428]\n",
      " [ 44.827248]\n",
      " [ 32.34914 ]\n",
      " [ 28.465086]\n",
      " [ 40.256577]\n",
      " [ 30.74268 ]\n",
      " [ 29.69317 ]\n",
      " [ 30.74268 ]\n",
      " [ 30.076086]\n",
      " [ 30.51904 ]\n",
      " [ 46.587585]\n",
      " [ 37.82795 ]\n",
      " [ 48.664017]\n",
      " [ 50.560596]\n",
      " [ 32.643715]\n",
      " [ 29.260818]\n",
      " [ 50.123734]\n",
      " [ 45.380695]\n",
      " [ 39.68944 ]\n",
      " [ 58.24063 ]\n",
      " [ 30.686632]\n",
      " [ 31.998777]\n",
      " [ 47.078434]\n",
      " [ 27.842276]\n",
      " [ 29.4763  ]\n",
      " [ 33.060116]\n",
      " [ 27.68846 ]\n",
      " [ 27.080614]\n",
      " [ 34.02967 ]\n",
      " [ 48.664017]\n",
      " [ 24.213081]\n",
      " [ 28.204111]\n",
      " [ 22.967993]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 24.625544]\n",
      " [ 22.924574]\n",
      " [ 25.803549]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 29.15361 ]\n",
      " [ 26.239515]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 28.465086]\n",
      " [ 25.232117]\n",
      " [ 23.273935]\n",
      " [ 23.89644 ]\n",
      " [ 28.204111]\n",
      " [ 23.89644 ]\n",
      " [ 25.279312]\n",
      " [ 23.230013]\n",
      " [ 23.89644 ]\n",
      " [ 25.803549]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 25.184998]\n",
      " [ 26.7811  ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.672482]\n",
      " [ 23.89644 ]\n",
      " [ 34.214256]\n",
      " [ 28.360447]\n",
      " [ 46.750683]\n",
      " [ 56.662983]\n",
      " [ 34.39973 ]\n",
      " [ 52.797554]\n",
      " [ 32.231968]\n",
      " [ 80.08111 ]\n",
      " [125.9238  ]\n",
      " [ 69.87707 ]\n",
      " [ 71.91264 ]\n",
      " [ 87.05653 ]\n",
      " [ 96.178154]\n",
      " [ 80.08111 ]\n",
      " [ 39.830544]\n",
      " [ 29.530384]\n",
      " [ 60.475895]\n",
      " [ 46.343903]\n",
      " [ 42.002083]\n",
      " [ 66.189644]\n",
      " [ 29.856747]\n",
      " [ 65.96528 ]\n",
      " [ 72.64413 ]\n",
      " [ 32.231968]\n",
      " [ 34.836006]\n",
      " [ 23.89644 ]\n",
      " [ 24.671747]\n",
      " [ 44.90594 ]\n",
      " [ 32.056934]\n",
      " [ 34.02967 ]\n",
      " [ 31.251156]\n",
      " [ 25.707539]\n",
      " [ 23.583405]\n",
      " [ 23.538979]\n",
      " [ 23.361994]\n",
      " [ 30.076086]\n",
      " [ 46.182095]\n",
      " [ 24.395647]\n",
      " [ 30.352268]\n",
      " [ 26.190758]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 22.324097]\n",
      " [ 26.681906]\n",
      " [ 28.308249]\n",
      " [ 24.625544]\n",
      " [ 26.142082]\n",
      " [ 24.395647]\n",
      " [ 32.702908]\n",
      " [ 33.060116]\n",
      " [ 30.46336 ]\n",
      " [ 29.207165]\n",
      " [ 25.232117]\n",
      " [ 23.273935]\n",
      " [ 23.538979]\n",
      " [ 30.241526]\n",
      " [ 31.882729]\n",
      " [ 23.361994]\n",
      " [ 27.586327]\n",
      " [ 24.95056 ]\n",
      " [ 24.258615]\n",
      " [ 23.273935]\n",
      " [ 46.343903]\n",
      " [ 35.595383]\n",
      " [ 41.780224]\n",
      " [ 64.195496]\n",
      " [ 44.202225]\n",
      " [ 42.299545]\n",
      " [103.0898  ]\n",
      " [ 50.9126  ]\n",
      " [ 26.583038]\n",
      " [ 26.337263]\n",
      " [ 40.399498]\n",
      " [ 47.078434]\n",
      " [ 36.630863]\n",
      " [ 26.63243 ]\n",
      " [ 38.576653]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 23.89644 ]\n",
      " [ 30.076086]\n",
      " [ 38.166634]\n",
      " [ 25.659647]\n",
      " [ 29.638819]\n",
      " [ 28.781067]\n",
      " [ 24.95056 ]\n",
      " [ 26.583038]\n",
      " [ 28.887081]\n",
      " [ 27.231464]\n",
      " [ 27.231464]\n",
      " [ 28.622698]\n",
      " [ 25.996523]\n",
      " [ 28.256136]\n",
      " [ 29.69317 ]\n",
      " [ 27.332443]\n",
      " [ 28.83403 ]\n",
      " [ 28.412731]\n",
      " [ 31.137522]\n",
      " [ 28.6754  ]\n",
      " [ 25.803549]\n",
      " [ 26.435337]\n",
      " [ 32.82159 ]\n",
      " [ 58.34056 ]\n",
      " [ 53.163727]\n",
      " [ 48.326237]\n",
      " [ 63.97738 ]\n",
      " [ 61.203518]\n",
      " [ 66.3021  ]\n",
      " [ 39.059998]\n",
      " [ 59.756237]\n",
      " [ 66.07738 ]\n",
      " [ 59.65409 ]\n",
      " [ 61.099075]\n",
      " [ 58.741848]\n",
      " [ 59.85857 ]\n",
      " [ 57.05366 ]\n",
      " [ 73.878654]\n",
      " [ 90.904724]\n",
      " [ 33.481236]\n",
      " [ 50.03677 ]\n",
      " [ 28.412731]\n",
      " [ 49.60405 ]\n",
      " [ 51.000946]\n",
      " [ 43.661835]\n",
      " [ 40.32798 ]\n",
      " [ 42.900185]\n",
      " [ 73.25898 ]\n",
      " [ 38.439545]\n",
      " [ 31.594263]\n",
      " [ 31.882729]\n",
      " [ 34.836006]\n",
      " [ 46.99631 ]\n",
      " [ 46.66907 ]\n",
      " [ 25.803549]\n",
      " [ 55.410156]\n",
      " [ 55.21968 ]\n",
      " [ 60.682964]\n",
      " [ 62.15088 ]\n",
      " [ 32.82159 ]\n",
      " [ 46.832424]\n",
      " [ 23.494623]\n",
      " [ 32.525597]\n",
      " [ 34.586105]\n",
      " [ 40.32798 ]\n",
      " [ 36.827995]\n",
      " [ 27.43375 ]\n",
      " [ 27.68846 ]\n",
      " [ 34.152634]\n",
      " [ 52.797554]\n",
      " [ 38.921352]\n",
      " [ 48.833714]\n",
      " [ 62.36322 ]\n",
      " [ 37.158653]\n",
      " [ 44.202225]\n",
      " [ 57.05366 ]\n",
      " [ 40.542873]\n",
      " [ 66.75368 ]\n",
      " [ 64.74378 ]\n",
      " [ 59.85857 ]\n",
      " [ 29.4763  ]\n",
      " [ 60.786743]\n",
      " [ 44.435688]\n",
      " [ 54.2763  ]\n",
      " [ 56.27475 ]\n",
      " [ 57.84248 ]\n",
      " [ 64.96431 ]\n",
      " [ 73.75432 ]\n",
      " [ 58.641296]\n",
      " [ 51.089436]\n",
      " [ 40.11411 ]\n",
      " [ 33.724003]\n",
      " [ 30.967764]\n",
      " [ 28.728188]\n",
      " [ 30.51904 ]\n",
      " [ 29.260818]\n",
      " [ 56.760414]\n",
      " [ 80.88968 ]\n",
      " [ 35.53153 ]\n",
      " [ 45.619778]\n",
      " [ 42.225006]\n",
      " [ 23.186167]\n",
      " [ 48.15814 ]\n",
      " [ 41.706516]\n",
      " [ 37.49196 ]\n",
      " [ 65.63006 ]\n",
      " [ 79.28008 ]\n",
      " [ 56.178085]\n",
      " [ 55.9852  ]\n",
      " [ 28.6754  ]\n",
      " [ 31.594263]\n",
      " [ 51.26682 ]\n",
      " [ 37.55894 ]\n",
      " [ 30.911352]\n",
      " [ 33.300167]\n",
      " [ 24.533361]\n",
      " [ 27.586327]\n",
      " [ 36.893913]\n",
      " [ 36.49997 ]\n",
      " [ 42.225006]\n",
      " [ 29.207165]\n",
      " [ 39.68944 ]\n",
      " [ 41.412815]\n",
      " [ 43.892704]\n",
      " [ 70.35115 ]\n",
      " [ 43.58512 ]\n",
      " [ 55.314857]\n",
      " [ 64.195496]\n",
      " [ 50.560596]\n",
      " [ 34.773376]\n",
      " [ 51.44478 ]\n",
      " [ 33.420776]\n",
      " [ 26.681906]\n",
      " [ 57.151726]\n",
      " [ 30.076086]\n",
      " [ 31.194296]\n",
      " [ 44.827248]\n",
      " [ 27.030487]\n",
      " [ 41.12098 ]\n",
      " [ 43.12741 ]\n",
      " [ 26.830818]\n",
      " [ 30.352268]\n",
      " [ 31.594263]\n",
      " [ 30.076086]\n",
      " [ 28.6754  ]\n",
      " [ 28.360447]\n",
      " [ 28.517538]\n",
      " [ 28.940203]\n",
      " [ 24.304218]\n",
      " [ 30.51904 ]\n",
      " [ 28.256136]\n",
      " [ 31.080837]\n",
      " [ 29.802134]\n",
      " [ 26.239515]\n",
      " [ 29.747606]\n",
      " [ 28.10031 ]\n",
      " [ 30.076086]\n",
      " [ 28.308249]\n",
      " [ 28.622698]\n",
      " [ 31.998777]\n",
      " [ 31.594263]\n",
      " [ 31.080837]\n",
      " [ 26.731459]\n",
      " [ 31.65177 ]\n",
      " [ 29.638819]\n",
      " [ 33.00033 ]\n",
      " [ 32.584606]\n",
      " [ 29.314558]\n",
      " [ 25.516438]\n",
      " [ 27.893719]\n",
      " [ 30.021112]\n",
      " [ 28.887081]\n",
      " [ 30.855036]\n",
      " [ 21.903559]\n",
      " [ 48.833714]\n",
      " [ 52.980343]\n",
      " [ 55.60123 ]\n",
      " [ 51.178055]\n",
      " [ 52.43366 ]\n",
      " [ 48.074295]\n",
      " [ 86.76695 ]\n",
      " [ 50.29808 ]\n",
      " [ 89.109215]\n",
      " [ 93.351555]\n",
      " [ 44.98476 ]\n",
      " [ 77.96163 ]\n",
      " [ 69.75902 ]\n",
      " [ 71.06789 ]\n",
      " [ 40.32798 ]\n",
      " [ 50.824387]\n",
      " [ 44.827248]\n",
      " [ 42.44899 ]\n",
      " [119.5105  ]\n",
      " [ 31.594263]\n",
      " [ 58.741848]\n",
      " [ 45.539963]\n",
      " [ 59.14568 ]\n",
      " [ 57.94179 ]\n",
      " [ 47.491074]\n",
      " [ 75.7671  ]\n",
      " [ 47.32564 ]\n",
      " [ 34.773376]\n",
      " [ 35.85176 ]\n",
      " [164.79857 ]\n",
      " [ 42.900185]\n",
      " [ 33.66317 ]\n",
      " [ 30.131145]\n",
      " [ 45.460262]\n",
      " [ 57.34829 ]\n",
      " [ 30.407766]\n",
      " [ 25.948162]\n",
      " [ 43.892704]\n",
      " [ 38.439545]\n",
      " [ 25.090998]\n",
      " [ 24.671747]\n",
      " [ 27.383055]\n",
      " [ 35.595383]\n",
      " [ 28.360447]\n",
      " [ 24.213081]\n",
      " [ 27.28191 ]\n",
      " [ 27.996847]\n",
      " [ 27.790924]\n",
      " [ 23.538979]\n",
      " [ 28.256136]\n",
      " [ 39.129486]\n",
      " [ 41.12098 ]\n",
      " [ 32.056934]\n",
      " [ 37.026066]\n",
      " [ 33.66317 ]\n",
      " [ 25.755508]\n",
      " [ 32.76221 ]\n",
      " [ 30.076086]\n",
      " [ 38.030838]\n",
      " [ 28.57007 ]\n",
      " [ 25.755508]\n",
      " [ 28.993427]\n",
      " [ 25.516438]\n",
      " [ 26.880611]\n",
      " [ 29.530384]\n",
      " [ 30.74268 ]\n",
      " [ 30.352268]\n",
      " [ 30.46336 ]\n",
      " [ 29.584557]\n",
      " [ 31.594263]\n",
      " [ 30.967764]\n",
      " [ 25.137962]\n",
      " [ 29.15361 ]\n",
      " [ 28.048538]\n",
      " [ 27.43375 ]]\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confc':\n",
    "    final_output_resp_sig = []\n",
    "    gamma, lamda, alpha, beta = tf.split(final_output, 4, axis=-1)\n",
    "    output = gamma.numpy()\n",
    "    output = output.reshape(output.shape[0] , output.shape[1])\n",
    "    for item in output:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    final_lamda = lamda.numpy()\n",
    "    final_alpha = alpha.numpy()\n",
    "    final_beta = beta.numpy()\n",
    "    \n",
    "    final_lamda = final_lamda.reshape(final_lamda.shape[0],final_lamda.shape[1])\n",
    "    final_alpha = final_alpha.reshape(final_alpha.shape[0],final_alpha.shape[1])\n",
    "    final_beta = final_beta.reshape(final_beta.shape[0],final_beta.shape[1])\n",
    "    #x_samps = np.arange(0,len(y_train_data[0]))\n",
    "    aleatoric = final_beta/(final_alpha - 1)\n",
    "    epistemic = final_beta/(final_lamda*(final_alpha - 1))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confe':\n",
    "    final_output_resp_sig = []\n",
    "    gamma, lamda, alpha, beta = tf.split(final_output, 4, axis=-1)\n",
    "    output = gamma.numpy()\n",
    "    output = output.reshape(output.shape[0] , output.shape[1])\n",
    "    for item in output:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    final_lamda = lamda.numpy()\n",
    "    final_alpha = alpha.numpy()\n",
    "    final_beta = beta.numpy()\n",
    "    \n",
    "    final_lamda = final_lamda.reshape(final_lamda.shape[0],final_lamda.shape[1])\n",
    "    final_alpha = final_alpha.reshape(final_alpha.shape[0],final_alpha.shape[1])\n",
    "    final_beta = final_beta.reshape(final_beta.shape[0],final_beta.shape[1])\n",
    "    x_samps = np.arange(0,len(y_train_data[0]))\n",
    "    aleatoric = final_beta/(final_alpha - 1)\n",
    "    epistemic = final_beta/(final_lamda*(final_alpha - 1))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confb':\n",
    "    gamma, lamda, alpha, beta = tf.split(final_output, 4, axis=-1)\n",
    "    final_output_rr = gamma.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "    \n",
    "    final_lamda = lamda.numpy()\n",
    "    final_alpha = alpha.numpy()\n",
    "    final_beta = beta.numpy()\n",
    "    \n",
    "    final_lamda = final_lamda.reshape(final_lamda.shape[0],final_lamda.shape[1])\n",
    "    final_alpha = final_alpha.reshape(final_alpha.shape[0],final_alpha.shape[1])\n",
    "    final_beta = final_beta.reshape(final_beta.shape[0],final_beta.shape[1])\n",
    "    #x_samps = np.arange(0,len(y_train_data[0]))\n",
    "    aleatoric = final_beta/(final_alpha - 1)\n",
    "    epistemic = final_beta/(final_lamda*(final_alpha - 1))\n",
    "    var = np.sqrt(epistemic)\n",
    "    print(epistemic)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confa':\n",
    "    gamma, lamda, alpha, beta = tf.split(final_output, 4, axis=-1)\n",
    "    final_output_rr = gamma.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "    \n",
    "    final_lamda = lamda.numpy()\n",
    "    final_alpha = alpha.numpy()\n",
    "    final_beta = beta.numpy()\n",
    "    \n",
    "    final_lamda = final_lamda.reshape(final_lamda.shape[0],final_lamda.shape[1])\n",
    "    final_alpha = final_alpha.reshape(final_alpha.shape[0],final_alpha.shape[1])\n",
    "    final_beta = final_beta.reshape(final_beta.shape[0],final_beta.shape[1])\n",
    "    aleatoric = final_beta/(final_alpha - 1)\n",
    "    epistemic = final_beta/(final_lamda*(final_alpha - 1))\n",
    "    print(epistemic)\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    gamma_resp, lamda_resp, alpha_resp, beta_resp = tf.split(final_output, 4, axis=-1)\n",
    "    gamma_rr, lamda_rr, alpha_rr, beta_rr = tf.split(final_output_rr, 4, axis=-1)\n",
    "    final_output_resp = gamma_resp.numpy()\n",
    "    final_rr = gamma_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0] , final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "    \n",
    "    final_lamda_resp = lamda_resp.numpy()\n",
    "    final_alpha_resp = alpha_resp.numpy()\n",
    "    final_beta_resp = beta_resp.numpy()\n",
    "    \n",
    "    final_lamda_rr = lamda_rr.numpy()\n",
    "    final_alpha_rr = alpha_rr.numpy()\n",
    "    final_beta_rr = beta_rr.numpy()\n",
    "    \n",
    "    aleatoric_resp = final_beta_resp/(final_alpha_resp - 1)\n",
    "    epistemic_resp = final_beta_resp/(final_lamda_resp*(final_alpha_resp - 1))\n",
    "    \n",
    "    aleatoric_rr = final_beta_rr/(final_alpha_rr - 1)\n",
    "    epistemic_rr = final_beta_rr/(final_lamda_rr*(final_alpha_rr - 1))\n",
    "    \n",
    "    epistemic_rr = epistemic_rr.reshape(epistemic_rr.shape[0],epistemic_rr.shape[1])\n",
    "    aleatoric_rr = aleatoric_rr.reshape(aleatoric_rr.shape[0],aleatoric_rr.shape[1])\n",
    "    print(epistemic_rr)\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confd':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    gamma_resp, lamda_resp, alpha_resp, beta_resp = tf.split(final_output, 4, axis=-1)\n",
    "    gamma_rr, lamda_rr, alpha_rr, beta_rr = tf.split(final_output_rr, 4, axis=-1)\n",
    "    final_output_resp = gamma_resp.numpy()\n",
    "    final_rr = gamma_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0] , final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "    \n",
    "    final_lamda_resp = lamda_resp.numpy()\n",
    "    final_alpha_resp = alpha_resp.numpy()\n",
    "    final_beta_resp = beta_resp.numpy()\n",
    "    \n",
    "    final_lamda_rr = lamda_rr.numpy()\n",
    "    final_alpha_rr = alpha_rr.numpy()\n",
    "    final_beta_rr = beta_rr.numpy()\n",
    "    \n",
    "    aleatoric_resp = final_beta_resp/(final_alpha_resp - 1)\n",
    "    epistemic_resp = final_beta_resp/(final_lamda_resp*(final_alpha_resp - 1))\n",
    "    \n",
    "    aleatoric_rr = final_beta_rr/(final_alpha_rr - 1)\n",
    "    epistemic_rr = final_beta_rr/(final_lamda_rr*(final_alpha_rr - 1))\n",
    "    epistemic_rr = epistemic_rr.reshape(epistemic_rr.shape[0],epistemic_rr.shape[1])\n",
    "    aleatoric_rr = aleatoric_rr.reshape(aleatoric_rr.shape[0],aleatoric_rr.shape[1])\n",
    "    print(epistemic_rr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Absolute Error for confa is: 2.5784237444011153\n",
    "#Root Mean Square Error for confa is: 3.26042372615126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'conff':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_multi_evi(model_input_shape)\n",
    "    #loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    coeff_val = 0.05\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/TEST_SAVE_MODEL/conff/best_model__coeff_0.05_100.h5')        \n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw , y_batch_test , x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        y_batch_test = tf.expand_dims(y_batch_test , axis = -1)\n",
    "        x_batch_test_ref_rr = tf.expand_dims(x_batch_test_ref_rr , axis = -1)\n",
    "        test_output,test_out_rr = model(x_batch_test_raw)\n",
    "        test_loss_resp = edl.losses.EvidentialRegression(y_batch_test  , test_output , coeff = coeff_val)\n",
    "        test_loss_rr = edl.losses.EvidentialRegression(x_batch_test_ref_rr , test_out_rr , coeff = coeff_val)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error average wise for conff is: 2.6432889742464303\n",
      "Root Mean Square Error average wise for conff is: 3.353913947958952\n",
      "Mean Absolute Error instantaneous wise for conff is: 3.336927640851908\n",
      "Root Mean Square Error instantaneous wise for conff is: 4.185678108924724\n",
      "[[36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.07176 ]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [35.47046 ]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.375847]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.29961 ]\n",
      " [36.452232]\n",
      " [36.29961 ]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.29961 ]\n",
      " [36.29961 ]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.29961 ]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.375847]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [35.845196]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.29961 ]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.29961 ]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [17.16732 ]\n",
      " [19.841782]\n",
      " [38.169987]\n",
      " [42.526665]\n",
      " [53.06423 ]\n",
      " [50.637253]\n",
      " [54.042812]\n",
      " [49.210506]\n",
      " [45.70976 ]\n",
      " [49.110027]\n",
      " [47.52779 ]\n",
      " [43.86515 ]\n",
      " [46.276863]\n",
      " [51.784916]\n",
      " [50.328358]\n",
      " [31.508556]\n",
      " [32.66684 ]\n",
      " [52.420963]\n",
      " [50.328358]\n",
      " [36.605453]\n",
      " [53.17215 ]\n",
      " [27.234884]\n",
      " [32.18533 ]\n",
      " [36.452232]\n",
      " [19.01232 ]\n",
      " [28.927353]\n",
      " [25.464533]\n",
      " [34.878246]\n",
      " [34.878246]\n",
      " [27.471123]\n",
      " [33.934944]\n",
      " [36.452232]\n",
      " [36.07176 ]\n",
      " [23.849373]\n",
      " [35.47046 ]\n",
      " [28.312418]\n",
      " [28.373377]\n",
      " [35.694874]\n",
      " [35.845196]\n",
      " [36.452232]\n",
      " [19.664581]\n",
      " [36.223515]\n",
      " [27.888935]\n",
      " [25.188782]\n",
      " [31.241442]\n",
      " [26.883923]\n",
      " [22.723225]\n",
      " [26.709967]\n",
      " [29.8722  ]\n",
      " [29.114155]\n",
      " [32.390903]\n",
      " [19.753008]\n",
      " [33.578312]\n",
      " [26.652199]\n",
      " [34.95177 ]\n",
      " [23.79714 ]\n",
      " [23.485819]\n",
      " [36.223515]\n",
      " [36.452232]\n",
      " [31.710224]\n",
      " [34.95177 ]\n",
      " [35.619926]\n",
      " [35.920578]\n",
      " [30.582546]\n",
      " [18.884163]\n",
      " [17.723848]\n",
      " [26.365034]\n",
      " [27.70918 ]\n",
      " [23.849373]\n",
      " [26.479568]\n",
      " [28.865328]\n",
      " [23.641024]\n",
      " [31.042454]\n",
      " [27.411892]\n",
      " [31.241442]\n",
      " [29.051767]\n",
      " [34.585503]\n",
      " [28.989504]\n",
      " [25.353922]\n",
      " [30.452276]\n",
      " [31.374746]\n",
      " [35.321556]\n",
      " [31.508556]\n",
      " [35.619926]\n",
      " [27.000456]\n",
      " [35.619926]\n",
      " [24.217892]\n",
      " [16.626019]\n",
      " [33.507397]\n",
      " [29.114155]\n",
      " [36.29961 ]\n",
      " [36.452232]\n",
      " [32.117073]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.29961 ]\n",
      " [36.375847]\n",
      " [36.452232]\n",
      " [19.22761 ]\n",
      " [24.006699]\n",
      " [18.172058]\n",
      " [17.804619]\n",
      " [17.08907 ]\n",
      " [19.270918]\n",
      " [25.911312]\n",
      " [22.031263]\n",
      " [19.576498]\n",
      " [33.507397]\n",
      " [19.48876 ]\n",
      " [25.911312]\n",
      " [24.484201]\n",
      " [21.933945]\n",
      " [26.30794 ]\n",
      " [31.777718]\n",
      " [27.234884]\n",
      " [32.390903]\n",
      " [19.09818 ]\n",
      " [30.844595]\n",
      " [34.658485]\n",
      " [33.934944]\n",
      " [33.084705]\n",
      " [29.554224]\n",
      " [27.176111]\n",
      " [19.270918]\n",
      " [29.17666 ]\n",
      " [28.130226]\n",
      " [16.664186]\n",
      " [19.886297]\n",
      " [22.128963]\n",
      " [39.056137]\n",
      " [20.110209]\n",
      " [26.422247]\n",
      " [28.741638]\n",
      " [24.86139 ]\n",
      " [33.72056 ]\n",
      " [24.591448]\n",
      " [35.996086]\n",
      " [35.247322]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.147568]\n",
      " [36.452232]\n",
      " [36.29961 ]\n",
      " [36.223515]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [29.936153]\n",
      " [26.942139]\n",
      " [17.206566]\n",
      " [34.07854 ]\n",
      " [26.422247]\n",
      " [17.723848]\n",
      " [34.731594]\n",
      " [21.357925]\n",
      " [41.74162 ]\n",
      " [18.46239 ]\n",
      " [38.651054]\n",
      " [28.312418]\n",
      " [18.969519]\n",
      " [22.32551 ]\n",
      " [25.298761]\n",
      " [19.48876 ]\n",
      " [29.744642]\n",
      " [23.178114]\n",
      " [17.845121]\n",
      " [31.441584]\n",
      " [19.141237]\n",
      " [16.626019]\n",
      " [36.759247]\n",
      " [25.298761]\n",
      " [19.753008]\n",
      " [36.147568]\n",
      " [34.878246]\n",
      " [19.576498]\n",
      " [26.479568]\n",
      " [28.618404]\n",
      " [17.443657]\n",
      " [37.852318]\n",
      " [24.484201]\n",
      " [26.767838]\n",
      " [35.694874]\n",
      " [20.20039 ]\n",
      " [22.177958]\n",
      " [27.649498]\n",
      " [46.08712 ]\n",
      " [38.89365 ]\n",
      " [38.010845]\n",
      " [27.70918 ]\n",
      " [33.86334 ]\n",
      " [38.40984 ]\n",
      " [26.422247]\n",
      " [26.365034]\n",
      " [20.245611]\n",
      " [23.69296 ]\n",
      " [24.699114]\n",
      " [22.227047]\n",
      " [24.537777]\n",
      " [24.591448]\n",
      " [26.883923]\n",
      " [35.996086]\n",
      " [35.920578]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [22.32551 ]\n",
      " [27.293772]\n",
      " [18.08984 ]\n",
      " [27.828909]\n",
      " [29.8722  ]\n",
      " [23.07634 ]\n",
      " [22.080065]\n",
      " [25.575583]\n",
      " [17.128155]\n",
      " [18.546082]\n",
      " [19.48876 ]\n",
      " [21.31053 ]\n",
      " [20.110209]\n",
      " [25.855082]\n",
      " [21.692293]\n",
      " [19.620493]\n",
      " [21.933945]\n",
      " [22.276228]\n",
      " [28.434465]\n",
      " [27.411892]\n",
      " [19.314318]\n",
      " [21.121866]\n",
      " [25.798973]\n",
      " [18.048855]\n",
      " [17.523321]\n",
      " [18.254604]\n",
      " [19.141237]\n",
      " [16.70243 ]\n",
      " [17.443657]\n",
      " [17.443657]\n",
      " [18.672237]\n",
      " [19.184381]\n",
      " [19.270918]\n",
      " [17.324759]\n",
      " [17.804619]\n",
      " [18.420673]\n",
      " [18.172058]\n",
      " [20.93468 ]\n",
      " [20.336319]\n",
      " [19.401367]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [20.702738]\n",
      " [18.379034]\n",
      " [30.713318]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [31.441584]\n",
      " [21.50067 ]\n",
      " [25.63127 ]\n",
      " [24.86139 ]\n",
      " [25.188782]\n",
      " [24.059341]\n",
      " [22.723225]\n",
      " [32.597656]\n",
      " [23.434288]\n",
      " [30.257797]\n",
      " [31.108656]\n",
      " [29.8722  ]\n",
      " [31.30803 ]\n",
      " [30.128775]\n",
      " [30.387331]\n",
      " [32.597656]\n",
      " [30.193232]\n",
      " [32.32225 ]\n",
      " [34.878246]\n",
      " [34.878246]\n",
      " [35.247322]\n",
      " [34.95177 ]\n",
      " [35.247322]\n",
      " [35.920578]\n",
      " [25.575583]\n",
      " [29.239286]\n",
      " [33.578312]\n",
      " [26.883923]\n",
      " [38.570496]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.375847]\n",
      " [32.73615 ]\n",
      " [31.777718]\n",
      " [37.77326 ]\n",
      " [36.452232]\n",
      " [36.375847]\n",
      " [36.29961 ]\n",
      " [34.878246]\n",
      " [36.452232]\n",
      " [32.390903]\n",
      " [33.084705]\n",
      " [26.422247]\n",
      " [34.658485]\n",
      " [31.108656]\n",
      " [36.375847]\n",
      " [28.803421]\n",
      " [33.225063]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.375847]\n",
      " [26.767838]\n",
      " [36.528763]\n",
      " [24.645227]\n",
      " [35.769962]\n",
      " [31.042454]\n",
      " [28.741638]\n",
      " [35.247322]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.29961 ]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [31.241442]\n",
      " [25.520006]\n",
      " [23.589188]\n",
      " [23.901716]\n",
      " [28.927353]\n",
      " [27.949081]\n",
      " [27.058899]\n",
      " [31.108656]\n",
      " [29.617569]\n",
      " [37.38029 ]\n",
      " [33.295444]\n",
      " [32.66684 ]\n",
      " [33.295444]\n",
      " [31.108656]\n",
      " [23.485819]\n",
      " [31.241442]\n",
      " [32.66684 ]\n",
      " [25.520006]\n",
      " [34.731594]\n",
      " [22.473932]\n",
      " [30.322506]\n",
      " [25.353922]\n",
      " [23.127174]\n",
      " [25.911312]\n",
      " [26.19407 ]\n",
      " [27.768988]\n",
      " [30.257797]\n",
      " [33.649364]\n",
      " [34.22271 ]\n",
      " [37.224148]\n",
      " [35.173225]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.07176 ]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [28.927353]\n",
      " [31.174992]\n",
      " [36.452232]\n",
      " [26.883923]\n",
      " [35.47046 ]\n",
      " [33.507397]\n",
      " [33.01473 ]\n",
      " [36.452232]\n",
      " [36.07176 ]\n",
      " [25.133955]\n",
      " [29.936153]\n",
      " [31.042454]\n",
      " [28.373377]\n",
      " [30.910418]\n",
      " [35.39594 ]\n",
      " [26.709967]\n",
      " [32.048946]\n",
      " [31.441584]\n",
      " [27.828909]\n",
      " [30.452276]\n",
      " [31.575647]\n",
      " [32.94488 ]\n",
      " [36.452232]\n",
      " [36.07176 ]\n",
      " [36.452232]\n",
      " [36.07176 ]\n",
      " [36.528763]\n",
      " [36.29961 ]\n",
      " [35.694874]\n",
      " [36.07176 ]\n",
      " [31.575647]\n",
      " [33.649364]\n",
      " [37.9315  ]\n",
      " [35.694874]\n",
      " [26.080639]\n",
      " [26.250948]\n",
      " [31.91307 ]\n",
      " [30.387331]\n",
      " [34.367413]\n",
      " [32.117073]\n",
      " [29.239286]\n",
      " [30.000233]\n",
      " [34.878246]\n",
      " [36.452232]\n",
      " [36.07176 ]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [36.29961 ]\n",
      " [36.452232]\n",
      " [34.658485]\n",
      " [31.91307 ]\n",
      " [30.647867]\n",
      " [36.452232]\n",
      " [30.51735 ]\n",
      " [34.731594]\n",
      " [30.193232]\n",
      " [36.452232]\n",
      " [36.452232]\n",
      " [35.39594 ]\n",
      " [35.920578]\n",
      " [36.452232]\n",
      " [34.731594]\n",
      " [31.845324]\n",
      " [31.241442]\n",
      " [23.849373]\n",
      " [36.223515]\n",
      " [30.51735 ]\n",
      " [37.38029 ]\n",
      " [31.710224]\n",
      " [30.910418]\n",
      " [30.647867]\n",
      " [31.642876]\n",
      " [29.8722  ]\n",
      " [36.375847]\n",
      " [36.452232]\n",
      " [32.66684 ]\n",
      " [35.920578]\n",
      " [27.058899]\n",
      " [32.32225 ]\n",
      " [36.07176 ]\n",
      " [30.976372]\n",
      " [29.936153]\n",
      " [31.575647]\n",
      " [28.741638]\n",
      " [31.98094 ]\n",
      " [31.642876]\n",
      " [36.147568]\n",
      " [32.528603]\n",
      " [35.694874]\n",
      " [33.86334 ]\n",
      " [30.000233]\n",
      " [29.8722  ]\n",
      " [28.009352]\n",
      " [34.294987]\n",
      " [34.585503]\n",
      " [31.241442]\n",
      " [34.878246]\n",
      " [32.805595]]\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'conff':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    gamma_resp, lamda_resp, alpha_resp, beta_resp = tf.split(final_output, 4, axis=-1)\n",
    "    gamma_rr, lamda_rr, alpha_rr, beta_rr = tf.split(final_output_rr, 4, axis=-1)\n",
    "    final_output_resp = gamma_resp.numpy()\n",
    "    final_rr = gamma_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0] , final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "    \n",
    "    final_lamda_resp = lamda_resp.numpy()\n",
    "    final_alpha_resp = alpha_resp.numpy()\n",
    "    final_beta_resp = beta_resp.numpy()\n",
    "    \n",
    "    final_lamda_rr = lamda_rr.numpy()\n",
    "    final_alpha_rr = alpha_rr.numpy()\n",
    "    final_beta_rr = beta_rr.numpy()\n",
    "    \n",
    "    aleatoric_resp = final_beta_resp/(final_alpha_resp - 1)\n",
    "    epistemic_resp = final_beta_resp/(final_lamda_resp*(final_alpha_resp - 1))\n",
    "    \n",
    "    aleatoric_rr = final_beta_rr/(final_alpha_rr - 1)\n",
    "    epistemic_rr = final_beta_rr/(final_lamda_rr*(final_alpha_rr - 1))\n",
    "    \n",
    "    epistemic_rr = epistemic_rr.reshape(epistemic_rr.shape[0],epistemic_rr.shape[1])\n",
    "    aleatoric_rr = aleatoric_rr.reshape(aleatoric_rr.shape[0],aleatoric_rr.shape[1])\n",
    "    print(epistemic_rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Absolute Error for confa is: 2.695209975106617\n",
    "#Root Mean Square Error for confa is: 3.4192597535608034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3335617667.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_92033/3335617667.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Mean Absolute Error for confb is: 2.396488667733235\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Mean Absolute Error for confb is: 2.396488667733235\n",
    "Root Mean Square Error for confb is: 3.027523586819892\n",
    "    \n",
    "#-----------------------------------------------------------\n",
    "Mean Absolute Error for confb is: 2.3896557374099223\n",
    "Root Mean Square Error for confb is: 3.0185706348248624\n",
    "    \n",
    "Mean Absolute Error for confb is: 2.3964927987598195\n",
    "Root Mean Square Error for confb is: 3.0275312498024753"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
