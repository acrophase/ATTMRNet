{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 19:36:39.774016: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_extraction import *\n",
    "from resp_signal_extraction import *\n",
    "from rr_extration import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "from tf_model import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber\n",
    "import evidential_deep_learning as edl\n",
    "import matplotlib.pyplot as plt\n",
    "from filters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_conf = 'confe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 19:36:42.822809: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-16 19:36:42.904523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-16 19:36:42.905063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:2d:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-08-16 19:36:42.905080: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-16 19:36:42.906504: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-16 19:36:42.906531: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-16 19:36:42.906990: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-16 19:36:42.907104: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-16 19:36:42.907510: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-08-16 19:36:42.907842: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-08-16 19:36:42.907924: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-16 19:36:42.907979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-16 19:36:42.908523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-16 19:36:42.909046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-08-16 19:36:42.909320: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-16 19:36:42.910483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-16 19:36:42.911011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:2d:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-08-16 19:36:42.911056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-16 19:36:42.911598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-16 19:36:42.912101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-08-16 19:36:42.912124: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-16 19:36:43.203586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-16 19:36:43.203616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-08-16 19:36:43.203621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-08-16 19:36:43.203842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-16 19:36:43.204362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-16 19:36:43.204870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-16 19:36:43.205343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22154 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3090, pci bus id: 0000:2d:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "with open('output','rb') as f:\n",
    "    output_data = pkl.load(f)\n",
    "\n",
    "with open('input','rb') as f:\n",
    "    input_data = pkl.load(f)\n",
    "\n",
    "with open('raw_signal.pkl','rb') as f:\n",
    "    raw_data = pkl.load(f)\n",
    "\n",
    "input_data = input_data.reshape(input_data.shape[0],input_data.shape[-1],input_data.shape[1])\n",
    "raw_data = raw_data.reshape(raw_data.shape[0],raw_data.shape[-1],raw_data.shape[1])\n",
    "annotation = pd.read_pickle('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/annotation.pkl')\n",
    "reference_rr = (annotation['Reference_RR'].values).reshape(-1,1)\n",
    "\n",
    "tensor_input = tf.convert_to_tensor(input_data, dtype = 'float32')\n",
    "tensor_output = tf.convert_to_tensor(output_data, dtype = 'float32')\n",
    "tensor_ref_rr = tf.convert_to_tensor(reference_rr, dtype = 'float32')\n",
    "tensor_raw_data = tf.convert_to_tensor(raw_data, dtype = 'float32')\n",
    "training_ids = annotation['patient_id'] < 13\n",
    "\n",
    "x_train_data = tensor_input[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_data = tensor_input[tf.convert_to_tensor(~(training_ids.values))]\n",
    "x_train_ref_rr = tensor_ref_rr[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_ref_rr = tensor_ref_rr[tf.convert_to_tensor(~(training_ids.values))]\n",
    "x_train_raw_sig = tensor_raw_data[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_raw_sig = tensor_raw_data[tf.convert_to_tensor(~(training_ids.values))]\n",
    "\n",
    "y_train_data = tensor_output[tf.convert_to_tensor(training_ids.values)]\n",
    "y_test_data = tensor_output[tf.convert_to_tensor(~(training_ids.values))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , y_train_data))\n",
    "    train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , y_test_data))\n",
    "    test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confd':\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , y_train_data, x_train_ref_rr))\n",
    "    train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , y_test_data, x_test_ref_rr))\n",
    "    test_dataset = test_dataset.batch(128)\n",
    "    \n",
    "if input_conf == 'confb':\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , x_train_ref_rr))\n",
    "    train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , x_test_ref_rr))\n",
    "    test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confe':\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , y_train_data))\n",
    "    train_dataset = train_dataset.shuffle(len(x_train_raw_sig)).batch(128)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , y_test_data))\n",
    "    test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confa':\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , x_train_ref_rr))\n",
    "    train_dataset = train_dataset.shuffle(len(x_train_raw_sig)).batch(128)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , x_test_ref_rr))\n",
    "    test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'conff':\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , y_train_data, x_train_ref_rr))\n",
    "    train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , y_test_data, x_test_ref_rr))\n",
    "    test_dataset = test_dataset.batch(128)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODELS/confc/best_modellr_0.0001__coeff_0.01.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step,(x_batch_test , y_batch_test) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = loss_fn(y_batch_test,output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confd':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Multi_resp(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODELS/confd/best_model_lr_0.0001__coeff_0.01.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,y_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr = model(x_batch_test)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "            \n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confb':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Encoder(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODELS/confb/best_model_lr_0.0001__coeff_0.01.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confe':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODELS/confe/best_model_lr_0.0001__coeff_0.01.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw,y_batch_test) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(y_batch_test , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "        \n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confa':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_encoder(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODELS/confa/best_model_lr_0.0001__coeff_0.01.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw, x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_multi(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODELS/conff/best_model_lr_0.0001__coeff_0.01.h5')        \n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw , y_batch_test , x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr = model(x_batch_test_raw)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extremas_extraction(signal):\n",
    "    avg_breath_duration = np.array([])\n",
    "    extrema_relevent = []\n",
    "    for item in signal:\n",
    "        amplitude = np.array([])\n",
    "        pos_peaks , _ = scipy.signal.find_peaks(item , height = [-300,300])\n",
    "        neg_peaks , _ = scipy.signal.find_peaks(-1*item , height = [-300 , 300])\n",
    "        extremas = np.concatenate((pos_peaks , neg_peaks))\n",
    "        extremas = np.sort(extremas)\n",
    "        for i in range(len(extremas)):\n",
    "            amplitude = np.append(amplitude , item[int(extremas[i])])\n",
    "        amplitude_diff = np.abs(np.diff(amplitude))\n",
    "        q3 = np.percentile(amplitude_diff , 75)\n",
    "        threshold = 0.3*q3\n",
    "        eliminate_pairs_of_extrema = 1\n",
    "        while(eliminate_pairs_of_extrema):\n",
    "            amps = np.array([])\n",
    "            if len(extremas)<3:\n",
    "                eliminate_pairs_of_extrema = 0\n",
    "                continue\n",
    "            for i in range(len(extremas)):\n",
    "                amps = np.append(amps , item[int(extremas[i])])\n",
    "            amp_diff = np.abs(np.diff(amps)) \n",
    "            min_amp_diff , index = min(amp_diff) , np.argmin(amp_diff)\n",
    "            #print(min_amp_diff)\n",
    "            if min_amp_diff > threshold:\n",
    "                eliminate_pairs_of_extrema = 0\n",
    "                #extrema_relevent = extremas\n",
    "            else:\n",
    "                extremas = np.concatenate((extremas[0:index] , extremas[index+2 :]))\n",
    "                #amplitude_diff = np.delete(amplitude_diff , index)\n",
    "        if item[int(extremas[0])] < item[int(extremas[1])]:\n",
    "            extremas = extremas[1:]\n",
    "        if item[int(extremas[-1])] < item[int(extremas[-2])]:\n",
    "            extremas = extremas[:-1]\n",
    "        no_of_breaths = (len(extremas)-1)/2\n",
    "        breath_duration = extremas[-1] - extremas[0]\n",
    "        avg_breath_duration = np.append(avg_breath_duration , breath_duration/no_of_breaths)\n",
    "        extrema_relevent.append(extremas)\n",
    "    return avg_breath_duration , extrema_relevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sig = y_test_data.numpy()\n",
    "fbpB , fbpA = band_pass(0.1,0.9,8)\n",
    "final_ref_resp_sig = []\n",
    "for item in ref_sig:\n",
    "    final_ref_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "final_ref_resp_sig = np.array(final_ref_resp_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confa':\n",
    "    final_output_rr = final_output.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "#----------------------------------------------------------------------------------------------------------------   \n",
    "if input_conf == 'confb':\n",
    "    final_output_rr = final_output.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "\n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------    \n",
    "if input_conf == 'confe':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confd':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_rr = final_output_rr\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_rr = final_output_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITH EVIDENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 19:37:20.716898: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-16 19:37:21.059261: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101\n",
      "2021-08-16 19:37:21.479799: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-16 19:37:21.779655: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-16 19:37:21.786116: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confc':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet(model_input_shape)\n",
    "    coeff_val = 1e-3\n",
    "    #loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODEL_WITH_EVI/confc/best_model__coeff_0.01.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step,(x_batch_test , y_batch_test) in enumerate(test_dataset):\n",
    "        y_batch_test = tf.expand_dims(y_batch_test , axis = -1)\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = edl.losses.EvidentialRegression(y_batch_test,output, coeff = coeff_val)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confe':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw(model_input_shape)\n",
    "    coeff_val = 1e-4\n",
    "    #loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODEL_WITH_EVI/confe/best_model___coeff_0.01.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw,y_batch_test) in enumerate(test_dataset):\n",
    "        y_batch_test = tf.expand_dims(y_batch_test , axis = -1)\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = edl.losses.EvidentialRegression(y_batch_test,output, coeff = coeff_val)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confb':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Encoder(model_input_shape)\n",
    "    coeff_val = 0.01\n",
    "    #loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODEL_WITH_EVI/confb/best_model___coeff_0.005.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        x_batch_test_ref_rr = tf.expand_dims(x_batch_test_ref_rr , axis = -1)\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = edl.losses.EvidentialRegression(x_batch_test_ref_rr , output , coeff = coeff_val)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confa':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_encoder(model_input_shape)\n",
    "    #loss_fn = Huber()\n",
    "    coeff_val = 0.01\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODEL_WITH_EVI/confa/best_model___coeff_0.01.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw, x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        x_batch_test_ref_rr = tf.expand_dims(x_batch_test_ref_rr , axis = -1)\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = edl.losses.EvidentialRegression(x_batch_test_ref_rr , output, coeff = coeff_val)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)  \n",
    "        \n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_multi(model_input_shape)\n",
    "    #loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    coeff_val = 0.05\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODEL_WITH_EVI/conff/best_model___coeff_0.05.h5')        \n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw , y_batch_test , x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        y_batch_test = tf.expand_dims(y_batch_test , axis = -1)\n",
    "        x_batch_test_ref_rr = tf.expand_dims(x_batch_test_ref_rr , axis = -1)\n",
    "        test_output,test_out_rr = model(x_batch_test_raw)\n",
    "        test_loss_resp = edl.losses.EvidentialRegression(y_batch_test  , test_output , coeff = coeff_val)\n",
    "        test_loss_rr = edl.losses.EvidentialRegression(x_batch_test_ref_rr , test_out_rr , coeff = coeff_val)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss) \n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confd':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Multi_resp(model_input_shape)\n",
    "    #loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    coeff_val = 0.005\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/SAVED_MODEL_WITH_EVI/confd/best_model___coeff_0.005.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,y_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        x_batch_test_ref_rr = tf.expand_dims(x_batch_test_ref_rr , axis = -1)\n",
    "        y_batch_test = tf.expand_dims(y_batch_test , axis = -1)\n",
    "        test_output,test_out_rr = model(x_batch_test)\n",
    "        test_loss_resp = edl.losses.EvidentialRegression(y_batch_test  , test_output, coeff = coeff_val)\n",
    "        test_loss_rr = edl.losses.EvidentialRegression(x_batch_test_ref_rr , test_out_rr,coeff = coeff_val)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma, lamda, alpha, beta = tf.split(final_output, 4, axis=-1)\n",
    "output = gamma.numpy()\n",
    "output = output.reshape(output.shape[0] , output.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error average wise for confe is: 3.5754335472094394\n",
      "Root Mean Square Error average wise for confe is: 4.47758835764782\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confc':\n",
    "    final_output_resp_sig = []\n",
    "    gamma, lamda, alpha, beta = tf.split(final_output, 4, axis=-1)\n",
    "    output = gamma.numpy()\n",
    "    output = output.reshape(output.shape[0] , output.shape[1])\n",
    "    for item in output:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    final_lamda = lamda.numpy()\n",
    "    final_alpha = alpha.numpy()\n",
    "    final_beta = beta.numpy()\n",
    "    \n",
    "    final_lamda = final_lamda.reshape(final_lamda.shape[0],final_lamda.shape[1])\n",
    "    final_alpha = final_alpha.reshape(final_alpha.shape[0],final_alpha.shape[1])\n",
    "    final_beta = final_beta.reshape(final_beta.shape[0],final_beta.shape[1])\n",
    "    #x_samps = np.arange(0,len(y_train_data[0]))\n",
    "    aleatoric = final_beta/(final_alpha - 1)\n",
    "    epistemic = final_beta/(final_lamda*(final_alpha - 1))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confe':\n",
    "    final_output_resp_sig = []\n",
    "    gamma, lamda, alpha, beta = tf.split(final_output, 4, axis=-1)\n",
    "    output = gamma.numpy()\n",
    "    output = output.reshape(output.shape[0] , output.shape[1])\n",
    "    for item in output:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    final_lamda = lamda.numpy()\n",
    "    final_alpha = alpha.numpy()\n",
    "    final_beta = beta.numpy()\n",
    "    \n",
    "    final_lamda = final_lamda.reshape(final_lamda.shape[0],final_lamda.shape[1])\n",
    "    final_alpha = final_alpha.reshape(final_alpha.shape[0],final_alpha.shape[1])\n",
    "    final_beta = final_beta.reshape(final_beta.shape[0],final_beta.shape[1])\n",
    "    x_samps = np.arange(0,len(y_train_data[0]))\n",
    "    aleatoric = final_beta/(final_alpha - 1)\n",
    "    epistemic = final_beta/(final_lamda*(final_alpha - 1))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confb':\n",
    "    gamma, lamda, alpha, beta = tf.split(final_output, 4, axis=-1)\n",
    "    final_output_rr = gamma.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "    \n",
    "    final_lamda = lamda.numpy()\n",
    "    final_alpha = alpha.numpy()\n",
    "    final_beta = beta.numpy()\n",
    "    \n",
    "    final_lamda = final_lamda.reshape(final_lamda.shape[0],final_lamda.shape[1])\n",
    "    final_alpha = final_alpha.reshape(final_alpha.shape[0],final_alpha.shape[1])\n",
    "    final_beta = final_beta.reshape(final_beta.shape[0],final_beta.shape[1])\n",
    "    #x_samps = np.arange(0,len(y_train_data[0]))\n",
    "    aleatoric = final_beta/(final_alpha - 1)\n",
    "    epistemic = final_beta/(final_lamda*(final_alpha - 1))\n",
    "    var = np.sqrt(epistemic)\n",
    "    print(epistemic)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confa':\n",
    "    gamma, lamda, alpha, beta = tf.split(final_output, 4, axis=-1)\n",
    "    final_output_rr = gamma.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "    \n",
    "    final_lamda = lamda.numpy()\n",
    "    final_alpha = alpha.numpy()\n",
    "    final_beta = beta.numpy()\n",
    "    \n",
    "    final_lamda = final_lamda.reshape(final_lamda.shape[0],final_lamda.shape[1])\n",
    "    final_alpha = final_alpha.reshape(final_alpha.shape[0],final_alpha.shape[1])\n",
    "    final_beta = final_beta.reshape(final_beta.shape[0],final_beta.shape[1])\n",
    "    aleatoric = final_beta/(final_alpha - 1)\n",
    "    epistemic = final_beta/(final_lamda*(final_alpha - 1))\n",
    "    print(epistemic)\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    gamma_resp, lamda_resp, alpha_resp, beta_resp = tf.split(final_output, 4, axis=-1)\n",
    "    gamma_rr, lamda_rr, alpha_rr, beta_rr = tf.split(final_output_rr, 4, axis=-1)\n",
    "    final_output_resp = gamma_resp.numpy()\n",
    "    final_rr = gamma_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0] , final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "    \n",
    "    final_lamda_resp = lamda_resp.numpy()\n",
    "    final_alpha_resp = alpha_resp.numpy()\n",
    "    final_beta_resp = beta_resp.numpy()\n",
    "    \n",
    "    final_lamda_rr = lamda_rr.numpy()\n",
    "    final_alpha_rr = alpha_rr.numpy()\n",
    "    final_beta_rr = beta_rr.numpy()\n",
    "    \n",
    "    aleatoric_resp = final_beta_resp/(final_alpha_resp - 1)\n",
    "    epistemic_resp = final_beta_resp/(final_lamda_resp*(final_alpha_resp - 1))\n",
    "    \n",
    "    aleatoric_rr = final_beta_rr/(final_alpha_rr - 1)\n",
    "    epistemic_rr = final_beta_rr/(final_lamda_rr*(final_alpha_rr - 1))\n",
    "    \n",
    "    print(epistemic_rr)\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confd':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    gamma_resp, lamda_resp, alpha_resp, beta_resp = tf.split(final_output, 4, axis=-1)\n",
    "    gamma_rr, lamda_rr, alpha_rr, beta_rr = tf.split(final_output_rr, 4, axis=-1)\n",
    "    final_output_resp = gamma_resp.numpy()\n",
    "    final_rr = gamma_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0] , final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "    \n",
    "    final_lamda_resp = lamda_resp.numpy()\n",
    "    final_alpha_resp = alpha_resp.numpy()\n",
    "    final_beta_resp = beta_resp.numpy()\n",
    "    \n",
    "    final_lamda_rr = lamda_rr.numpy()\n",
    "    final_alpha_rr = alpha_rr.numpy()\n",
    "    final_beta_rr = beta_rr.numpy()\n",
    "    \n",
    "    aleatoric_resp = final_beta_resp/(final_alpha_resp - 1)\n",
    "    epistemic_resp = final_beta_resp/(final_lamda_resp*(final_alpha_resp - 1))\n",
    "    \n",
    "    aleatoric_rr = final_beta_rr/(final_alpha_rr - 1)\n",
    "    epistemic_rr = final_beta_rr/(final_lamda_rr*(final_alpha_rr - 1))\n",
    "    \n",
    "    print(epistemic_rr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confd':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Multi_resp(model_input_shape)\n",
    "    #loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    coeff_val = 0.005\n",
    "    model.load_weights('/media/acrophase/Sentinel_1/charan/BR_Uncertainty/DL_BASED_METHOD/TEST_SAVE_MODEL/confd/best_model___coeff_0.005.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,y_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        x_batch_test_ref_rr = tf.expand_dims(x_batch_test_ref_rr , axis = -1)\n",
    "        y_batch_test = tf.expand_dims(y_batch_test , axis = -1)\n",
    "        test_output,test_out_rr = model(x_batch_test)\n",
    "        test_loss_resp = edl.losses.EvidentialRegression(y_batch_test  , test_output, coeff = coeff_val)\n",
    "        test_loss_rr = edl.losses.EvidentialRegression(x_batch_test_ref_rr , test_out_rr,coeff = coeff_val)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confd':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    gamma_resp, lamda_resp, alpha_resp, beta_resp = tf.split(final_output, 4, axis=-1)\n",
    "    gamma_rr, lamda_rr, alpha_rr, beta_rr = tf.split(final_output_rr, 4, axis=-1)\n",
    "    final_output_resp = gamma_resp.numpy()\n",
    "    final_rr = gamma_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0] , final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "    \n",
    "    final_lamda_resp = lamda_resp.numpy()\n",
    "    final_alpha_resp = alpha_resp.numpy()\n",
    "    final_beta_resp = beta_resp.numpy()\n",
    "    \n",
    "    final_lamda_rr = lamda_rr.numpy()\n",
    "    final_alpha_rr = alpha_rr.numpy()\n",
    "    final_beta_rr = beta_rr.numpy()\n",
    "    \n",
    "    aleatoric_resp = final_beta_resp/(final_alpha_resp - 1)\n",
    "    epistemic_resp = final_beta_resp/(final_lamda_resp*(final_alpha_resp - 1))\n",
    "    \n",
    "    aleatoric_rr = final_beta_rr/(final_alpha_rr - 1)\n",
    "    epistemic_rr = final_beta_rr/(final_lamda_rr*(final_alpha_rr - 1))\n",
    "    \n",
    "    print(epistemic_rr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(final_output_resp[123])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
