{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee4cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "SEED = 0\n",
    "#------------------------------------------------------------------------------------\n",
    "def set_seeds(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "#------------------------------------------------------------------------------------\n",
    "def set_global_determinism(seed=SEED):\n",
    "    set_seeds(seed=seed)\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    \n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Call the above function with seed value\n",
    "set_global_determinism(seed=SEED)\n",
    "#-----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7187b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.4.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "from data_extraction import *\n",
    "from resp_signal_extraction import *\n",
    "from rr_extration import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "import pickle as pkl\n",
    "from tf_model import *\n",
    "from tf_model_new import *\n",
    "from tf_model_evi import *\n",
    "from tf_model_attn_monte import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber\n",
    "import matplotlib.pyplot as plt\n",
    "from filters import *\n",
    "import tqdm\n",
    "import plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import ipywidgets as widgets\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "py.offline.init_notebook_mode(connected = True)\n",
    "from plotly import tools\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d514e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_conf = 'confd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ce9b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 12:40:04.323682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:40:04.328861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:40:04.329187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:40:04.366316: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-20 12:40:04.366436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:40:04.366786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:40:04.367120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:40:04.690394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:40:04.690744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:40:04.691076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:40:04.691358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10345 MB memory:  -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "with open('output','rb') as f:\n",
    "    output_data = pkl.load(f)\n",
    "\n",
    "with open('input','rb') as f:\n",
    "    input_data = pkl.load(f)\n",
    "\n",
    "with open('raw_signal.pkl','rb') as f:\n",
    "    raw_data = pkl.load(f)\n",
    "\n",
    "input_data = np.transpose(input_data, (0,2,1))\n",
    "raw_data = np.transpose(raw_data, (0,2,1))\n",
    "annotation = pd.read_pickle('/media/acrophase/pose1/charan/BR_Uncertainty/MONTE_CARLO/annotation.pkl')\n",
    "reference_rr = (annotation['Reference_RR'].values).reshape(-1,1)\n",
    "\n",
    "input_data = np.around(input_data , decimals = 4)\n",
    "raw_data = np.around(raw_data , decimals = 4)\n",
    "output_data = np.around(output_data , decimals = 4)\n",
    "reference_rr = np.around(reference_rr , decimals = 4)\n",
    "\n",
    "tensor_input = tf.convert_to_tensor(input_data, dtype = 'float32')\n",
    "tensor_output = tf.convert_to_tensor(output_data, dtype = 'float32')\n",
    "tensor_ref_rr = tf.convert_to_tensor(reference_rr, dtype = 'float32')\n",
    "tensor_raw_data = tf.convert_to_tensor(raw_data, dtype = 'float32')\n",
    "training_ids = annotation['patient_id'] < 13\n",
    "\n",
    "x_train_data = tensor_input[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_data = tensor_input[tf.convert_to_tensor(~(training_ids.values))]\n",
    "x_train_ref_rr = tensor_ref_rr[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_ref_rr = tensor_ref_rr[tf.convert_to_tensor(~(training_ids.values))]\n",
    "x_train_raw_sig = tensor_raw_data[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_raw_sig = tensor_raw_data[tf.convert_to_tensor(~(training_ids.values))]\n",
    "\n",
    "y_train_data = tensor_output[tf.convert_to_tensor(training_ids.values)]\n",
    "y_test_data = tensor_output[tf.convert_to_tensor(~(training_ids.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba8152e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , y_train_data))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , y_test_data))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confb':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confd':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , y_train_data, x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , y_test_data, x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "if input_conf == 'confa':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_raw_sig)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confe':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , y_train_data))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_raw_sig)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , y_test_data))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "if input_conf == 'conff':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , y_train_data, x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , y_test_data, x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cf31ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 12:40:05.600633: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8202\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confc':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_WO_ATT/confc/best_model_0.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,y_batch_test) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = loss_fn(y_batch_test , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "        \n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confd':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Multi_resp(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_WO_ATT/confd/best_model_40.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,y_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr = model(x_batch_test)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "            \n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confb':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Encoder(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_WO_ATT/confb/best_model_10.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confe':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_WO_ATT/confe/best_model_20.001_0.0001_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw,y_batch_test) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(y_batch_test , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "        \n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confa':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_encoder(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_WO_ATT/confa/best_model_10.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw, x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_multi(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_WO_ATT/conff/best_model_10.0001_0.0001_100.h5')        \n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw , y_batch_test , x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr = model(x_batch_test_raw)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a54eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extremas_extraction(signal):\n",
    "    avg_breath_duration = np.array([])\n",
    "    extrema_relevent = []\n",
    "    for item in signal:\n",
    "        amplitude = np.array([])\n",
    "        pos_peaks , _ = scipy.signal.find_peaks(item , height = [-3000,3000])\n",
    "        neg_peaks , _ = scipy.signal.find_peaks(-1*item , height = [-3000 , 3000])\n",
    "        extremas = np.concatenate((pos_peaks , neg_peaks))\n",
    "        extremas = np.sort(extremas)\n",
    "        for i in range(len(extremas)):\n",
    "            amplitude = np.append(amplitude , item[int(extremas[i])])\n",
    "        amplitude_diff = np.abs(np.diff(amplitude))\n",
    "        q3 = np.percentile(amplitude_diff , 75)\n",
    "        threshold = 0.3*q3\n",
    "        eliminate_pairs_of_extrema = 1\n",
    "        while(eliminate_pairs_of_extrema):\n",
    "            amps = np.array([])\n",
    "            if len(extremas)<3:\n",
    "                eliminate_pairs_of_extrema = 0\n",
    "                continue\n",
    "            for i in range(len(extremas)):\n",
    "                amps = np.append(amps , item[int(extremas[i])])\n",
    "            amp_diff = np.abs(np.diff(amps)) \n",
    "            min_amp_diff , index = min(amp_diff) , np.argmin(amp_diff)\n",
    "            #print(min_amp_diff)\n",
    "            if min_amp_diff > threshold:\n",
    "                eliminate_pairs_of_extrema = 0\n",
    "                #extrema_relevent = extremas\n",
    "            else:\n",
    "                extremas = np.concatenate((extremas[0:index] , extremas[index+2 :]))\n",
    "                #amplitude_diff = np.delete(amplitude_diff , index)\n",
    "        if item[int(extremas[0])] < item[int(extremas[1])]:\n",
    "            extremas = extremas[1:]\n",
    "        if item[int(extremas[-1])] < item[int(extremas[-2])]:\n",
    "            extremas = extremas[:-1]\n",
    "        no_of_breaths = (len(extremas)-1)/2\n",
    "        breath_duration = extremas[-1] - extremas[0]\n",
    "        avg_breath_duration = np.append(avg_breath_duration , breath_duration/no_of_breaths)\n",
    "        extrema_relevent.append(extremas)\n",
    "    return avg_breath_duration , extrema_relevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ed826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sig = y_test_data.numpy()\n",
    "fbpB , fbpA = band_pass(0.1,0.7,8)\n",
    "final_ref_resp_sig = []\n",
    "for item in ref_sig:\n",
    "    final_ref_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "final_ref_resp_sig = np.array(final_ref_resp_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd65665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confa':\n",
    "    final_output_rr = final_output.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "#----------------------------------------------------------------------------------------------------------------   \n",
    "if input_conf == 'confb':\n",
    "    final_output_rr = final_output.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf585261",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "\n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------    \n",
    "if input_conf == 'confe':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50b3cc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error average wise for confd is: 2.379813739263379\n",
      "Root Mean Square Error average wise for confd is: 2.95026732858665\n",
      "Mean Absolute Error instantaneous wise for confd is: 4.30007286260875\n",
      "Root Mean Square Error instantaneous wise for confd is: 5.220437461580008\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confd':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_rr = final_output_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_rr = final_output_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3938e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89eb3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f56aa9a",
   "metadata": {},
   "source": [
    "# WITH ATTENTION BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2067fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_ATT(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODELS_WITH_ATT/confc/best_model_10.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    attn1 = tf.convert_to_tensor([])\n",
    "    attn2 = tf.convert_to_tensor([])\n",
    "    attn3 = tf.convert_to_tensor([])\n",
    "    attn4 = tf.convert_to_tensor([])\n",
    "    attn5 = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,y_batch_test) in enumerate(test_dataset):\n",
    "        output,at_1,at_2,at_3,at_4,at_5 = model(x_batch_test)\n",
    "        test_loss = loss_fn(y_batch_test , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "            attn1 = at_1\n",
    "            attn2 = at_2\n",
    "            attn3 = at_3\n",
    "            attn4 = at_4\n",
    "            attn5 = at_5\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "            attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "        \n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confd':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Multi_resp_ATT(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODELS_WITH_ATT/confd/best_model_0.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    attn1 = tf.convert_to_tensor([])\n",
    "    attn2 = tf.convert_to_tensor([])\n",
    "    attn3 = tf.convert_to_tensor([])\n",
    "    attn4 = tf.convert_to_tensor([])\n",
    "    attn5 = tf.convert_to_tensor([])\n",
    "    attn6 = tf.convert_to_tensor([])\n",
    "    attn7 = tf.convert_to_tensor([])\n",
    "    attn8 = tf.convert_to_tensor([])\n",
    "    attn9 = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,y_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr,at_1,at_2,at_3,at_4,at_5,at_6,at_7,at_8,at_9 = model(x_batch_test)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "            attn1 = at_1\n",
    "            attn2 = at_2\n",
    "            attn3 = at_3\n",
    "            attn4 = at_4\n",
    "            attn5 = at_5\n",
    "            attn6 = at_6\n",
    "            attn7 = at_7\n",
    "            attn8 = at_8\n",
    "            attn9 = at_9\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "            attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "            attn6 = tf.concat([attn6 , at_6] , axis = 0)\n",
    "            attn7 = tf.concat([attn7 , at_7] , axis = 0)\n",
    "            attn8 = tf.concat([attn8 , at_8] , axis = 0)\n",
    "            attn9 = tf.concat([attn9 , at_9] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "            \n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confb':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Encoder_ATT(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODELS_WITH_ATT/confb/best_model_0.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    attn1 = tf.convert_to_tensor([])\n",
    "    attn2 = tf.convert_to_tensor([])\n",
    "    attn3 = tf.convert_to_tensor([])\n",
    "    attn4 = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output,at_1,at_2,at_3,at_4 = model(x_batch_test)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "            attn1 = at_1\n",
    "            attn2 = at_2\n",
    "            attn3 = at_3\n",
    "            attn4 = at_4\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confe':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_ATT(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODELS_WITH_ATT/confe/best_model_10.001_0.0001_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    attn1 = tf.convert_to_tensor([])\n",
    "    attn2 = tf.convert_to_tensor([])\n",
    "    attn3 = tf.convert_to_tensor([])\n",
    "    attn4 = tf.convert_to_tensor([])\n",
    "    attn5 = tf.convert_to_tensor([])\n",
    "    attn6 = tf.convert_to_tensor([])\n",
    "    attn7 = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw,y_batch_test) in enumerate(test_dataset):\n",
    "        output,at_1,at_2,at_3,at_4,at_5,at_6,at_7 = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(y_batch_test , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "            attn1 = at_1\n",
    "            attn2 = at_2\n",
    "            attn3 = at_3\n",
    "            attn4 = at_4\n",
    "            attn5 = at_5\n",
    "            attn6 = at_6\n",
    "            attn7 = at_7\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "            attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "            attn6 = tf.concat([attn6 , at_6] , axis = 0)\n",
    "            attn7 = tf.concat([attn7 , at_7] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "        \n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confa':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_encoder_ATT(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODELS_WITH_ATT/confa/best_model_10.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    attn1 = tf.convert_to_tensor([])\n",
    "    attn2 = tf.convert_to_tensor([])\n",
    "    attn3 = tf.convert_to_tensor([])\n",
    "    attn4 = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw, x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output,at_1,at_2,at_3,at_4  = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "            attn1 = at_1\n",
    "            attn2 = at_2\n",
    "            attn3 = at_3\n",
    "            attn4 = at_4\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_multi_ATT(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODELS_WITH_ATT/conff/best_model_20.0001_0.0001_100.h5')        \n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    attn1 = tf.convert_to_tensor([])\n",
    "    attn2 = tf.convert_to_tensor([])\n",
    "    attn3 = tf.convert_to_tensor([])\n",
    "    attn4 = tf.convert_to_tensor([])\n",
    "    attn5 = tf.convert_to_tensor([])\n",
    "    attn6 = tf.convert_to_tensor([])\n",
    "    attn7 = tf.convert_to_tensor([])\n",
    "    attn8 = tf.convert_to_tensor([])\n",
    "    attn9 = tf.convert_to_tensor([])\n",
    "    attn10 = tf.convert_to_tensor([])\n",
    "    attn11 = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw , y_batch_test , x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr,at_1,at_2,at_3,at_4,at_5,at_6,at_7,at_8,at_9,at_10,at_11 = model(x_batch_test_raw)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "            attn1 = at_1\n",
    "            attn2 = at_2\n",
    "            attn3 = at_3\n",
    "            attn4 = at_4\n",
    "            attn5 = at_5\n",
    "            attn6 = at_6\n",
    "            attn7 = at_7\n",
    "            attn8 = at_8\n",
    "            attn9 = at_9\n",
    "            attn10 = at_10\n",
    "            attn11 = at_11\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "            attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "            attn6 = tf.concat([attn6 , at_6] , axis = 0)\n",
    "            attn7 = tf.concat([attn7 , at_7] , axis = 0)\n",
    "            attn8 = tf.concat([attn8 , at_8] , axis = 0)\n",
    "            attn9 = tf.concat([attn9 , at_9] , axis = 0)\n",
    "            attn10 = tf.concat([attn10 , at_10] , axis = 0)\n",
    "            attn11 = tf.concat([attn11 , at_11] , axis = 0)\n",
    "        test_loss_list.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec177928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if input_conf == 'confa':\n",
    "    final_output_rr = final_output.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "#----------------------------------------------------------------------------------------------------------------   \n",
    "if input_conf == 'confb':\n",
    "    final_output_rr = final_output.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "\n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------    \n",
    "if input_conf == 'confe':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16d1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confd':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_rr = final_output_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_rr = final_output_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc6cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(attn1.shape)\n",
    "#print(attn2.shape)\n",
    "#print(attn3.shape)\n",
    "#print(attn4.shape)\n",
    "#print(attn5.shape)\n",
    "#print(attn6.shape)\n",
    "#print(attn7.shape)\n",
    "#print(attn8.shape)\n",
    "#print(attn9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c75c13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#x_attn1 = attn1[0][0].numpy()\n",
    "#x_attn5 = attn5[0][0].numpy()\n",
    "#x_attn6 = attn6[0][0].numpy()\n",
    "#x_attn7 = attn7[0][0].numpy()\n",
    "#x_attn8 = attn8[0][0].numpy()\n",
    "#x_attn9 = attn9[0][0].numpy()\n",
    "\n",
    "#figure,axes = plt.subplots(nrows = 2 , ncols = 3)\n",
    "\n",
    "#axes[0,0].plot(x_attn1)\n",
    "\n",
    "#axes[0,1].plot(x_attn5)\n",
    "#axes[0,2].plot(x_attn6)\n",
    "#axes[1,0].plot(x_attn7)\n",
    "#axes[1,1].plot(x_attn8)\n",
    "#axes[1,2].plot(x_attn9)\n",
    "\n",
    "#figure.tight_layout()\n",
    "#y = np.transpose(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c4fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_attn1 = attn1[0][0].numpy()\n",
    "#x_attn2 = attn2[0][0].numpy()\n",
    "#x_attn3 = attn3[0][0].numpy()\n",
    "#x_attn4 = attn4[0][0].numpy()\n",
    "\n",
    "#figure1,axes1 = plt.subplots(nrows = 2 , ncols = 2)\n",
    "\n",
    "#axes1[0,0].plot(x_attn1)\n",
    "#axes1[0,1].plot(x_attn2)\n",
    "#axes1[1,0].plot(x_attn3)\n",
    "#axes1[1,1].plot(x_attn4)\n",
    "\n",
    "#figure1.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d6f158",
   "metadata": {},
   "source": [
    "# ATTENTION WITH MONTE CARLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642408ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    final_output = np.array([])\n",
    "    final_attn1 = np.array([])\n",
    "    final_attn2 = np.array([])\n",
    "    final_attn3 = np.array([])\n",
    "    final_attn4 = np.array([])\n",
    "    final_attn5 = np.array([])\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_ATT_MC(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_MONTE/confc/best_model_20.01_1e-05_100.h5')\n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        attn1 = tf.convert_to_tensor([])\n",
    "        attn2 = tf.convert_to_tensor([])\n",
    "        attn3 = tf.convert_to_tensor([])\n",
    "        attn4 = tf.convert_to_tensor([])\n",
    "        attn5 = tf.convert_to_tensor([])\n",
    "        for step,(x_batch_test , y_batch_test) in enumerate(test_dataset):\n",
    "            output,at_1,at_2,at_3,at_4,at_5 = model(x_batch_test)\n",
    "            test_loss = loss_fn(y_batch_test,output)\n",
    "            if step == 0:\n",
    "                output_data = output\n",
    "                attn1 = at_1\n",
    "                attn2 = at_2\n",
    "                attn3 = at_3\n",
    "                attn4 = at_4\n",
    "                attn5 = at_5\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , output] , axis = 0)\n",
    "                attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "                attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "                attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "                attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "                attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "            test_loss_list.append(test_loss)\n",
    "        output_array = output_data.numpy()\n",
    "        attn1_array = attn1.numpy()\n",
    "        attn2_array = attn2.numpy()\n",
    "        attn3_array = attn3.numpy()\n",
    "        attn4_array = attn4.numpy()\n",
    "        attn5_array = attn5.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        attn1_array = np.expand_dims(attn1_array,axis = 0)\n",
    "        attn2_array = np.expand_dims(attn2_array,axis = 0)\n",
    "        attn3_array = np.expand_dims(attn3_array,axis = 0)\n",
    "        attn4_array = np.expand_dims(attn4_array,axis = 0)\n",
    "        attn5_array = np.expand_dims(attn5_array,axis = 0)\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "            final_attn1 = attn1_array\n",
    "            final_attn2 = attn2_array\n",
    "            final_attn3 = attn3_array\n",
    "            final_attn4 = attn4_array\n",
    "            final_attn5 = attn5_array\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "            final_attn1 = np.vstack((final_attn1,attn1_array))\n",
    "            final_attn2 = np.vstack((final_attn2,attn2_array))\n",
    "            final_attn3 = np.vstack((final_attn3,attn3_array))\n",
    "            final_attn4 = np.vstack((final_attn4,attn4_array))\n",
    "            final_attn5 = np.vstack((final_attn5,attn5_array))\n",
    "#=================================================================================================================\n",
    "if input_conf == 'confe':\n",
    "    final_output = np.array([])\n",
    "    final_attn1 = np.array([])\n",
    "    final_attn2 = np.array([])\n",
    "    final_attn3 = np.array([])\n",
    "    final_attn4 = np.array([])\n",
    "    final_attn5 = np.array([])\n",
    "    final_attn6 = np.array([])\n",
    "    final_attn7 = np.array([])\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_ATT_MC(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_MONTE/confe/best_model_20.001_0.0001_100.h5')\n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        attn1 = tf.convert_to_tensor([])\n",
    "        attn2 = tf.convert_to_tensor([])\n",
    "        attn3 = tf.convert_to_tensor([])\n",
    "        attn4 = tf.convert_to_tensor([])\n",
    "        attn5 = tf.convert_to_tensor([])\n",
    "        attn6 = tf.convert_to_tensor([])\n",
    "        attn7 = tf.convert_to_tensor([])\n",
    "        for step , (x_batch_test_raw,y_batch_test) in enumerate(test_dataset):\n",
    "            output,at_1,at_2,at_3,at_4,at_5,at_6,at_7 = model(x_batch_test_raw)\n",
    "            test_loss = loss_fn(y_batch_test , output)\n",
    "            if step == 0:\n",
    "                output_data = output\n",
    "                attn1 = at_1\n",
    "                attn2 = at_2\n",
    "                attn3 = at_3\n",
    "                attn4 = at_4\n",
    "                attn5 = at_5\n",
    "                attn6 = at_6\n",
    "                attn7 = at_7\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , output] , axis = 0)\n",
    "                attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "                attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "                attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "                attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "                attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "                attn6 = tf.concat([attn6 , at_6] , axis = 0)\n",
    "                attn7 = tf.concat([attn7 , at_7] , axis = 0)\n",
    "            test_loss_list.append(test_loss)\n",
    "        output_array = output_data.numpy()\n",
    "        attn1_array = attn1.numpy()\n",
    "        attn2_array = attn2.numpy()\n",
    "        attn3_array = attn3.numpy()\n",
    "        attn4_array = attn4.numpy()\n",
    "        attn5_array = attn5.numpy()\n",
    "        attn6_array = attn6.numpy()\n",
    "        attn7_array = attn7.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        attn1_array = np.expand_dims(attn1_array,axis = 0)\n",
    "        attn2_array = np.expand_dims(attn2_array,axis = 0)\n",
    "        attn3_array = np.expand_dims(attn3_array,axis = 0)\n",
    "        attn4_array = np.expand_dims(attn4_array,axis = 0)\n",
    "        attn5_array = np.expand_dims(attn5_array,axis = 0)\n",
    "        attn6_array = np.expand_dims(attn6_array,axis = 0)\n",
    "        attn7_array = np.expand_dims(attn7_array,axis = 0)\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "            final_attn1 = attn1_array\n",
    "            final_attn2 = attn2_array\n",
    "            final_attn3 = attn3_array\n",
    "            final_attn4 = attn4_array\n",
    "            final_attn5 = attn5_array\n",
    "            final_attn6 = attn6_array\n",
    "            final_attn7 = attn7_array\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "            final_attn1 = np.vstack((final_attn1,attn1_array))\n",
    "            final_attn2 = np.vstack((final_attn2,attn2_array))\n",
    "            final_attn3 = np.vstack((final_attn3,attn3_array))\n",
    "            final_attn4 = np.vstack((final_attn4,attn4_array))\n",
    "            final_attn5 = np.vstack((final_attn5,attn5_array))\n",
    "            final_attn6 = np.vstack((final_attn6,attn6_array))\n",
    "            final_attn7 = np.vstack((final_attn7,attn7_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4648dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confb':\n",
    "    final_output = np.array([])\n",
    "    final_attn1 = np.array([])\n",
    "    final_attn2 = np.array([])\n",
    "    final_attn3 = np.array([])\n",
    "    final_attn4 = np.array([])\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Encoder_ATT_MC(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_MONTE/confb/best_model_20.01_1e-05_100.h5')\n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        attn1 = tf.convert_to_tensor([])\n",
    "        attn2 = tf.convert_to_tensor([])\n",
    "        attn3 = tf.convert_to_tensor([])\n",
    "        attn4 = tf.convert_to_tensor([])\n",
    "        for step , (x_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "            output,at_1,at_2,at_3,at_4 = model(x_batch_test)\n",
    "            test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "            if step == 0:\n",
    "                output_data = output\n",
    "                attn1 = at_1\n",
    "                attn2 = at_2\n",
    "                attn3 = at_3\n",
    "                attn4 = at_4\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , output] , axis = 0)\n",
    "                attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "                attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "                attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "                attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "            test_loss_list.append(test_loss)\n",
    "        output_array = output_data.numpy()\n",
    "        attn1_array = attn1.numpy()\n",
    "        attn2_array = attn2.numpy()\n",
    "        attn3_array = attn3.numpy()\n",
    "        attn4_array = attn4.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        attn1_array = np.expand_dims(attn1_array,axis = 0)\n",
    "        attn2_array = np.expand_dims(attn2_array,axis = 0)\n",
    "        attn3_array = np.expand_dims(attn3_array,axis = 0)\n",
    "        attn4_array = np.expand_dims(attn4_array,axis = 0)\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "            final_attn1 = attn1_array\n",
    "            final_attn2 = attn2_array\n",
    "            final_attn3 = attn3_array\n",
    "            final_attn4 = attn4_array\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "            final_attn1 = np.vstack((final_attn1,attn1_array))\n",
    "            final_attn2 = np.vstack((final_attn2,attn2_array))\n",
    "            final_attn3 = np.vstack((final_attn3,attn3_array))\n",
    "            final_attn4 = np.vstack((final_attn4,attn4_array))\n",
    "\n",
    "#==========================================================================================================\n",
    "if input_conf == 'confa':\n",
    "    final_output = np.array([])\n",
    "    final_attn1 = np.array([])\n",
    "    final_attn2 = np.array([])\n",
    "    final_attn3 = np.array([])\n",
    "    final_attn4 = np.array([])\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_encoder_ATT_MC(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_MONTE/confa/best_model_20.01_1e-05_100.h5')\n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        attn1 = tf.convert_to_tensor([])\n",
    "        attn2 = tf.convert_to_tensor([])\n",
    "        attn3 = tf.convert_to_tensor([])\n",
    "        attn4 = tf.convert_to_tensor([])\n",
    "        for step , (x_batch_test_raw, x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "            output,at_1,at_2,at_3,at_4 = model(x_batch_test_raw)\n",
    "            test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "            if step == 0:\n",
    "                output_data = output\n",
    "                attn1 = at_1\n",
    "                attn2 = at_2\n",
    "                attn3 = at_3\n",
    "                attn4 = at_4\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , output] , axis = 0)\n",
    "                attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "                attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "                attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "                attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "            test_loss_list.append(test_loss)  \n",
    "        output_array = output_data.numpy()\n",
    "        attn1_array = attn1.numpy()\n",
    "        attn2_array = attn2.numpy()\n",
    "        attn3_array = attn3.numpy()\n",
    "        attn4_array = attn4.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        attn1_array = np.expand_dims(attn1_array,axis = 0)\n",
    "        attn2_array = np.expand_dims(attn2_array,axis = 0)\n",
    "        attn3_array = np.expand_dims(attn3_array,axis = 0)\n",
    "        attn4_array = np.expand_dims(attn4_array,axis = 0)\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "            final_attn1 = attn1_array\n",
    "            final_attn2 = attn2_array\n",
    "            final_attn3 = attn3_array\n",
    "            final_attn4 = attn4_array\n",
    "            \n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "            final_attn1 = np.vstack((final_attn1,attn1_array))\n",
    "            final_attn2 = np.vstack((final_attn2,attn2_array))\n",
    "            final_attn3 = np.vstack((final_attn3,attn3_array))\n",
    "            final_attn4 = np.vstack((final_attn4,attn4_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confd':\n",
    "    final_output = np.array([])\n",
    "    final_output_rr = np.array([])\n",
    "    final_attn1 = np.array([])\n",
    "    final_attn2 = np.array([])\n",
    "    final_attn3 = np.array([])\n",
    "    final_attn4 = np.array([])\n",
    "    final_attn5 = np.array([])\n",
    "    final_attn6 = np.array([])\n",
    "    final_attn7 = np.array([])\n",
    "    final_attn8 = np.array([])\n",
    "    final_attn9 = np.array([])\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Multi_resp_ATT_MC(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_MONTE/confd/best_model_20.01_1e-05_100.h5')\n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        output_data_rr = tf.convert_to_tensor([])\n",
    "        attn1 = tf.convert_to_tensor([])\n",
    "        attn2 = tf.convert_to_tensor([])\n",
    "        attn3 = tf.convert_to_tensor([])\n",
    "        attn4 = tf.convert_to_tensor([])\n",
    "        attn5 = tf.convert_to_tensor([])\n",
    "        attn6 = tf.convert_to_tensor([])\n",
    "        attn7 = tf.convert_to_tensor([])\n",
    "        attn8 = tf.convert_to_tensor([])\n",
    "        attn9 = tf.convert_to_tensor([])\n",
    "        for step , (x_batch_test,y_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "            test_output,test_out_rr,at_1,at_2,at_3,at_4,at_5,at_6,at_7,at_8,at_9 = model(x_batch_test)\n",
    "            test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "            test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "            test_loss = test_loss_resp + test_loss_rr\n",
    "            if step == 0:\n",
    "                output_data = test_output\n",
    "                output_data_rr = test_out_rr\n",
    "                attn1 = at_1\n",
    "                attn2 = at_2\n",
    "                attn3 = at_3\n",
    "                attn4 = at_4\n",
    "                attn5 = at_5\n",
    "                attn6 = at_6\n",
    "                attn7 = at_7\n",
    "                attn8 = at_8\n",
    "                attn9 = at_9\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , test_output] , axis = 0)\n",
    "                output_data_rr = tf.concat([output_data_rr , test_out_rr] , axis = 0)\n",
    "                attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "                attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "                attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "                attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "                attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "                attn6 = tf.concat([attn6 , at_6] , axis = 0)\n",
    "                attn7 = tf.concat([attn7 , at_7] , axis = 0)\n",
    "                attn8 = tf.concat([attn8 , at_8] , axis = 0)\n",
    "                attn9 = tf.concat([attn9 , at_9] , axis = 0)\n",
    "            test_loss_list.append(test_loss)\n",
    "        output_array = output_data.numpy()\n",
    "        output_array_rr = output_data_rr.numpy()\n",
    "        attn1_array = attn1.numpy()\n",
    "        attn2_array = attn2.numpy()\n",
    "        attn3_array = attn3.numpy()\n",
    "        attn4_array = attn4.numpy()\n",
    "        attn5_array = attn5.numpy()\n",
    "        attn6_array = attn6.numpy()\n",
    "        attn7_array = attn7.numpy()\n",
    "        attn8_array = attn8.numpy()\n",
    "        attn9_array = attn9.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        output_array_rr = output_array_rr.reshape(output_array_rr.shape[-1],output_array_rr.shape[0],output_array_rr.shape[1])\n",
    "        attn1_array = np.expand_dims(attn1_array,axis = 0)\n",
    "        attn2_array = np.expand_dims(attn2_array,axis = 0)\n",
    "        attn3_array = np.expand_dims(attn3_array,axis = 0)\n",
    "        attn4_array = np.expand_dims(attn4_array,axis = 0)\n",
    "        attn5_array = np.expand_dims(attn5_array,axis = 0)\n",
    "        attn6_array = np.expand_dims(attn6_array,axis = 0)\n",
    "        attn7_array = np.expand_dims(attn7_array,axis = 0)\n",
    "        attn8_array = np.expand_dims(attn8_array,axis = 0)\n",
    "        attn9_array = np.expand_dims(attn9_array,axis = 0)\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "            final_output_rr = output_array_rr\n",
    "            final_attn1 = attn1_array\n",
    "            final_attn2 = attn2_array\n",
    "            final_attn3 = attn3_array\n",
    "            final_attn4 = attn4_array\n",
    "            final_attn5 = attn5_array\n",
    "            final_attn6 = attn6_array\n",
    "            final_attn7 = attn7_array\n",
    "            final_attn8 = attn8_array\n",
    "            final_attn9 = attn9_array\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "            final_output_rr = np.vstack((final_output_rr,output_array_rr))\n",
    "            final_attn1 = np.vstack((final_attn1,attn1_array))\n",
    "            final_attn2 = np.vstack((final_attn2,attn2_array))\n",
    "            final_attn3 = np.vstack((final_attn3,attn3_array))\n",
    "            final_attn4 = np.vstack((final_attn4,attn4_array))\n",
    "            final_attn5 = np.vstack((final_attn5,attn5_array))\n",
    "            final_attn6 = np.vstack((final_attn6,attn6_array))\n",
    "            final_attn7 = np.vstack((final_attn7,attn7_array))\n",
    "            final_attn8 = np.vstack((final_attn8,attn8_array))\n",
    "            final_attn9 = np.vstack((final_attn9,attn9_array))\n",
    "            \n",
    "#=================================================================================================================\n",
    "if input_conf == 'conff':\n",
    "    final_output = np.array([])\n",
    "    final_output_rr = np.array([])\n",
    "    final_attn1 = np.array([])\n",
    "    final_attn2 = np.array([])\n",
    "    final_attn3 = np.array([])\n",
    "    final_attn4 = np.array([])\n",
    "    final_attn5 = np.array([])\n",
    "    final_attn6 = np.array([])\n",
    "    final_attn7 = np.array([])\n",
    "    final_attn8 = np.array([])\n",
    "    final_attn9 = np.array([])\n",
    "    final_attn10 = np.array([])\n",
    "    final_attn11 = np.array([])\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_multi_ATT_MC(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_MONTE/conff/best_model_10.0001_0.0001_100.h5') \n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        output_data_rr = tf.convert_to_tensor([])\n",
    "        attn1 = tf.convert_to_tensor([])\n",
    "        attn2 = tf.convert_to_tensor([])\n",
    "        attn3 = tf.convert_to_tensor([])\n",
    "        attn4 = tf.convert_to_tensor([])\n",
    "        attn5 = tf.convert_to_tensor([])\n",
    "        attn6 = tf.convert_to_tensor([])\n",
    "        attn7 = tf.convert_to_tensor([])\n",
    "        attn8 = tf.convert_to_tensor([])\n",
    "        attn9 = tf.convert_to_tensor([])\n",
    "        attn10 = tf.convert_to_tensor([])\n",
    "        attn11 = tf.convert_to_tensor([])\n",
    "        for step , (x_batch_test_raw , y_batch_test , x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "            test_output,test_out_rr,at_1,at_2,at_3,at_4,at_5,at_6,at_7,at_8,at_9,at_10,at_11 = model(x_batch_test_raw)\n",
    "            test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "            test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "            test_loss = test_loss_resp + test_loss_rr\n",
    "            if step == 0:\n",
    "                output_data = test_output\n",
    "                output_data_rr = test_out_rr\n",
    "                attn1 = at_1\n",
    "                attn2 = at_2\n",
    "                attn3 = at_3\n",
    "                attn4 = at_4\n",
    "                attn5 = at_5\n",
    "                attn6 = at_6\n",
    "                attn7 = at_7\n",
    "                attn8 = at_8\n",
    "                attn9 = at_9\n",
    "                attn10 = at_10\n",
    "                attn11 = at_11\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , test_output] , axis = 0)\n",
    "                output_data_rr = tf.concat([output_data_rr , test_out_rr] , axis = 0)\n",
    "                attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "                attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "                attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "                attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "                attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "                attn6 = tf.concat([attn6 , at_6] , axis = 0)\n",
    "                attn7 = tf.concat([attn7 , at_7] , axis = 0)\n",
    "                attn8 = tf.concat([attn8 , at_8] , axis = 0)\n",
    "                attn9 = tf.concat([attn9 , at_9] , axis = 0)\n",
    "                attn10 = tf.concat([attn10 , at_10] , axis = 0)\n",
    "                attn11 = tf.concat([attn11 , at_11] , axis = 0)\n",
    "            test_loss_list.append(test_loss)\n",
    "        output_array = output_data.numpy()\n",
    "        output_array_rr = output_data_rr.numpy()\n",
    "        attn1_array = attn1.numpy()\n",
    "        attn2_array = attn2.numpy()\n",
    "        attn3_array = attn3.numpy()\n",
    "        attn4_array = attn4.numpy()\n",
    "        attn5_array = attn5.numpy()\n",
    "        attn6_array = attn6.numpy()\n",
    "        attn7_array = attn7.numpy()\n",
    "        attn8_array = attn8.numpy()\n",
    "        attn9_array = attn9.numpy()\n",
    "        attn10_array = attn10.numpy()\n",
    "        attn11_array = attn11.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        output_array_rr = output_array_rr.reshape(output_array_rr.shape[-1],output_array_rr.shape[0],output_array_rr.shape[1])\n",
    "        attn1_array = np.expand_dims(attn1_array,axis = 0)\n",
    "        attn2_array = np.expand_dims(attn2_array,axis = 0)\n",
    "        attn3_array = np.expand_dims(attn3_array,axis = 0)\n",
    "        attn4_array = np.expand_dims(attn4_array,axis = 0)\n",
    "        attn5_array = np.expand_dims(attn5_array,axis = 0)\n",
    "        attn6_array = np.expand_dims(attn6_array,axis = 0)\n",
    "        attn7_array = np.expand_dims(attn7_array,axis = 0)\n",
    "        attn8_array = np.expand_dims(attn8_array,axis = 0)\n",
    "        attn9_array = np.expand_dims(attn9_array,axis = 0)\n",
    "        attn10_array = np.expand_dims(attn10_array,axis = 0)\n",
    "        attn11_array = np.expand_dims(attn11_array,axis = 0)\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "            final_output_rr = output_array_rr\n",
    "            final_attn1 = attn1_array\n",
    "            final_attn2 = attn2_array\n",
    "            final_attn3 = attn3_array\n",
    "            final_attn4 = attn4_array\n",
    "            final_attn5 = attn5_array\n",
    "            final_attn6 = attn6_array\n",
    "            final_attn7 = attn7_array\n",
    "            final_attn8 = attn8_array\n",
    "            final_attn9 = attn9_array\n",
    "            final_attn10 = attn10_array\n",
    "            final_attn11 = attn11_array\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "            final_output_rr = np.vstack((final_output_rr,output_array_rr))\n",
    "            final_attn1 = np.vstack((final_attn1,attn1_array))\n",
    "            final_attn2 = np.vstack((final_attn2,attn2_array))\n",
    "            final_attn3 = np.vstack((final_attn3,attn3_array))\n",
    "            final_attn4 = np.vstack((final_attn4,attn4_array))\n",
    "            final_attn5 = np.vstack((final_attn5,attn5_array))\n",
    "            final_attn6 = np.vstack((final_attn6,attn6_array))\n",
    "            final_attn7 = np.vstack((final_attn7,attn7_array))\n",
    "            final_attn8 = np.vstack((final_attn8,attn8_array))\n",
    "            final_attn9 = np.vstack((final_attn9,attn9_array))\n",
    "            final_attn10 = np.vstack((final_attn10,attn10_array))\n",
    "            final_attn11 = np.vstack((final_attn11,attn11_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34fc72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f002c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    #l = 0.1\n",
    "    #drop_prob = 0.1\n",
    "    #lam = 0.0001\n",
    "    \n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_attn1_output = np.mean(final_attn1 , axis = 0)\n",
    "    final_attn2_output = np.mean(final_attn2 , axis = 0)\n",
    "    final_attn3_output = np.mean(final_attn3 , axis = 0)\n",
    "    final_attn4_output = np.mean(final_attn4 , axis = 0)\n",
    "    final_attn5_output = np.mean(final_attn5 , axis = 0)\n",
    "    \n",
    "    final_output_resp = np.mean(final_output , axis = 0)\n",
    "    final_var = np.var(final_output , axis = 0)\n",
    "    avg_final_var = np.mean(final_var , axis = 1)\n",
    "    #tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    #final_var += (tau**-1)\n",
    "    output_copy = final_output_resp\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    avg_std_dev = np.sqrt(avg_final_var).reshape(-1,1)\n",
    "    #final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "\n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    samples = np.arange(0,len(avg_breaths)).reshape(-1,1)\n",
    "    confc_data = np.hstack((samples, avg_std_dev, error_avg_breaths, error_inst_breaths))\n",
    "    col_confc = ['Samples','Uncertainty', 'Error Avg Breath(BrPM)','Error Inst Breath(BrPM)']\n",
    "    data_confc = pd.DataFrame(confc_data , columns = col_confc)\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "#===============================================================================================================\n",
    "\n",
    "if input_conf == 'confe':\n",
    "    #l = 1\n",
    "    #drop_prob = 0.1\n",
    "    #lam = 0.0001\n",
    "    \n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_attn1_output = np.mean(final_attn1 , axis = 0)\n",
    "    final_attn2_output = np.mean(final_attn2 , axis = 0)\n",
    "    final_attn3_output = np.mean(final_attn3 , axis = 0)\n",
    "    final_attn4_output = np.mean(final_attn4 , axis = 0)\n",
    "    final_attn5_output = np.mean(final_attn5 , axis = 0)\n",
    "    final_attn6_output = np.mean(final_attn6 , axis = 0)\n",
    "    final_attn7_output = np.mean(final_attn7 , axis = 0)\n",
    "    \n",
    "    final_output_resp = np.mean(final_output , axis = 0)\n",
    "    final_var = np.var(final_output , axis = 0)\n",
    "    avg_final_var = np.mean(final_var , axis = 1)\n",
    "    #print(final_var)\n",
    "    #tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    #final_var += (tau**-1)\n",
    "    \n",
    "    output_copy = final_output_resp\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    avg_std_dev = np.sqrt(avg_final_var).reshape(-1,1)\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    samples = np.arange(0,len(avg_breaths)).reshape(-1,1)\n",
    "    confe_data = np.hstack((samples, avg_std_dev, error_avg_breaths, error_inst_breaths))\n",
    "    col_confe = ['Samples','Uncertainty', 'Error Avg Breath(BrPM)','Error Inst Breath(BrPM)']\n",
    "    data_confe = pd.DataFrame(confe_data , columns = col_confe)\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff4fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0971c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confb':\n",
    "    #l = 0.01\n",
    "    #drop_prob = 0.1\n",
    "    #lam = 0.0001\n",
    "    \n",
    "    final_attn1_output = np.mean(final_attn1 , axis = 0)\n",
    "    final_attn2_output = np.mean(final_attn2 , axis = 0)\n",
    "    final_attn3_output = np.mean(final_attn3 , axis = 0)\n",
    "    final_attn4_output = np.mean(final_attn4 , axis = 0)\n",
    "    \n",
    "    final_output_rr = np.mean(final_output , axis = 0)\n",
    "    final_var = np.var(final_output , axis = 0)\n",
    "    #tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    #final_var += (tau**-1)\n",
    "    output_copy = final_output_rr\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    #final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "    \n",
    "    samples = np.arange(0,len(final_output_rr)).reshape(-1,1)\n",
    "    confb_data = np.hstack((samples,final_output_rr , std_dev, error))\n",
    "    col_confb = ['Samples','Final RR Output (BrPM)' , 'Uncertainty', 'Absolute Error (BrPM)']\n",
    "    data_confb = pd.DataFrame(confb_data , columns = col_confb)\n",
    "\n",
    "#=====================================================================================================================\n",
    "if input_conf == 'confa':\n",
    "    #l = 0.01\n",
    "    #drop_prob = 0.1\n",
    "    #lam = 0.0001\n",
    "    \n",
    "    final_attn1_output = np.mean(final_attn1 , axis = 0)\n",
    "    final_attn2_output = np.mean(final_attn2 , axis = 0)\n",
    "    final_attn3_output = np.mean(final_attn3 , axis = 0)\n",
    "    final_attn4_output = np.mean(final_attn4 , axis = 0)\n",
    "    \n",
    "    final_output_rr = np.mean(final_output , axis = 0)\n",
    "    final_var = np.var(final_output , axis = 0)\n",
    "    #tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    #final_var += (tau**-1)\n",
    "    output_copy = final_output_rr\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    #final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "    \n",
    "    samples = np.arange(0,len(final_output_rr)).reshape(-1,1)\n",
    "    confa_data = np.hstack((samples,final_output_rr ,std_dev ,error))\n",
    "    col_confa = ['Samples','Final RR Output (BrPM)' ,'Uncertainty','Absolute Error (BrPM)']\n",
    "    data_confa = pd.DataFrame(confa_data , columns = col_confa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7190ef52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfce84d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if input_conf == 'confd':\n",
    "    #l = 0.1\n",
    "    #drop_prob = 0.1\n",
    "    #lam = 0.0001\n",
    "    \n",
    "    #l_rr = 0.01\n",
    "    #drop_prob_rr = 0.1\n",
    "    #lam_rr = 0.0001\n",
    "    \n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_attn1_output = np.mean(final_attn1 , axis = 0)\n",
    "    final_attn2_output = np.mean(final_attn2 , axis = 0)\n",
    "    final_attn3_output = np.mean(final_attn3 , axis = 0)\n",
    "    final_attn4_output = np.mean(final_attn4 , axis = 0)\n",
    "    final_attn5_output = np.mean(final_attn5 , axis = 0)\n",
    "    final_attn6_output = np.mean(final_attn6 , axis = 0)\n",
    "    final_attn7_output = np.mean(final_attn7 , axis = 0)\n",
    "    final_attn8_output = np.mean(final_attn8 , axis = 0)\n",
    "    final_attn9_output = np.mean(final_attn9 , axis = 0)\n",
    "    \n",
    "    final_output_resp = np.mean(final_output,axis = 0)\n",
    "    final_rr = np.mean(final_output_rr,axis = 0)\n",
    "    #tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    #tau_rr = (l_rr**2) * (1-drop_prob_rr) / (2. * lam_rr)\n",
    "    \n",
    "    final_var = np.var(final_output,axis = 0)\n",
    "    final_var_rr = np.var(final_output_rr,axis = 0)\n",
    "    #final_var += (tau**-1)\n",
    "    #final_var_rr += (tau_rr**-1)\n",
    "    output_copy = final_output_resp\n",
    "    output_copy_rr = final_rr\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    std_dev_rr = np.sqrt(final_var_rr)\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    samples = np.arange(0,len(final_rr)).reshape(-1,1)\n",
    "    confd_data = np.hstack((samples,final_rr , std_dev_rr,error_avg_breaths, error_inst_breaths))\n",
    "    col_confd = ['Samples','Final RR Output (BrPM)' , 'Uncertainty', 'Error Avg Breath(BrPM)','Error Inst Breath(BrPM)']\n",
    "    data_confd = pd.DataFrame(confd_data , columns = col_confd)\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "    \n",
    "#===================================================================================================================\n",
    "if input_conf == 'conff':\n",
    "    #l = 1\n",
    "    #drop_prob = 0.1\n",
    "    #lam = 0.0001\n",
    "    \n",
    "    #l_rr = 0.01\n",
    "    #drop_prob_rr = 0.1\n",
    "    #lam_rr = 0.0001\n",
    "    \n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_attn1_output = np.mean(final_attn1 , axis = 0)\n",
    "    final_attn2_output = np.mean(final_attn2 , axis = 0)\n",
    "    final_attn3_output = np.mean(final_attn3 , axis = 0)\n",
    "    final_attn4_output = np.mean(final_attn4 , axis = 0)\n",
    "    final_attn5_output = np.mean(final_attn5 , axis = 0)\n",
    "    final_attn6_output = np.mean(final_attn6 , axis = 0)\n",
    "    final_attn7_output = np.mean(final_attn7 , axis = 0)\n",
    "    final_attn8_output = np.mean(final_attn8 , axis = 0)\n",
    "    final_attn9_output = np.mean(final_attn9 , axis = 0)\n",
    "    final_attn10_output = np.mean(final_attn10 , axis = 0)\n",
    "    final_attn11_output = np.mean(final_attn11 , axis = 0)\n",
    "    \n",
    "    final_output_resp = np.mean(final_output,axis = 0)\n",
    "    final_rr = np.mean(final_output_rr,axis = 0)\n",
    "    #tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    #tau_rr = (l_rr**2) * (1-drop_prob_rr) / (2. * lam_rr)\n",
    "    final_var = np.var(final_output,axis = 0)\n",
    "    final_var_rr = np.var(final_output_rr,axis = 0)\n",
    "    #final_var += (tau**-1)\n",
    "    #final_var_rr += (tau_rr**-1)\n",
    "    output_copy = final_output_resp\n",
    "    output_copy_rr = final_rr\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    std_dev_rr = np.sqrt(final_var_rr)\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    samples = np.arange(0,len(final_rr)).reshape(-1,1)\n",
    "    conff_data = np.hstack((samples,final_rr , std_dev_rr, error_avg_breaths, error_inst_breaths))\n",
    "    col_conff = ['Samples','Final RR Output (BrPM)' , 'Uncertainty', 'Error Avg Breath(BrPM)','Error Inst Breath(BrPM)']\n",
    "    data_conff = pd.DataFrame(conff_data , columns = col_conff)\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2b28b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82703f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc' or input_conf == 'confe' or input_conf == 'confd' or input_conf == 'conff':\n",
    "    no_of_samples = 32*4\n",
    "    x_unc = np.linspace(start = 0,stop = no_of_samples, num = no_of_samples)\n",
    "    layout_epistemic = go.Layout(\n",
    "    title = \"Respiratory Waveform with Epistemic Uncertainty for \"+ input_conf.upper(),\n",
    "    yaxis = dict(\n",
    "        title = 'Output Respiration Signal' \n",
    "    ),\n",
    "    xaxis = dict(\n",
    "        title = 'samples'\n",
    "    )\n",
    "    )\n",
    "    def update_plot(signals):\n",
    "        data = []\n",
    "            # Reference ECG trace\n",
    "        trace_epistemic = go.Scatter(\n",
    "            x = x_unc,\n",
    "            y = final_output_resp_sig[signals], \n",
    "            mode = 'lines',\n",
    "            name = 'Respiration with Epistemic',\n",
    "                    line = dict(\n",
    "                    shape = 'spline',\n",
    "                    color = 'red',\n",
    "                    width = 5\n",
    "                     ),\n",
    "                error_y=dict(\n",
    "                    type='data', # value of error bar given in data coordinates\n",
    "                    array=final_var[signals],\n",
    "                    visible=True,\n",
    "                    color='black',\n",
    "                thickness=3,\n",
    "                width=5)\n",
    "                )\n",
    "        fig_epistemic = go.Figure(data = [trace_epistemic],layout = layout_epistemic)\n",
    "        py.offline.iplot(fig_epistemic)\n",
    "signals_epsitemic = widgets.IntSlider(min = 0,max = len(final_output_resp_sig), value = 0, description = 'Record_no:')\n",
    "widgets.interactive(update_plot, signals = signals_epsitemic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6cf7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confb':\n",
    "    fig1 = px.scatter(data_confb,x = 'Samples', y=\"Absolute Error (BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper(),\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis,size='Uncertainty')\n",
    "    fig1.show()\n",
    "\n",
    "if input_conf == 'confa':\n",
    "    fig1 = px.scatter(data_confa,x = 'Samples', y=\"Absolute Error (BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper(),\n",
    "                   color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    fig1.show()\n",
    "\n",
    "if input_conf == 'confd':\n",
    "    fig1 = px.scatter(data_confd,x = 'Samples', y=\"Error Avg Breath(BrPM)\",title=\"Uncertainty Distribution for \"+input_conf.upper()+ \" for average RR error\" ,\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis,size='Uncertainty')\n",
    "    \n",
    "    fig2 = px.scatter(data_confd,x = 'Samples', y=\"Error Inst Breath(BrPM)\",title=\"Uncertainty Distribution for \"+input_conf.upper()+ \" for instantaneous RR error\" ,\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis,size='Uncertainty')\n",
    "    fig1.show()\n",
    "    fig2.show()\n",
    "     \n",
    "\n",
    "if input_conf == 'conff':\n",
    "    fig1 = px.scatter(data_conff,x = 'Samples', y=\"Error Avg Breath(BrPM)\",title=\"Uncertainty Distribution for \"+input_conf.upper()+ \" for average RR error\" ,\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis,size='Uncertainty')\n",
    "    \n",
    "    fig2 = px.scatter(data_conff,x = 'Samples', y=\"Error Inst Breath(BrPM)\",title=\"Uncertainty Distribution for \"+input_conf.upper()+ \" for instantaneous RR error\" ,\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis,size='Uncertainty')\n",
    "    fig1.show()\n",
    "    fig2.show()\n",
    "    \n",
    "if input_conf == 'confc':\n",
    "    fig1 = px.scatter(data_confc,x = 'Samples', y=\"Error Avg Breath(BrPM)\",title=\"Uncertainty Distribution for \"+input_conf.upper()+ \" for average RR error\" ,\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    \n",
    "    fig2 = px.scatter(data_confc,x = 'Samples', y=\"Error Inst Breath(BrPM)\",title=\"Uncertainty Distribution for \"+input_conf.upper()+ \" for instantaneous RR error\" ,\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    fig1.show()\n",
    "    fig2.show()\n",
    "    \n",
    "if input_conf == 'confe':\n",
    "    fig1 = px.scatter(data_confe,x = 'Samples', y=\"Error Avg Breath(BrPM)\",title=\"Uncertainty Distribution for \"+input_conf.upper()+ \" for average RR error\" ,\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    \n",
    "    fig2 = px.scatter(data_confe,x = 'Samples', y=\"Error Inst Breath(BrPM)\",title=\"Uncertainty Distribution for \"+input_conf.upper()+ \" for instantaneous RR error\" ,\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    fig1.show()\n",
    "    fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confd' or input_conf == 'conff':\n",
    "    if input_conf == 'confd':\n",
    "        high_unc_index = np.where(std_dev_rr>0.6)\n",
    "    elif input_conf == 'conff':\n",
    "        high_unc_index = np.where(std_dev_rr>1.0)        \n",
    "    for item in high_unc_index[0]:\n",
    "        error_avg_breaths[item] = 0\n",
    "        error_inst_breaths[item] = 0\n",
    "    mae_avg_new = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath_new = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    mae_inst_new = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath_new = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_new))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath_new))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_new))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath_new))\n",
    "\n",
    "if input_conf == 'confb':\n",
    "    high_unc_index = np.where(std_dev>0.8)\n",
    "    for item in high_unc_index[0]:\n",
    "        error[item] = 0\n",
    "    mae_avg_new = np.mean(error)\n",
    "    rmse_avg_breath_new = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_new))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath_new))\n",
    "    \n",
    "if input_conf == 'confa':\n",
    "    high_unc_index = np.where(std_dev>0.7)\n",
    "    for item in high_unc_index[0]:\n",
    "        error[item] = 0\n",
    "    mae_avg_new = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath_new = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_new))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath_new))\n",
    "    \n",
    "if input_conf == 'confc' or input_conf == 'conf':\n",
    "    high_unc_index = np.where(avg_std_dev>0.155)\n",
    "    for item in high_unc_index[0]:\n",
    "        error_avg_breaths[item] = 0\n",
    "        error_inst_breaths[item] = 0\n",
    "    mae_avg_new = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath_new = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    mae_inst_new = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath_new = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_new))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath_new))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_new))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9dc017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47164ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu25",
   "language": "python",
   "name": "tf_gpu25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
