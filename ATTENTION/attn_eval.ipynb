{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee4cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "SEED = 0\n",
    "#------------------------------------------------------------------------------------\n",
    "def set_seeds(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "#------------------------------------------------------------------------------------\n",
    "def set_global_determinism(seed=SEED):\n",
    "    set_seeds(seed=seed)\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    \n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Call the above function with seed value\n",
    "set_global_determinism(seed=SEED)\n",
    "#-----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7187b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.4.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "from data_extraction import *\n",
    "from resp_signal_extraction import *\n",
    "from rr_extration import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "import pickle as pkl\n",
    "from tf_model import *\n",
    "from tf_model_new import *\n",
    "from tf_model_evi import *\n",
    "from tf_model_attn_monte import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber\n",
    "import matplotlib.pyplot as plt\n",
    "from filters import *\n",
    "import tqdm\n",
    "import plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import ipywidgets as widgets\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "py.offline.init_notebook_mode(connected = True)\n",
    "from plotly import tools\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d514e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_conf = 'confd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ce9b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:43:47.491683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 19:43:47.496882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 19:43:47.497240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 19:43:47.522270: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-17 19:43:47.522402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 19:43:47.522707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 19:43:47.522998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 19:43:47.843825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 19:43:47.844181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 19:43:47.844488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 19:43:47.844770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10228 MB memory:  -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "with open('output','rb') as f:\n",
    "    output_data = pkl.load(f)\n",
    "\n",
    "with open('input','rb') as f:\n",
    "    input_data = pkl.load(f)\n",
    "\n",
    "with open('raw_signal.pkl','rb') as f:\n",
    "    raw_data = pkl.load(f)\n",
    "\n",
    "input_data = np.transpose(input_data, (0,2,1))\n",
    "raw_data = np.transpose(raw_data, (0,2,1))\n",
    "annotation = pd.read_pickle('/media/acrophase/pose1/charan/BR_Uncertainty/MONTE_CARLO/annotation.pkl')\n",
    "reference_rr = (annotation['Reference_RR'].values).reshape(-1,1)\n",
    "\n",
    "input_data = np.around(input_data , decimals = 4)\n",
    "raw_data = np.around(raw_data , decimals = 4)\n",
    "output_data = np.around(output_data , decimals = 4)\n",
    "reference_rr = np.around(reference_rr , decimals = 4)\n",
    "\n",
    "tensor_input = tf.convert_to_tensor(input_data, dtype = 'float32')\n",
    "tensor_output = tf.convert_to_tensor(output_data, dtype = 'float32')\n",
    "tensor_ref_rr = tf.convert_to_tensor(reference_rr, dtype = 'float32')\n",
    "tensor_raw_data = tf.convert_to_tensor(raw_data, dtype = 'float32')\n",
    "training_ids = annotation['patient_id'] < 13\n",
    "\n",
    "x_train_data = tensor_input[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_data = tensor_input[tf.convert_to_tensor(~(training_ids.values))]\n",
    "x_train_ref_rr = tensor_ref_rr[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_ref_rr = tensor_ref_rr[tf.convert_to_tensor(~(training_ids.values))]\n",
    "x_train_raw_sig = tensor_raw_data[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_raw_sig = tensor_raw_data[tf.convert_to_tensor(~(training_ids.values))]\n",
    "\n",
    "y_train_data = tensor_output[tf.convert_to_tensor(training_ids.values)]\n",
    "y_test_data = tensor_output[tf.convert_to_tensor(~(training_ids.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba8152e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , y_train_data))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , y_test_data))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confb':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confd':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , y_train_data, x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , y_test_data, x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "if input_conf == 'confa':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_raw_sig)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confe':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , y_train_data))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_raw_sig)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , y_test_data))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "if input_conf == 'conff':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , y_train_data, x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , y_test_data, x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cf31ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:43:48.731424: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8202\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confc':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_WO_ATT/confc/best_model_0.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,y_batch_test) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = loss_fn(y_batch_test , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "        \n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confd':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Multi_resp(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_WO_ATT/confd/best_model_10.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,y_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr = model(x_batch_test)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "            \n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confb':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Encoder(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_WO_ATT/confb/best_model_10.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confe':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_WO_ATT/confe/best_model_20.001_0.0001_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw,y_batch_test) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(y_batch_test , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "        \n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confa':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_encoder(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_WO_ATT/confa/best_model_10.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw, x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_multi(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_WO_ATT/conff/best_model_0.0001_0.0001_100.h5')        \n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw , y_batch_test , x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr = model(x_batch_test_raw)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a54eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extremas_extraction(signal):\n",
    "    avg_breath_duration = np.array([])\n",
    "    extrema_relevent = []\n",
    "    for item in signal:\n",
    "        amplitude = np.array([])\n",
    "        pos_peaks , _ = scipy.signal.find_peaks(item , height = [-3000,3000])\n",
    "        neg_peaks , _ = scipy.signal.find_peaks(-1*item , height = [-3000 , 3000])\n",
    "        extremas = np.concatenate((pos_peaks , neg_peaks))\n",
    "        extremas = np.sort(extremas)\n",
    "        for i in range(len(extremas)):\n",
    "            amplitude = np.append(amplitude , item[int(extremas[i])])\n",
    "        amplitude_diff = np.abs(np.diff(amplitude))\n",
    "        q3 = np.percentile(amplitude_diff , 75)\n",
    "        threshold = 0.3*q3\n",
    "        eliminate_pairs_of_extrema = 1\n",
    "        while(eliminate_pairs_of_extrema):\n",
    "            amps = np.array([])\n",
    "            if len(extremas)<3:\n",
    "                eliminate_pairs_of_extrema = 0\n",
    "                continue\n",
    "            for i in range(len(extremas)):\n",
    "                amps = np.append(amps , item[int(extremas[i])])\n",
    "            amp_diff = np.abs(np.diff(amps)) \n",
    "            min_amp_diff , index = min(amp_diff) , np.argmin(amp_diff)\n",
    "            #print(min_amp_diff)\n",
    "            if min_amp_diff > threshold:\n",
    "                eliminate_pairs_of_extrema = 0\n",
    "                #extrema_relevent = extremas\n",
    "            else:\n",
    "                extremas = np.concatenate((extremas[0:index] , extremas[index+2 :]))\n",
    "                #amplitude_diff = np.delete(amplitude_diff , index)\n",
    "        if item[int(extremas[0])] < item[int(extremas[1])]:\n",
    "            extremas = extremas[1:]\n",
    "        if item[int(extremas[-1])] < item[int(extremas[-2])]:\n",
    "            extremas = extremas[:-1]\n",
    "        no_of_breaths = (len(extremas)-1)/2\n",
    "        breath_duration = extremas[-1] - extremas[0]\n",
    "        avg_breath_duration = np.append(avg_breath_duration , breath_duration/no_of_breaths)\n",
    "        extrema_relevent.append(extremas)\n",
    "    return avg_breath_duration , extrema_relevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ed826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sig = y_test_data.numpy()\n",
    "fbpB , fbpA = band_pass(0.1,0.7,8)\n",
    "final_ref_resp_sig = []\n",
    "for item in ref_sig:\n",
    "    final_ref_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "final_ref_resp_sig = np.array(final_ref_resp_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd65665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confa':\n",
    "    final_output_rr = final_output.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "#----------------------------------------------------------------------------------------------------------------   \n",
    "if input_conf == 'confb':\n",
    "    final_output_rr = final_output.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf585261",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "\n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------    \n",
    "if input_conf == 'confe':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50b3cc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error average wise for confd is: 2.3428448776869613\n",
      "Root Mean Square Error average wise for confd is: 2.9311694180716006\n",
      "Mean Absolute Error instantaneous wise for confd is: 3.3860862382415107\n",
      "Root Mean Square Error instantaneous wise for confd is: 4.233973503910626\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confd':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_rr = final_output_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_rr = final_output_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3938e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89eb3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f56aa9a",
   "metadata": {},
   "source": [
    "# WITH ATTENTION BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f2067fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_ATT(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODELS_WITH_ATT/confc/best_model_10.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    attn1 = tf.convert_to_tensor([])\n",
    "    attn2 = tf.convert_to_tensor([])\n",
    "    attn3 = tf.convert_to_tensor([])\n",
    "    attn4 = tf.convert_to_tensor([])\n",
    "    attn5 = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,y_batch_test) in enumerate(test_dataset):\n",
    "        output,at_1,at_2,at_3,at_4,at_5 = model(x_batch_test)\n",
    "        test_loss = loss_fn(y_batch_test , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "            attn1 = at_1\n",
    "            attn2 = at_2\n",
    "            attn3 = at_3\n",
    "            attn4 = at_4\n",
    "            attn5 = at_5\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "            attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "        \n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confd':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Multi_resp_ATT(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODELS_WITH_ATT/confd/best_model_0.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    attn1 = tf.convert_to_tensor([])\n",
    "    attn2 = tf.convert_to_tensor([])\n",
    "    attn3 = tf.convert_to_tensor([])\n",
    "    attn4 = tf.convert_to_tensor([])\n",
    "    attn5 = tf.convert_to_tensor([])\n",
    "    attn6 = tf.convert_to_tensor([])\n",
    "    attn7 = tf.convert_to_tensor([])\n",
    "    attn8 = tf.convert_to_tensor([])\n",
    "    attn9 = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,y_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr,at_1,at_2,at_3,at_4,at_5,at_6,at_7,at_8,at_9 = model(x_batch_test)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "            attn1 = at_1\n",
    "            attn2 = at_2\n",
    "            attn3 = at_3\n",
    "            attn4 = at_4\n",
    "            attn5 = at_5\n",
    "            attn6 = at_6\n",
    "            attn7 = at_7\n",
    "            attn8 = at_8\n",
    "            attn9 = at_9\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "            attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "            attn6 = tf.concat([attn6 , at_6] , axis = 0)\n",
    "            attn7 = tf.concat([attn7 , at_7] , axis = 0)\n",
    "            attn8 = tf.concat([attn8 , at_8] , axis = 0)\n",
    "            attn9 = tf.concat([attn9 , at_9] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "            \n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confb':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Encoder_ATT(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODELS_WITH_ATT/confb/best_model_0.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    attn1 = tf.convert_to_tensor([])\n",
    "    attn2 = tf.convert_to_tensor([])\n",
    "    attn3 = tf.convert_to_tensor([])\n",
    "    attn4 = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output,at_1,at_2,at_3,at_4 = model(x_batch_test)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "            attn1 = at_1\n",
    "            attn2 = at_2\n",
    "            attn3 = at_3\n",
    "            attn4 = at_4\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confe':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_ATT(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODELS_WITH_ATT/confe/best_model_10.001_0.0001_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    attn1 = tf.convert_to_tensor([])\n",
    "    attn2 = tf.convert_to_tensor([])\n",
    "    attn3 = tf.convert_to_tensor([])\n",
    "    attn4 = tf.convert_to_tensor([])\n",
    "    attn5 = tf.convert_to_tensor([])\n",
    "    attn6 = tf.convert_to_tensor([])\n",
    "    attn7 = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw,y_batch_test) in enumerate(test_dataset):\n",
    "        output,at_1,at_2,at_3,at_4,at_5,at_6,at_7 = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(y_batch_test , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "            attn1 = at_1\n",
    "            attn2 = at_2\n",
    "            attn3 = at_3\n",
    "            attn4 = at_4\n",
    "            attn5 = at_5\n",
    "            attn6 = at_6\n",
    "            attn7 = at_7\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "            attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "            attn6 = tf.concat([attn6 , at_6] , axis = 0)\n",
    "            attn7 = tf.concat([attn7 , at_7] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "        \n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confa':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_encoder_ATT(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODELS_WITH_ATT/confa/best_model_10.01_1e-05_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    attn1 = tf.convert_to_tensor([])\n",
    "    attn2 = tf.convert_to_tensor([])\n",
    "    attn3 = tf.convert_to_tensor([])\n",
    "    attn4 = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw, x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output,at_1,at_2,at_3,at_4  = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "            attn1 = at_1\n",
    "            attn2 = at_2\n",
    "            attn3 = at_3\n",
    "            attn4 = at_4\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_multi_ATT(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODELS_WITH_ATT/conff/best_model_10.0001_0.0001_100.h5')        \n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    attn1 = tf.convert_to_tensor([])\n",
    "    attn2 = tf.convert_to_tensor([])\n",
    "    attn3 = tf.convert_to_tensor([])\n",
    "    attn4 = tf.convert_to_tensor([])\n",
    "    attn5 = tf.convert_to_tensor([])\n",
    "    attn6 = tf.convert_to_tensor([])\n",
    "    attn7 = tf.convert_to_tensor([])\n",
    "    attn8 = tf.convert_to_tensor([])\n",
    "    attn9 = tf.convert_to_tensor([])\n",
    "    attn10 = tf.convert_to_tensor([])\n",
    "    attn11 = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw , y_batch_test , x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr,at_1,at_2,at_3,at_4,at_5,at_6,at_7,at_8,at_9,at_10,at_11 = model(x_batch_test_raw)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "            attn1 = at_1\n",
    "            attn2 = at_2\n",
    "            attn3 = at_3\n",
    "            attn4 = at_4\n",
    "            attn5 = at_5\n",
    "            attn6 = at_6\n",
    "            attn7 = at_7\n",
    "            attn8 = at_8\n",
    "            attn9 = at_9\n",
    "            attn10 = at_10\n",
    "            attn11 = at_11\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "            attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "            attn6 = tf.concat([attn6 , at_6] , axis = 0)\n",
    "            attn7 = tf.concat([attn7 , at_7] , axis = 0)\n",
    "            attn8 = tf.concat([attn8 , at_8] , axis = 0)\n",
    "            attn9 = tf.concat([attn9 , at_9] , axis = 0)\n",
    "            attn10 = tf.concat([attn10 , at_10] , axis = 0)\n",
    "            attn11 = tf.concat([attn11 , at_11] , axis = 0)\n",
    "        test_loss_list.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec177928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if input_conf == 'confa':\n",
    "    final_output_rr = final_output.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "#----------------------------------------------------------------------------------------------------------------   \n",
    "if input_conf == 'confb':\n",
    "    final_output_rr = final_output.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34d3ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "\n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------    \n",
    "if input_conf == 'confe':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b16d1e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error average wise for confd is: 2.3561530143449416\n",
      "Root Mean Square Error average wise for confd is: 2.9525362488233102\n",
      "Mean Absolute Error instantaneous wise for confd is: 3.433484652927073\n",
      "Root Mean Square Error instantaneous wise for confd is: 4.347050489663885\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confd':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_rr = final_output_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_rr = final_output_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fc6cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(attn1.shape)\n",
    "#print(attn2.shape)\n",
    "#print(attn3.shape)\n",
    "#print(attn4.shape)\n",
    "#print(attn5.shape)\n",
    "#print(attn6.shape)\n",
    "#print(attn7.shape)\n",
    "#print(attn8.shape)\n",
    "#print(attn9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5c75c13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#x_attn1 = attn1[0][0].numpy()\n",
    "#x_attn5 = attn5[0][0].numpy()\n",
    "#x_attn6 = attn6[0][0].numpy()\n",
    "#x_attn7 = attn7[0][0].numpy()\n",
    "#x_attn8 = attn8[0][0].numpy()\n",
    "#x_attn9 = attn9[0][0].numpy()\n",
    "\n",
    "#figure,axes = plt.subplots(nrows = 2 , ncols = 3)\n",
    "\n",
    "#axes[0,0].plot(x_attn1)\n",
    "\n",
    "#axes[0,1].plot(x_attn5)\n",
    "#axes[0,2].plot(x_attn6)\n",
    "#axes[1,0].plot(x_attn7)\n",
    "#axes[1,1].plot(x_attn8)\n",
    "#axes[1,2].plot(x_attn9)\n",
    "\n",
    "#figure.tight_layout()\n",
    "#y = np.transpose(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33c4fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_attn1 = attn1[0][0].numpy()\n",
    "#x_attn2 = attn2[0][0].numpy()\n",
    "#x_attn3 = attn3[0][0].numpy()\n",
    "#x_attn4 = attn4[0][0].numpy()\n",
    "\n",
    "#figure1,axes1 = plt.subplots(nrows = 2 , ncols = 2)\n",
    "\n",
    "#axes1[0,0].plot(x_attn1)\n",
    "#axes1[0,1].plot(x_attn2)\n",
    "#axes1[1,0].plot(x_attn3)\n",
    "#axes1[1,1].plot(x_attn4)\n",
    "\n",
    "#figure1.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f71c022",
   "metadata": {},
   "source": [
    "# ATTENTION WITH EVIDENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8d6b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if input_conf == 'confc':\n",
    "#    model_input_shape = (128,3)\n",
    "#    model  = BRUnet_ATT_EVI(model_input_shape)\n",
    "#    coeff_val = 0.1\n",
    "#    #loss_fn = Huber()\n",
    "#    model(tf.ones((128,128,3)))\n",
    "#    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_EVI/confc/best_model_10.01_1e-05_0.05_100.h5')\n",
    "#    test_loss_list = []\n",
    "#    final_output = tf.convert_to_tensor([])\n",
    "#    attn1 = tf.convert_to_tensor([])\n",
    "#    attn2 = tf.convert_to_tensor([])\n",
    "#    attn3 = tf.convert_to_tensor([])\n",
    "#    attn4 = tf.convert_to_tensor([])\n",
    "#    attn5 = tf.convert_to_tensor([])\n",
    "#    for step,(x_batch_test , y_batch_test) in enumerate(test_dataset):\n",
    "#        y_batch_test = tf.expand_dims(y_batch_test , axis = -1)\n",
    "#        output,at_1,at_2,at_3,at_4,at_5 = model(x_batch_test)\n",
    "#        test_loss = edl.losses.EvidentialRegression(y_batch_test,output, coeff = coeff_val)\n",
    "#        if step == 0:\n",
    "#            final_output = output\n",
    "#            attn1 = at_1\n",
    "#            attn2 = at_2\n",
    "#            attn3 = at_3\n",
    "#            attn4 = at_4\n",
    "#            attn5 = at_5\n",
    "#        else:\n",
    "#            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "#            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "#            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "#            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "#            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "#            attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "#        test_loss_list.append(test_loss)\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "#if input_conf == 'confe':\n",
    "#    model_input_shape = (2048,3)\n",
    "#    model  = BRUnet_raw_ATT_EVI(model_input_shape)\n",
    "#    coeff_val = 0.005\n",
    "#    #loss_fn = Huber()\n",
    "#    model(tf.ones((128,2048,3)))\n",
    "#    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_EVI/confe/best_model_10.001_0.0001_0.005_100.h5')\n",
    "#    test_loss_list = []\n",
    "#    final_output = tf.convert_to_tensor([])\n",
    "#    attn1 = tf.convert_to_tensor([])\n",
    "#    attn2 = tf.convert_to_tensor([])\n",
    "#    attn3 = tf.convert_to_tensor([])\n",
    "#    attn4 = tf.convert_to_tensor([])\n",
    "#    attn5 = tf.convert_to_tensor([])\n",
    "#    attn6 = tf.convert_to_tensor([])\n",
    "#    attn7 = tf.convert_to_tensor([])\n",
    "#    for step , (x_batch_test_raw,y_batch_test) in enumerate(test_dataset):\n",
    "#        y_batch_test = tf.expand_dims(y_batch_test , axis = -1)\n",
    "#        output,at_1,at_2,at_3,at_4,at_5,at_6,at_7 = model(x_batch_test_raw)\n",
    "#        test_loss = edl.losses.EvidentialRegression(y_batch_test,output, coeff = coeff_val)\n",
    "#        if step == 0:\n",
    "#            final_output = output\n",
    "#            attn1 = at_1\n",
    "#            attn2 = at_2\n",
    "#            attn3 = at_3\n",
    "#            attn4 = at_4\n",
    "#            attn5 = at_5\n",
    "#            attn6 = at_6\n",
    "#            attn7 = at_7\n",
    "#        else:\n",
    "#            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "#            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "#            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "#            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "#            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "#            attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "#            attn6 = tf.concat([attn6 , at_6] , axis = 0)\n",
    "#            attn7 = tf.concat([attn7 , at_7] , axis = 0)\n",
    "#        test_loss_list.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "006254ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if input_conf == 'confb':\n",
    "#    model_input_shape = (128,3)\n",
    "#    model  = BRUnet_Encoder_ATT_EVI(model_input_shape)\n",
    "#    coeff_val = 0.01\n",
    "#    #loss_fn = Huber()\n",
    "#    model(tf.ones((128,128,3)))\n",
    "#    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_EVI/confb/best_model_10.01_0.001_5e-05_100.h5')\n",
    "#    test_loss_list = []\n",
    "#    final_output = tf.convert_to_tensor([])\n",
    "#    attn1 = tf.convert_to_tensor([])\n",
    "#    attn2 = tf.convert_to_tensor([])\n",
    "#    attn3 = tf.convert_to_tensor([])\n",
    "#    attn4 = tf.convert_to_tensor([])\n",
    "#    for step , (x_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "#        x_batch_test_ref_rr = tf.expand_dims(x_batch_test_ref_rr , axis = -1)\n",
    "#        output,at_1,at_2,at_3,at_4 = model(x_batch_test)\n",
    "#        test_loss = edl.losses.EvidentialRegression(x_batch_test_ref_rr , output , coeff = coeff_val)\n",
    "#        if step == 0:\n",
    "#            final_output = output\n",
    "#            attn1 = at_1\n",
    "#            attn2 = at_2\n",
    "#            attn3 = at_3\n",
    "#            attn4 = at_4\n",
    "#        else:\n",
    "#            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "#            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "#            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "#            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "#            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "#        test_loss_list.append(test_loss)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "#if input_conf == 'confa':\n",
    "#    model_input_shape = (2048,3)\n",
    "#    model  = BRUnet_raw_encoder_ATT_EVI(model_input_shape)\n",
    "#    #loss_fn = Huber()\n",
    "#    coeff_val = 0.0001\n",
    "#    model(tf.ones((128,2048,3)))\n",
    "#    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_EVI/confa/best_model_10.01_1e-05_0.0005_100.h5')\n",
    "#    test_loss_list = []\n",
    "#    final_output = tf.convert_to_tensor([])\n",
    "#    attn1 = tf.convert_to_tensor([])\n",
    "#    attn2 = tf.convert_to_tensor([])\n",
    "#    attn3 = tf.convert_to_tensor([])\n",
    "#    attn4 = tf.convert_to_tensor([])\n",
    "#    for step , (x_batch_test_raw, x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "#        x_batch_test_ref_rr = tf.expand_dims(x_batch_test_ref_rr , axis = -1)\n",
    "#        output,at_1,at_2,at_3,at_4  = model(x_batch_test_raw)\n",
    "#        test_loss = edl.losses.EvidentialRegression(x_batch_test_ref_rr , output, coeff = coeff_val)\n",
    "#        if step == 0:\n",
    "#            final_output = output\n",
    "#            attn1 = at_1\n",
    "#            attn2 = at_2\n",
    "#            attn3 = at_3\n",
    "#            attn4 = at_4\n",
    "#        else:\n",
    "#            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "#            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "#            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "#            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "#            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "#        test_loss_list.append(test_loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cd9835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if input_conf == 'confd':\n",
    "#    model_input_shape = (128,3)\n",
    "#    model  = BRUnet_Multi_resp_ATT_EVI(model_input_shape)\n",
    "#    #loss_fn = Huber()\n",
    "#    model(tf.ones((128,128,3)))\n",
    "#    coeff_val = 0.0005\n",
    "#    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_EVI/confd/best_model_20.01_0.001_0.005_100.h5')\n",
    "#    test_loss_list = []\n",
    "#    final_output = tf.convert_to_tensor([])\n",
    "#    final_output_rr = tf.convert_to_tensor([])\n",
    "#    attn1 = tf.convert_to_tensor([])\n",
    "#    attn2 = tf.convert_to_tensor([])\n",
    "#    attn3 = tf.convert_to_tensor([])\n",
    "#    attn4 = tf.convert_to_tensor([])\n",
    "#    attn5 = tf.convert_to_tensor([])\n",
    "#    attn6 = tf.convert_to_tensor([])\n",
    "#    attn7 = tf.convert_to_tensor([])\n",
    "#    attn8 = tf.convert_to_tensor([])\n",
    "#    attn9 = tf.convert_to_tensor([])\n",
    "#    for step , (x_batch_test,y_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "#        x_batch_test_ref_rr = tf.expand_dims(x_batch_test_ref_rr , axis = -1)\n",
    "#        y_batch_test = tf.expand_dims(y_batch_test , axis = -1)\n",
    "#        test_output,test_out_rr,at_1,at_2,at_3,at_4,at_5,at_6,at_7,at_8,at_9 = model(x_batch_test)\n",
    "#        test_loss_resp = edl.losses.EvidentialRegression(y_batch_test  , test_output, coeff = coeff_val)\n",
    "#        test_loss_rr = edl.losses.EvidentialRegression(x_batch_test_ref_rr , test_out_rr,coeff = coeff_val)\n",
    "#        test_loss = test_loss_resp + test_loss_rr\n",
    "#        if step == 0:\n",
    "#            final_output = test_output\n",
    "#            final_output_rr = test_out_rr\n",
    "#            attn1 = at_1\n",
    "#            attn2 = at_2\n",
    "#            attn3 = at_3\n",
    "#            attn4 = at_4\n",
    "#            attn5 = at_5\n",
    "#            attn6 = at_6\n",
    "#            attn7 = at_7\n",
    "#            attn8 = at_8\n",
    "#            attn9 = at_9\n",
    "#        else:\n",
    "#            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "#            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "#            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "#            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "#            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "#            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "#            attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "#            attn6 = tf.concat([attn6 , at_6] , axis = 0)\n",
    "#            attn7 = tf.concat([attn7 , at_7] , axis = 0)\n",
    "#            attn8 = tf.concat([attn8 , at_8] , axis = 0)\n",
    "#            attn9 = tf.concat([attn9 , at_9] , axis = 0)\n",
    "#        test_loss_list.append(test_loss)\n",
    "        \n",
    "#---------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#if input_conf == 'conff':\n",
    "#    model_input_shape = (2048,3)\n",
    "#    model  = BRUnet_raw_multi_ATT_EVI(model_input_shape)\n",
    "#    #loss_fn = Huber()\n",
    "#    model(tf.ones((128,2048,3)))\n",
    "#    coeff_val = 0.0005\n",
    "#    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_EVI/conff/best_model_0.01_0.001_0.0005_100.h5')        \n",
    "#    test_loss_list = []\n",
    "#    final_output = tf.convert_to_tensor([])\n",
    "#    final_output_rr = tf.convert_to_tensor([])\n",
    "#    attn1 = tf.convert_to_tensor([])\n",
    "#    attn2 = tf.convert_to_tensor([])\n",
    "#    attn3 = tf.convert_to_tensor([])\n",
    "#    attn4 = tf.convert_to_tensor([])\n",
    "#    attn5 = tf.convert_to_tensor([])\n",
    "#    attn6 = tf.convert_to_tensor([])\n",
    "#    attn7 = tf.convert_to_tensor([])\n",
    "#    attn8 = tf.convert_to_tensor([])\n",
    "#    attn9 = tf.convert_to_tensor([])\n",
    "#    attn10 = tf.convert_to_tensor([])\n",
    "#    attn11 = tf.convert_to_tensor([])\n",
    "#    for step , (x_batch_test_raw , y_batch_test , x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "#        y_batch_test = tf.expand_dims(y_batch_test , axis = -1)\n",
    "#        x_batch_test_ref_rr = tf.expand_dims(x_batch_test_ref_rr , axis = -1)\n",
    "#        test_output,test_out_rr,at_1,at_2,at_3,at_4,at_5,at_6,at_7,at_8,at_9,at_10,at_11 = model(x_batch_test_raw)\n",
    "#        test_loss_resp = edl.losses.EvidentialRegression(y_batch_test  , test_output , coeff = coeff_val)\n",
    "#        test_loss_rr = edl.losses.EvidentialRegression(x_batch_test_ref_rr , test_out_rr , coeff = coeff_val)\n",
    "#        test_loss = test_loss_resp + test_loss_rr\n",
    "#        if step == 0:\n",
    "#            final_output = test_output\n",
    "#            final_output_rr = test_out_rr\n",
    "#            attn1 = at_1\n",
    "#            attn2 = at_2\n",
    "#            attn3 = at_3\n",
    "#            attn4 = at_4\n",
    "#            attn5 = at_5\n",
    "#            attn6 = at_6\n",
    "#            attn7 = at_7\n",
    "#            attn8 = at_8\n",
    "#            attn9 = at_9\n",
    "#            attn10 = at_10\n",
    "#            attn11 = at_11\n",
    "#        else:\n",
    "#            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "#            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "#            attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "#            attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "#            attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "#            attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "#            attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "#            attn6 = tf.concat([attn6 , at_6] , axis = 0)\n",
    "#            attn7 = tf.concat([attn7 , at_7] , axis = 0)\n",
    "#            attn8 = tf.concat([attn8 , at_8] , axis = 0)\n",
    "#            attn9 = tf.concat([attn9 , at_9] , axis = 0)\n",
    "#            attn10 = tf.concat([attn10 , at_10] , axis = 0)\n",
    "#            attn11 = tf.concat([attn11 , at_11] , axis = 0)\n",
    "#        test_loss_list.append(test_loss) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c4063a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1eeb7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "#if input_conf == 'confc':\n",
    "#    final_output_resp_sig = []\n",
    "#    inst_br_dur = []\n",
    "#    inst_ref_br_dur = []\n",
    "#    inst_rr = []\n",
    "#    inst_ref_rr = []\n",
    "#    gamma, lamda, alpha, beta = tf.split(final_output, 4, axis=-1)\n",
    "#    output = gamma.numpy()\n",
    "#    output = output.reshape(output.shape[0] , output.shape[1])\n",
    "#    output_copy = output\n",
    "#    for item in output:\n",
    "#        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "#    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "#    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "#    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "#    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "#    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "#    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "#    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "#    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "#    for item in extremas_resp:\n",
    "#        inst_br_dur.append(np.diff(item[0::2]))\n",
    "#    for item in extremas_ref_resp:\n",
    "#        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "#    for item in inst_br_dur:\n",
    "#        inst_rr.append(np.mean(60*4/item))\n",
    "#    for item in inst_ref_br_dur:\n",
    "#        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "#    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "#    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "#    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "#    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "#    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "#    final_lamda = lamda.numpy()\n",
    "#    final_alpha = alpha.numpy()\n",
    "#    final_beta = beta.numpy()\n",
    "    \n",
    "#    final_lamda = final_lamda.reshape(final_lamda.shape[0],final_lamda.shape[1])\n",
    "#    final_alpha = final_alpha.reshape(final_alpha.shape[0],final_alpha.shape[1])\n",
    "#    final_beta = final_beta.reshape(final_beta.shape[0],final_beta.shape[1])\n",
    "#    #x_samps = np.arange(0,len(y_train_data[0]))\n",
    "#    aleatoric = final_beta/(final_alpha - 1)\n",
    "#    epistemic = final_beta/(final_lamda*(final_alpha - 1))\n",
    "#    std_dev = np.sqrt(epistemic)\n",
    "#    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "#    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "#    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "#    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "#if input_conf == 'confe':\n",
    "#    final_output_resp_sig = []\n",
    "#    gamma, lamda, alpha, beta = tf.split(final_output, 4, axis=-1)\n",
    "#    output = gamma.numpy()\n",
    "#    output = output.reshape(output.shape[0] , output.shape[1])\n",
    "#    output_copy = output\n",
    "#    for item in output:\n",
    "#        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "#    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "#    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "#    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "#    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "#    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "#    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "#    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "#    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "#    final_lamda = lamda.numpy()\n",
    "#    final_alpha = alpha.numpy()\n",
    "#    final_beta = beta.numpy()\n",
    "    \n",
    "#    final_lamda = final_lamda.reshape(final_lamda.shape[0],final_lamda.shape[1])\n",
    "#    final_alpha = final_alpha.reshape(final_alpha.shape[0],final_alpha.shape[1])\n",
    "#    final_beta = final_beta.reshape(final_beta.shape[0],final_beta.shape[1])\n",
    "#    x_samps = np.arange(0,len(y_train_data[0]))\n",
    "#    aleatoric = final_beta/(final_alpha - 1)\n",
    "#    epistemic = final_beta/(final_lamda*(final_alpha - 1))\n",
    "#    std_dev = np.sqrt(epistemic)\n",
    "#    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "#    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05842e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#if input_conf == 'confb':\n",
    "#    gamma, lamda, alpha, beta = tf.split(final_output, 4, axis=-1)\n",
    "#    final_output_rr = gamma.numpy()\n",
    "#    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "#    output_copy = final_output_rr\n",
    "#    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "#    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "#    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "#    mae = np.mean(error)\n",
    "#    rmse = np.sqrt(np.mean(error**2))\n",
    "#    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "#    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "    \n",
    "#    final_lamda = lamda.numpy()\n",
    "#    final_alpha = alpha.numpy()\n",
    "#    final_beta = beta.numpy()\n",
    "    \n",
    "#    final_lamda = final_lamda.reshape(final_lamda.shape[0],final_lamda.shape[1])\n",
    "#    final_alpha = final_alpha.reshape(final_alpha.shape[0],final_alpha.shape[1])\n",
    "#    final_beta = final_beta.reshape(final_beta.shape[0],final_beta.shape[1])\n",
    "#    #x_samps = np.arange(0,len(y_train_data[0]))\n",
    "#    aleatoric = final_beta/(final_alpha - 1)\n",
    "#    epistemic = final_beta/(final_lamda*(final_alpha - 1))\n",
    "#    std_dev = np.sqrt(epistemic)\n",
    "#    print(epistemic)\n",
    "#    samples = np.arange(0,len(final_output_rr)).reshape(-1,1)\n",
    "#    aleatoric = aleatoric/max(aleatoric)\n",
    "#    epistemic = epistemic/max(epistemic)\n",
    "#    confb_data = np.hstack((samples,final_output_rr , epistemic , aleatoric, error, avg_ref_breath))\n",
    "#    col_confb = ['Samples','Final RR Output (BrPM)' , 'Epistemic','Aleatoric','Absolute Error', 'Reference RR (BrPM)']\n",
    "#    data_confb = pd.DataFrame(confb_data , columns = col_confb)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "#if input_conf == 'confa':\n",
    "#    gamma, lamda, alpha, beta = tf.split(final_output, 4, axis=-1)\n",
    "#    final_output_rr = gamma.numpy()\n",
    "#    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "#    output_copy = final_output_rr\n",
    "#    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "#    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "#    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "#    mae = np.mean(error)\n",
    "#    rmse = np.sqrt(np.mean(error**2))\n",
    "#    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "#    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "    \n",
    "#    final_lamda = lamda.numpy()\n",
    "#    final_alpha = alpha.numpy()\n",
    "#    final_beta = beta.numpy()\n",
    "    \n",
    "#    final_lamda = final_lamda.reshape(final_lamda.shape[0],final_lamda.shape[1])\n",
    "#    final_alpha = final_alpha.reshape(final_alpha.shape[0],final_alpha.shape[1])\n",
    "#    final_beta = final_beta.reshape(final_beta.shape[0],final_beta.shape[1])\n",
    "#    aleatoric = final_beta/(final_alpha - 1)\n",
    "#    epistemic = final_beta/(final_lamda*(final_alpha - 1))\n",
    "#    std_dev = np.sqrt(epistemic)\n",
    "#    print(epistemic)\n",
    "#    samples = np.arange(0,len(final_output_rr)).reshape(-1,1)\n",
    "#    aleatoric = aleatoric/max(aleatoric)\n",
    "#    epistemic = epistemic/max(epistemic)\n",
    "#    confa_data = np.hstack((samples,final_output_rr , epistemic , aleatoric, error, avg_ref_breath))\n",
    "#    col_confa = ['Samples','Final RR Output (BrPM)' , 'Epistemic','Aleatoric','Absolute Error', 'Reference RR (BrPM)']\n",
    "#    data_confa = pd.DataFrame(confa_data , columns = col_confa)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c295f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "#if input_conf == 'confd':\n",
    "#    final_output_resp_sig = []\n",
    "#    inst_br_dur = []\n",
    "#    inst_ref_br_dur = []\n",
    "#    inst_rr = []\n",
    "#    inst_ref_rr = []\n",
    "    \n",
    "#    gamma_resp, lamda_resp, alpha_resp, beta_resp = tf.split(final_output, 4, axis=-1)\n",
    "#    gamma_rr, lamda_rr, alpha_rr, beta_rr = tf.split(final_output_rr, 4, axis=-1)\n",
    "#    final_output_resp = gamma_resp.numpy()\n",
    "#    final_rr = gamma_rr.numpy()\n",
    "#    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0] , final_output_resp.shape[1])\n",
    "#    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "#    output_copy = final_output_resp\n",
    "#    output_copy_rr = final_rr\n",
    "#    for item in final_output_resp:\n",
    "#        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    \n",
    "#    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "#    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "#    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "#    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "#    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "#    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "#    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "#    for item in extremas_resp:\n",
    "#        inst_br_dur.append(np.diff(item[0::2]))\n",
    "#    for item in extremas_ref_resp:\n",
    "#        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "#    for item in inst_br_dur:\n",
    "#        inst_rr.append(np.mean(60*4/item))\n",
    "#    for item in inst_ref_br_dur:\n",
    "#        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "#    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "#    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "#    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "#    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "#    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "#    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "#    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "#    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "#    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "    \n",
    "#    final_lamda_resp = lamda_resp.numpy()\n",
    "#    final_alpha_resp = alpha_resp.numpy()\n",
    "#    final_beta_resp = beta_resp.numpy()\n",
    "    \n",
    "#    final_lamda_rr = lamda_rr.numpy()\n",
    "#    final_alpha_rr = alpha_rr.numpy()\n",
    "#    final_beta_rr = beta_rr.numpy()\n",
    "    \n",
    "#    aleatoric = final_beta_resp/(final_alpha_resp - 1)\n",
    "#    epistemic = final_beta_resp/(final_lamda_resp*(final_alpha_resp - 1))\n",
    "#    epistemic = epistemic.reshape(epistemic.shape[0],epistemic.shape[1])\n",
    "#    aleatoric = aleatoric.reshape(aleatoric.shape[0],aleatoric.shape[1])\n",
    "#    std_dev = np.sqrt(epistemic)\n",
    "#    aleatoric_rr = final_beta_rr/(final_alpha_rr - 1)\n",
    "#    epistemic_rr = final_beta_rr/(final_lamda_rr*(final_alpha_rr - 1))\n",
    "#    epistemic_rr = epistemic_rr.reshape(epistemic_rr.shape[0],epistemic_rr.shape[1])\n",
    "#    aleatoric_rr = aleatoric_rr.reshape(aleatoric_rr.shape[0],aleatoric_rr.shape[1])\n",
    "#    std_dev_rr = np.sqrt(epistemic_rr)\n",
    "#    print(epistemic_rr)\n",
    "#    samples = np.arange(0,len(final_rr)).reshape(-1,1)\n",
    "#    epistemic_rr = epistemic_rr/max(epistemic_rr)\n",
    "#    aleatoric_rr = aleatoric_rr/max(aleatoric_rr)\n",
    "    \n",
    "#    confd_data = np.hstack((samples,final_rr , epistemic_rr , aleatoric_rr, error_avg_breaths,error_inst_breaths, avg_ref_breath))\n",
    "#    col_confd = ['Samples','Final RR Output (BrPM)' , 'Epistemic','Aleatoric', 'Average RR Error(BrPM)','Instaneous RR Error(BrPM)','Reference RR (BrPM)']\n",
    "#    data_confd = pd.DataFrame(confd_data , columns = col_confd)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "#if input_conf == 'conff':\n",
    "#    final_output_resp_sig = []\n",
    "#    inst_br_dur = []\n",
    "#    inst_ref_br_dur = []\n",
    "#    inst_rr = []\n",
    "#    inst_ref_rr = []\n",
    "    \n",
    "#    gamma_resp, lamda_resp, alpha_resp, beta_resp = tf.split(final_output, 4, axis=-1)\n",
    "#    gamma_rr, lamda_rr, alpha_rr, beta_rr = tf.split(final_output_rr, 4, axis=-1)\n",
    "#    final_output_resp = gamma_resp.numpy()\n",
    "#    final_rr = gamma_rr.numpy()\n",
    "#    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0] , final_output_resp.shape[1])\n",
    "#    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "#    output_copy = final_output_resp\n",
    "#    output_copy_rr = final_rr\n",
    "#    for item in final_output_resp:\n",
    "#        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    \n",
    "#    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "#    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "#    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "#    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "#    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "#    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "#    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "#    for item in extremas_resp:\n",
    "#        inst_br_dur.append(np.diff(item[0::2]))\n",
    "#    for item in extremas_ref_resp:\n",
    "#        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "#    for item in inst_br_dur:\n",
    "#        inst_rr.append(np.mean(60*4/item))\n",
    "#    for item in inst_ref_br_dur:\n",
    "#        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "#    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "#    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "#    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "#    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "#    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "#    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "#    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "#    \n",
    "#    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "#    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "#    \n",
    "#    final_lamda_resp = lamda_resp.numpy()\n",
    "#    final_alpha_resp = alpha_resp.numpy()\n",
    "#    final_beta_resp = beta_resp.numpy()\n",
    "#    \n",
    "#    final_lamda_rr = lamda_rr.numpy()\n",
    "#    final_alpha_rr = alpha_rr.numpy()\n",
    "#    final_beta_rr = beta_rr.numpy()\n",
    "    \n",
    "#    aleatoric = final_beta_resp/(final_alpha_resp - 1)\n",
    "#    epistemic = final_beta_resp/(final_lamda_resp*(final_alpha_resp - 1))\n",
    "#    epistemic = epistemic.reshape(epistemic.shape[0],epistemic.shape[1])\n",
    "#    aleatoric = aleatoric.reshape(aleatoric.shape[0],aleatoric.shape[1])\n",
    "#    aleatoric_rr = final_beta_rr/(final_alpha_rr - 1)\n",
    "#    epistemic_rr = final_beta_rr/(final_lamda_rr*(final_alpha_rr - 1))\n",
    "#    print(epistemic_rr)\n",
    "#    samples = np.arange(0,len(final_rr)).reshape(-1,1)\n",
    "#    epistemic_rr = epistemic_rr.reshape(epistemic_rr.shape[0],epistemic_rr.shape[1])\n",
    "#    aleatoric_rr = aleatoric_rr.reshape(aleatoric_rr.shape[0],aleatoric_rr.shape[1])\n",
    "#    std_dev = np.sqrt(epistemic)\n",
    "#    std_dev_rr = np.sqrt(epistemic_rr)\n",
    "#    epistemic_rr = epistemic_rr/max(epistemic_rr)\n",
    "#    aleatoric_rr = aleatoric_rr/max(aleatoric_rr)\n",
    "    \n",
    "#    conff_data = np.hstack((samples,final_rr , epistemic_rr , aleatoric_rr , error_avg_breaths,error_inst_breaths, avg_ref_breath))\n",
    "#    col_conff = ['Samples','Final RR Output (BrPM)' , 'Epistemic','Aleatoric','Average RR Error(BrPM)','Instaneous RR Error(BrPM)','Reference RR (BrPM)']\n",
    "#    data_conff = pd.DataFrame(conff_data , columns = col_conff)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "486a5cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "#if input_conf == 'confc' or input_conf == 'confe' or input_conf == 'confd' or input_conf == 'conff':\n",
    "#    no_of_samples = 32*4\n",
    "#    x_unc = np.linspace(start = 0,stop = no_of_samples, num = no_of_samples)\n",
    "#    layout_epistemic = go.Layout(\n",
    "#    title = \"Respiratory Waveform with Epistemic Uncertainty for \"+ input_conf.upper(),\n",
    "#    yaxis = dict(\n",
    "#        title = 'Output Respiration Signal' \n",
    "#    ),\n",
    "#    xaxis = dict(\n",
    "#        title = 'samples'\n",
    "#    )\n",
    "#    )\n",
    "\n",
    "#    layout_aleatoric = go.Layout(\n",
    "#    title = \"Respiratory Waveform with Aleatoric Uncertainty for \"+ input_conf.upper(),\n",
    "#    yaxis = dict(\n",
    "#        title = 'Output Respiration Signal' \n",
    "#    ),\n",
    "#    xaxis = dict(\n",
    "#        title = 'samples'\n",
    "#    )\n",
    "#    )\n",
    "\n",
    "#    def update_plot(signals):\n",
    "#        data = []\n",
    "#            # Reference ECG trace\n",
    "#        trace_epistemic = go.Scatter(\n",
    "#            x = x_unc,\n",
    "#            y = final_output_resp_sig[signals], \n",
    "#            mode = 'lines',\n",
    "#            name = 'Respiration with Epistemic',\n",
    "#                    line = dict(\n",
    "#                    shape = 'spline',\n",
    "#                    color = 'green'\n",
    "#                     ),\n",
    "#                error_y=dict(\n",
    "#                    type='data', # value of error bar given in data coordinates\n",
    "#                    array=epistemic[signals],\n",
    "#                    visible=True,\n",
    "#                    color='black',\n",
    "#                thickness=3,\n",
    "#                width=5)\n",
    "#                )\n",
    "\n",
    "#        trace_aleatoric = go.Scatter(\n",
    "#                     x = x_unc,\n",
    "#                     y = final_output_resp_sig[signals], \n",
    "#                    mode = 'lines',\n",
    "#                     name = 'Respiration with Aleatoric',\n",
    "#                     line = dict(\n",
    "#                         shape = 'spline',\n",
    "#                         color = 'green'\n",
    "#                     ),\n",
    "#                error_y=dict(\n",
    "#                    type='data', # value of error bar given in data coordinates\n",
    "#                    array=aleatoric[signals],\n",
    "#                    visible=True,\n",
    "#                    color='black',\n",
    "#                thickness=3,\n",
    "#                width=5)\n",
    "#                )\n",
    "#        fig_epistemic = go.Figure(data = [trace_epistemic],layout = layout_epistemic)\n",
    "#        py.offline.iplot(fig_epistemic)\n",
    "#        fig_aleatoric = go.Figure(data = [trace_aleatoric],layout = layout_aleatoric)\n",
    "#        py.offline.iplot(fig_aleatoric)\n",
    "#signals_epsitemic = widgets.IntSlider(min = 0,max = len(final_output_resp_sig), value = 0, description = 'Record_no:')\n",
    "#widgets.interactive(update_plot, signals = signals_epsitemic)\n",
    "#signals_aleatoric = widgets.IntSlider(min = 0,max = len(final_output_resp_sig), value = 0, description = 'Record_no:')\n",
    "#widgets.interactive(update_plot, signals = signals_aleatoric)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ece4492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "#if input_conf == 'confb':\n",
    "#    fig1 = px.scatter(data_confb,x = 'Samples', y=\"Final RR Output (BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper(),\n",
    "#                     color=\"Epistemic\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "\n",
    "#    fig2 = px.scatter(data_confb,x = 'Samples', y=\"Final RR Output (BrPM)\",title=\"Aleatoric Uncertainty Distribution for \"+input_conf.upper(),\n",
    "#                     color=\"Aleatoric\", color_continuous_scale=px.colors.sequential.Plasma)\n",
    "    \n",
    "#    fig3 = px.scatter(data_confb,x = 'Samples', y=\"Absolute Error\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper(),\n",
    "#                     color=\"Epistemic\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    \n",
    "#    fig4 = px.scatter(data_confb,x = 'Samples', y=\"Absolute Error\",title=\"Aleatoric Uncertainty Distribution for \"+input_conf.upper(),\n",
    "#                     color=\"Aleatoric\", color_continuous_scale=px.colors.sequential.Plasma)\n",
    "    \n",
    "#    fig5 = px.scatter(data_confb,x = 'Samples', y='Reference RR (BrPM)',title=\"Aleatoric Uncertainty Distribution for \"+input_conf.upper(),\n",
    "#                     color=\"Aleatoric\", color_continuous_scale=px.colors.sequential.Plasma)\n",
    "\n",
    "#    fig1.show()\n",
    "#    fig2.show()\n",
    "#    fig3.show()\n",
    "#    fig4.show()\n",
    "#    fig5.show()\n",
    "\n",
    "#if input_conf == 'confd':\n",
    "#    fig1 = px.scatter(data_confd,x = 'Samples', y=\"Final RR Output (BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper()+\" for final RR output\",\n",
    "#                     color=\"Epistemic\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "\n",
    "#    fig2 = px.scatter(data_confd, x = 'Samples',y=\"Final RR Output (BrPM)\",title=\"Aleatoric Uncertainty Distribution for \"+input_conf.upper()+\" for final RR output\",\n",
    "#                     color=\"Aleatoric\", color_continuous_scale=px.colors.sequential.Plasma)\n",
    "    \n",
    "#    fig3 = px.scatter(data_confd,x = 'Samples', y=\"Average RR Error(BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper()+\" for Average RR Error\",\n",
    "#                     color=\"Epistemic\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    \n",
    "#    fig4 = px.scatter(data_confd, x = 'Samples',y=\"Average RR Error(BrPM)\",title=\"Aleatoric Uncertainty Distribution for \"+input_conf.upper()+\" for Average RR Error\",\n",
    "#                     color=\"Aleatoric\", color_continuous_scale=px.colors.sequential.Plasma)\n",
    "    \n",
    "#    fig5 = px.scatter(data_confd, x = 'Samples',y='Reference RR (BrPM)',title=\"Aleatoric Uncertainty Distribution for \"+input_conf.upper()+\" for Reference signal\",\n",
    "#                     color=\"Aleatoric\", color_continuous_scale=px.colors.sequential.Plasma)\n",
    "#    fig6 = px.scatter(data_confd,x = 'Samples', y=\"Instaneous RR Error(BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper()+\" for Instantaneous RR Error\",\n",
    "#                     color=\"Epistemic\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "\n",
    "\n",
    "#    fig1.show()\n",
    "#    fig2.show()\n",
    "#    fig3.show()\n",
    "#    fig4.show()\n",
    "#    fig5.show()\n",
    "#    fig6.show()\n",
    "    \n",
    "#if input_conf == 'conff':\n",
    "#    fig1 = px.scatter(data_conff,x = 'Samples', y=\"Final RR Output (BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper()+\" for final RR output\",\n",
    "#                     color=\"Epistemic\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "\n",
    "#    fig2 = px.scatter(data_conff, x = 'Samples',y=\"Final RR Output (BrPM)\",title=\"Aleatoric Uncertainty Distribution for \"+input_conf.upper()+\" for final RR output\",\n",
    "#                     color=\"Aleatoric\", color_continuous_scale=px.colors.sequential.Plasma)\n",
    "    \n",
    "#    fig3 = px.scatter(data_conff,x = 'Samples', y=\"Average RR Error(BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper()+\" for Average RR Error\",\n",
    "#                     color=\"Epistemic\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    \n",
    "#    fig4 = px.scatter(data_conff, x = 'Samples',y=\"Average RR Error(BrPM)\",title=\"Aleatoric Uncertainty Distribution for \"+input_conf.upper()+\" for Average RR Error\",\n",
    "#                     color=\"Aleatoric\", color_continuous_scale=px.colors.sequential.Plasma)\n",
    "    \n",
    "#    fig5 = px.scatter(data_conff, x = 'Samples',y='Reference RR (BrPM)',title=\"Aleatoric Uncertainty Distribution for \"+input_conf.upper()+\" for Reference signal\",\n",
    "#                     color=\"Aleatoric\", color_continuous_scale=px.colors.sequential.Plasma)\n",
    "#    fig6 = px.scatter(data_conff,x = 'Samples', y=\"Instaneous RR Error(BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper()+\" for Instantaneous RR Error\",\n",
    "#                     color=\"Epistemic\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "\n",
    "\n",
    "#    fig1.show()\n",
    "#    fig2.show()\n",
    "#    fig3.show()\n",
    "#    fig4.show()\n",
    "#    fig5.show()\n",
    "#    fig6.show()\n",
    "    \n",
    "#if input_conf == 'confa':\n",
    "#    fig1 = px.scatter(data_confa,x = 'Samples', y=\"Final RR Output (BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper(),\n",
    "#                     color=\"Epistemic\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "\n",
    "#    fig2 = px.scatter(data_confa, x = 'Samples',y=\"Final RR Output (BrPM)\",title=\"Aleatoric Uncertainty Distribution for \"+input_conf.upper(),\n",
    "#                     color=\"Aleatoric\", color_continuous_scale=px.colors.sequential.Plasma)\n",
    "    \n",
    "#    fig3 = px.scatter(data_confa,x = 'Samples', y=\"Absolute Error\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper(),\n",
    "#                     color=\"Epistemic\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    \n",
    "#    fig4 = px.scatter(data_confa, x = 'Samples',y=\"Absolute Error\",title=\"Aleatoric Uncertainty Distribution for \"+input_conf.upper(),\n",
    "#                     color=\"Aleatoric\", color_continuous_scale=px.colors.sequential.Plasma)\n",
    "    \n",
    "#    fig5 = px.scatter(data_confa, x = 'Samples',y='Reference RR (BrPM)',title=\"Aleatoric Uncertainty Distribution for \"+input_conf.upper(),\n",
    "#                     color=\"Aleatoric\", color_continuous_scale=px.colors.sequential.Plasma)\n",
    "\n",
    "#    fig1.show()\n",
    "#    fig2.show()\n",
    "#    fig3.show()\n",
    "#    fig4.show()\n",
    "#    fig5.show()\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d6f158",
   "metadata": {},
   "source": [
    "# ATTENTION WITH MONTE CARLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "642408ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    final_output = np.array([])\n",
    "    final_attn1 = np.array([])\n",
    "    final_attn2 = np.array([])\n",
    "    final_attn3 = np.array([])\n",
    "    final_attn4 = np.array([])\n",
    "    final_attn5 = np.array([])\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_ATT_MC(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_MONTE/confc/best_model_10.01_1e-05_100.h5')\n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        attn1 = tf.convert_to_tensor([])\n",
    "        attn2 = tf.convert_to_tensor([])\n",
    "        attn3 = tf.convert_to_tensor([])\n",
    "        attn4 = tf.convert_to_tensor([])\n",
    "        attn5 = tf.convert_to_tensor([])\n",
    "        for step,(x_batch_test , y_batch_test) in enumerate(test_dataset):\n",
    "            output,at_1,at_2,at_3,at_4,at_5 = model(x_batch_test)\n",
    "            test_loss = loss_fn(y_batch_test,output)\n",
    "            if step == 0:\n",
    "                output_data = output\n",
    "                attn1 = at_1\n",
    "                attn2 = at_2\n",
    "                attn3 = at_3\n",
    "                attn4 = at_4\n",
    "                attn5 = at_5\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , output] , axis = 0)\n",
    "                attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "                attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "                attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "                attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "                attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "            test_loss_list.append(test_loss)\n",
    "        output_array = output_data.numpy()\n",
    "        attn1_array = attn1.numpy()\n",
    "        attn2_array = attn2.numpy()\n",
    "        attn3_array = attn3.numpy()\n",
    "        attn4_array = attn4.numpy()\n",
    "        attn5_array = attn5.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        attn1_array = np.expand_dims(attn1_array,axis = 0)\n",
    "        attn2_array = np.expand_dims(attn2_array,axis = 0)\n",
    "        attn3_array = np.expand_dims(attn3_array,axis = 0)\n",
    "        attn4_array = np.expand_dims(attn4_array,axis = 0)\n",
    "        attn5_array = np.expand_dims(attn5_array,axis = 0)\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "            final_attn1 = attn1_array\n",
    "            final_attn2 = attn2_array\n",
    "            final_attn3 = attn3_array\n",
    "            final_attn4 = attn4_array\n",
    "            final_attn5 = attn5_array\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "            final_attn1 = np.vstack((final_attn1,attn1_array))\n",
    "            final_attn2 = np.vstack((final_attn2,attn2_array))\n",
    "            final_attn3 = np.vstack((final_attn3,attn3_array))\n",
    "            final_attn4 = np.vstack((final_attn4,attn4_array))\n",
    "            final_attn5 = np.vstack((final_attn5,attn5_array))\n",
    "#=================================================================================================================\n",
    "if input_conf == 'confe':\n",
    "    final_output = np.array([])\n",
    "    final_attn1 = np.array([])\n",
    "    final_attn2 = np.array([])\n",
    "    final_attn3 = np.array([])\n",
    "    final_attn4 = np.array([])\n",
    "    final_attn5 = np.array([])\n",
    "    final_attn6 = np.array([])\n",
    "    final_attn7 = np.array([])\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_ATT_MC(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_MONTE/confe/best_model_10.001_0.0001_100.h5')\n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        attn1 = tf.convert_to_tensor([])\n",
    "        attn2 = tf.convert_to_tensor([])\n",
    "        attn3 = tf.convert_to_tensor([])\n",
    "        attn4 = tf.convert_to_tensor([])\n",
    "        attn5 = tf.convert_to_tensor([])\n",
    "        attn6 = tf.convert_to_tensor([])\n",
    "        attn7 = tf.convert_to_tensor([])\n",
    "        for step , (x_batch_test_raw,y_batch_test) in enumerate(test_dataset):\n",
    "            output,at_1,at_2,at_3,at_4,at_5,at_6,at_7 = model(x_batch_test_raw)\n",
    "            test_loss = loss_fn(y_batch_test , output)\n",
    "            if step == 0:\n",
    "                output_data = output\n",
    "                attn1 = at_1\n",
    "                attn2 = at_2\n",
    "                attn3 = at_3\n",
    "                attn4 = at_4\n",
    "                attn5 = at_5\n",
    "                attn6 = at_6\n",
    "                attn7 = at_7\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , output] , axis = 0)\n",
    "                attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "                attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "                attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "                attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "                attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "                attn6 = tf.concat([attn6 , at_6] , axis = 0)\n",
    "                attn7 = tf.concat([attn7 , at_7] , axis = 0)\n",
    "            test_loss_list.append(test_loss)\n",
    "        output_array = output_data.numpy()\n",
    "        attn1_array = attn1.numpy()\n",
    "        attn2_array = attn2.numpy()\n",
    "        attn3_array = attn3.numpy()\n",
    "        attn4_array = attn4.numpy()\n",
    "        attn5_array = attn5.numpy()\n",
    "        attn6_array = attn6.numpy()\n",
    "        attn7_array = attn7.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        attn1_array = np.expand_dims(attn1_array,axis = 0)\n",
    "        attn2_array = np.expand_dims(attn2_array,axis = 0)\n",
    "        attn3_array = np.expand_dims(attn3_array,axis = 0)\n",
    "        attn4_array = np.expand_dims(attn4_array,axis = 0)\n",
    "        attn5_array = np.expand_dims(attn5_array,axis = 0)\n",
    "        attn6_array = np.expand_dims(attn6_array,axis = 0)\n",
    "        attn7_array = np.expand_dims(attn7_array,axis = 0)\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "            final_attn1 = attn1_array\n",
    "            final_attn2 = attn2_array\n",
    "            final_attn3 = attn3_array\n",
    "            final_attn4 = attn4_array\n",
    "            final_attn5 = attn5_array\n",
    "            final_attn6 = attn6_array\n",
    "            final_attn7 = attn7_array\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "            final_attn1 = np.vstack((final_attn1,attn1_array))\n",
    "            final_attn2 = np.vstack((final_attn2,attn2_array))\n",
    "            final_attn3 = np.vstack((final_attn3,attn3_array))\n",
    "            final_attn4 = np.vstack((final_attn4,attn4_array))\n",
    "            final_attn5 = np.vstack((final_attn5,attn5_array))\n",
    "            final_attn6 = np.vstack((final_attn6,attn6_array))\n",
    "            final_attn7 = np.vstack((final_attn7,attn7_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d4648dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confb':\n",
    "    final_output = np.array([])\n",
    "    final_attn1 = np.array([])\n",
    "    final_attn2 = np.array([])\n",
    "    final_attn3 = np.array([])\n",
    "    final_attn4 = np.array([])\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Encoder_ATT_MC(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_MONTE/confb/best_model_10.01_1e-05_100.h5')\n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        attn1 = tf.convert_to_tensor([])\n",
    "        attn2 = tf.convert_to_tensor([])\n",
    "        attn3 = tf.convert_to_tensor([])\n",
    "        attn4 = tf.convert_to_tensor([])\n",
    "        for step , (x_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "            output,at_1,at_2,at_3,at_4 = model(x_batch_test)\n",
    "            test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "            if step == 0:\n",
    "                output_data = output\n",
    "                attn1 = at_1\n",
    "                attn2 = at_2\n",
    "                attn3 = at_3\n",
    "                attn4 = at_4\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , output] , axis = 0)\n",
    "                attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "                attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "                attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "                attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "            test_loss_list.append(test_loss)\n",
    "        output_array = output_data.numpy()\n",
    "        attn1_array = attn1.numpy()\n",
    "        attn2_array = attn2.numpy()\n",
    "        attn3_array = attn3.numpy()\n",
    "        attn4_array = attn4.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        attn1_array = np.expand_dims(attn1_array,axis = 0)\n",
    "        attn2_array = np.expand_dims(attn2_array,axis = 0)\n",
    "        attn3_array = np.expand_dims(attn3_array,axis = 0)\n",
    "        attn4_array = np.expand_dims(attn4_array,axis = 0)\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "            final_attn1 = attn1_array\n",
    "            final_attn2 = attn2_array\n",
    "            final_attn3 = attn3_array\n",
    "            final_attn4 = attn4_array\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "            final_attn1 = np.vstack((final_attn1,attn1_array))\n",
    "            final_attn2 = np.vstack((final_attn2,attn2_array))\n",
    "            final_attn3 = np.vstack((final_attn3,attn3_array))\n",
    "            final_attn4 = np.vstack((final_attn4,attn4_array))\n",
    "\n",
    "#==========================================================================================================\n",
    "if input_conf == 'confa':\n",
    "    final_output = np.array([])\n",
    "    final_attn1 = np.array([])\n",
    "    final_attn2 = np.array([])\n",
    "    final_attn3 = np.array([])\n",
    "    final_attn4 = np.array([])\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_encoder_ATT_MC(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_MONTE/confa/best_model_10.01_1e-05_100.h5')\n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        attn1 = tf.convert_to_tensor([])\n",
    "        attn2 = tf.convert_to_tensor([])\n",
    "        attn3 = tf.convert_to_tensor([])\n",
    "        attn4 = tf.convert_to_tensor([])\n",
    "        for step , (x_batch_test_raw, x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "            output,at_1,at_2,at_3,at_4 = model(x_batch_test_raw)\n",
    "            test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "            if step == 0:\n",
    "                output_data = output\n",
    "                attn1 = at_1\n",
    "                attn2 = at_2\n",
    "                attn3 = at_3\n",
    "                attn4 = at_4\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , output] , axis = 0)\n",
    "                attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "                attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "                attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "                attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "            test_loss_list.append(test_loss)  \n",
    "        output_array = output_data.numpy()\n",
    "        attn1_array = attn1.numpy()\n",
    "        attn2_array = attn2.numpy()\n",
    "        attn3_array = attn3.numpy()\n",
    "        attn4_array = attn4.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        attn1_array = np.expand_dims(attn1_array,axis = 0)\n",
    "        attn2_array = np.expand_dims(attn2_array,axis = 0)\n",
    "        attn3_array = np.expand_dims(attn3_array,axis = 0)\n",
    "        attn4_array = np.expand_dims(attn4_array,axis = 0)\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "            final_attn1 = attn1_array\n",
    "            final_attn2 = attn2_array\n",
    "            final_attn3 = attn3_array\n",
    "            final_attn4 = attn4_array\n",
    "            \n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "            final_attn1 = np.vstack((final_attn1,attn1_array))\n",
    "            final_attn2 = np.vstack((final_attn2,attn2_array))\n",
    "            final_attn3 = np.vstack((final_attn3,attn3_array))\n",
    "            final_attn4 = np.vstack((final_attn4,attn4_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0bc779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:14<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confd':\n",
    "    final_output = np.array([])\n",
    "    final_output_rr = np.array([])\n",
    "    final_attn1 = np.array([])\n",
    "    final_attn2 = np.array([])\n",
    "    final_attn3 = np.array([])\n",
    "    final_attn4 = np.array([])\n",
    "    final_attn5 = np.array([])\n",
    "    final_attn6 = np.array([])\n",
    "    final_attn7 = np.array([])\n",
    "    final_attn8 = np.array([])\n",
    "    final_attn9 = np.array([])\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Multi_resp_ATT_MC(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_MONTE/confd/best_model_10.01_1e-05_100.h5')\n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        output_data_rr = tf.convert_to_tensor([])\n",
    "        attn1 = tf.convert_to_tensor([])\n",
    "        attn2 = tf.convert_to_tensor([])\n",
    "        attn3 = tf.convert_to_tensor([])\n",
    "        attn4 = tf.convert_to_tensor([])\n",
    "        attn5 = tf.convert_to_tensor([])\n",
    "        attn6 = tf.convert_to_tensor([])\n",
    "        attn7 = tf.convert_to_tensor([])\n",
    "        attn8 = tf.convert_to_tensor([])\n",
    "        attn9 = tf.convert_to_tensor([])\n",
    "        for step , (x_batch_test,y_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "            test_output,test_out_rr,at_1,at_2,at_3,at_4,at_5,at_6,at_7,at_8,at_9 = model(x_batch_test)\n",
    "            test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "            test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "            test_loss = test_loss_resp + test_loss_rr\n",
    "            if step == 0:\n",
    "                output_data = test_output\n",
    "                output_data_rr = test_out_rr\n",
    "                attn1 = at_1\n",
    "                attn2 = at_2\n",
    "                attn3 = at_3\n",
    "                attn4 = at_4\n",
    "                attn5 = at_5\n",
    "                attn6 = at_6\n",
    "                attn7 = at_7\n",
    "                attn8 = at_8\n",
    "                attn9 = at_9\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , test_output] , axis = 0)\n",
    "                output_data_rr = tf.concat([output_data_rr , test_out_rr] , axis = 0)\n",
    "                attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "                attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "                attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "                attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "                attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "                attn6 = tf.concat([attn6 , at_6] , axis = 0)\n",
    "                attn7 = tf.concat([attn7 , at_7] , axis = 0)\n",
    "                attn8 = tf.concat([attn8 , at_8] , axis = 0)\n",
    "                attn9 = tf.concat([attn9 , at_9] , axis = 0)\n",
    "            test_loss_list.append(test_loss)\n",
    "        output_array = output_data.numpy()\n",
    "        output_array_rr = output_data_rr.numpy()\n",
    "        attn1_array = attn1.numpy()\n",
    "        attn2_array = attn2.numpy()\n",
    "        attn3_array = attn3.numpy()\n",
    "        attn4_array = attn4.numpy()\n",
    "        attn5_array = attn5.numpy()\n",
    "        attn6_array = attn6.numpy()\n",
    "        attn7_array = attn7.numpy()\n",
    "        attn8_array = attn8.numpy()\n",
    "        attn9_array = attn9.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        output_array_rr = output_array_rr.reshape(output_array_rr.shape[-1],output_array_rr.shape[0],output_array_rr.shape[1])\n",
    "        attn1_array = np.expand_dims(attn1_array,axis = 0)\n",
    "        attn2_array = np.expand_dims(attn2_array,axis = 0)\n",
    "        attn3_array = np.expand_dims(attn3_array,axis = 0)\n",
    "        attn4_array = np.expand_dims(attn4_array,axis = 0)\n",
    "        attn5_array = np.expand_dims(attn5_array,axis = 0)\n",
    "        attn6_array = np.expand_dims(attn6_array,axis = 0)\n",
    "        attn7_array = np.expand_dims(attn7_array,axis = 0)\n",
    "        attn8_array = np.expand_dims(attn8_array,axis = 0)\n",
    "        attn9_array = np.expand_dims(attn9_array,axis = 0)\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "            final_output_rr = output_array_rr\n",
    "            final_attn1 = attn1_array\n",
    "            final_attn2 = attn2_array\n",
    "            final_attn3 = attn3_array\n",
    "            final_attn4 = attn4_array\n",
    "            final_attn5 = attn5_array\n",
    "            final_attn6 = attn6_array\n",
    "            final_attn7 = attn7_array\n",
    "            final_attn8 = attn8_array\n",
    "            final_attn9 = attn9_array\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "            final_output_rr = np.vstack((final_output_rr,output_array_rr))\n",
    "            final_attn1 = np.vstack((final_attn1,attn1_array))\n",
    "            final_attn2 = np.vstack((final_attn2,attn2_array))\n",
    "            final_attn3 = np.vstack((final_attn3,attn3_array))\n",
    "            final_attn4 = np.vstack((final_attn4,attn4_array))\n",
    "            final_attn5 = np.vstack((final_attn5,attn5_array))\n",
    "            final_attn6 = np.vstack((final_attn6,attn6_array))\n",
    "            final_attn7 = np.vstack((final_attn7,attn7_array))\n",
    "            final_attn8 = np.vstack((final_attn8,attn8_array))\n",
    "            final_attn9 = np.vstack((final_attn9,attn9_array))\n",
    "            \n",
    "#=================================================================================================================\n",
    "if input_conf == 'conff':\n",
    "    final_output = np.array([])\n",
    "    final_output_rr = np.array([])\n",
    "    final_attn1 = np.array([])\n",
    "    final_attn2 = np.array([])\n",
    "    final_attn3 = np.array([])\n",
    "    final_attn4 = np.array([])\n",
    "    final_attn5 = np.array([])\n",
    "    final_attn6 = np.array([])\n",
    "    final_attn7 = np.array([])\n",
    "    final_attn8 = np.array([])\n",
    "    final_attn9 = np.array([])\n",
    "    final_attn10 = np.array([])\n",
    "    final_attn11 = np.array([])\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_multi_ATT_MC(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/ATTENTION/SAVED_MODEL_ATT_MONTE/conff/best_model_10.0001_0.0001_100.h5') \n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        output_data_rr = tf.convert_to_tensor([])\n",
    "        attn1 = tf.convert_to_tensor([])\n",
    "        attn2 = tf.convert_to_tensor([])\n",
    "        attn3 = tf.convert_to_tensor([])\n",
    "        attn4 = tf.convert_to_tensor([])\n",
    "        attn5 = tf.convert_to_tensor([])\n",
    "        attn6 = tf.convert_to_tensor([])\n",
    "        attn7 = tf.convert_to_tensor([])\n",
    "        attn8 = tf.convert_to_tensor([])\n",
    "        attn9 = tf.convert_to_tensor([])\n",
    "        attn10 = tf.convert_to_tensor([])\n",
    "        attn11 = tf.convert_to_tensor([])\n",
    "        for step , (x_batch_test_raw , y_batch_test , x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "            test_output,test_out_rr,at_1,at_2,at_3,at_4,at_5,at_6,at_7,at_8,at_9,at_10,at_11 = model(x_batch_test_raw)\n",
    "            test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "            test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "            test_loss = test_loss_resp + test_loss_rr\n",
    "            if step == 0:\n",
    "                output_data = test_output\n",
    "                output_data_rr = test_out_rr\n",
    "                attn1 = at_1\n",
    "                attn2 = at_2\n",
    "                attn3 = at_3\n",
    "                attn4 = at_4\n",
    "                attn5 = at_5\n",
    "                attn6 = at_6\n",
    "                attn7 = at_7\n",
    "                attn8 = at_8\n",
    "                attn9 = at_9\n",
    "                attn10 = at_10\n",
    "                attn11 = at_11\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , test_output] , axis = 0)\n",
    "                output_data_rr = tf.concat([output_data_rr , test_out_rr] , axis = 0)\n",
    "                attn1 = tf.concat([attn1 , at_1] , axis = 0)\n",
    "                attn2 = tf.concat([attn2 , at_2] , axis = 0)\n",
    "                attn3 = tf.concat([attn3 , at_3] , axis = 0)\n",
    "                attn4 = tf.concat([attn4 , at_4] , axis = 0)\n",
    "                attn5 = tf.concat([attn5 , at_5] , axis = 0)\n",
    "                attn6 = tf.concat([attn6 , at_6] , axis = 0)\n",
    "                attn7 = tf.concat([attn7 , at_7] , axis = 0)\n",
    "                attn8 = tf.concat([attn8 , at_8] , axis = 0)\n",
    "                attn9 = tf.concat([attn9 , at_9] , axis = 0)\n",
    "                attn10 = tf.concat([attn10 , at_10] , axis = 0)\n",
    "                attn11 = tf.concat([attn11 , at_11] , axis = 0)\n",
    "            test_loss_list.append(test_loss)\n",
    "        output_array = output_data.numpy()\n",
    "        output_array_rr = output_data_rr.numpy()\n",
    "        attn1_array = attn1.numpy()\n",
    "        attn2_array = attn2.numpy()\n",
    "        attn3_array = attn3.numpy()\n",
    "        attn4_array = attn4.numpy()\n",
    "        attn5_array = attn5.numpy()\n",
    "        attn6_array = attn6.numpy()\n",
    "        attn7_array = attn7.numpy()\n",
    "        attn8_array = attn8.numpy()\n",
    "        attn9_array = attn9.numpy()\n",
    "        attn10_array = attn10.numpy()\n",
    "        attn11_array = attn11.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        output_array_rr = output_array_rr.reshape(output_array_rr.shape[-1],output_array_rr.shape[0],output_array_rr.shape[1])\n",
    "        attn1_array = np.expand_dims(attn1_array,axis = 0)\n",
    "        attn2_array = np.expand_dims(attn2_array,axis = 0)\n",
    "        attn3_array = np.expand_dims(attn3_array,axis = 0)\n",
    "        attn4_array = np.expand_dims(attn4_array,axis = 0)\n",
    "        attn5_array = np.expand_dims(attn5_array,axis = 0)\n",
    "        attn6_array = np.expand_dims(attn6_array,axis = 0)\n",
    "        attn7_array = np.expand_dims(attn7_array,axis = 0)\n",
    "        attn8_array = np.expand_dims(attn8_array,axis = 0)\n",
    "        attn9_array = np.expand_dims(attn9_array,axis = 0)\n",
    "        attn10_array = np.expand_dims(attn10_array,axis = 0)\n",
    "        attn11_array = np.expand_dims(attn11_array,axis = 0)\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "            final_output_rr = output_array_rr\n",
    "            final_attn1 = attn1_array\n",
    "            final_attn2 = attn2_array\n",
    "            final_attn3 = attn3_array\n",
    "            final_attn4 = attn4_array\n",
    "            final_attn5 = attn5_array\n",
    "            final_attn6 = attn6_array\n",
    "            final_attn7 = attn7_array\n",
    "            final_attn8 = attn8_array\n",
    "            final_attn9 = attn9_array\n",
    "            final_attn10 = attn10_array\n",
    "            final_attn11 = attn11_array\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "            final_output_rr = np.vstack((final_output_rr,output_array_rr))\n",
    "            final_attn1 = np.vstack((final_attn1,attn1_array))\n",
    "            final_attn2 = np.vstack((final_attn2,attn2_array))\n",
    "            final_attn3 = np.vstack((final_attn3,attn3_array))\n",
    "            final_attn4 = np.vstack((final_attn4,attn4_array))\n",
    "            final_attn5 = np.vstack((final_attn5,attn5_array))\n",
    "            final_attn6 = np.vstack((final_attn6,attn6_array))\n",
    "            final_attn7 = np.vstack((final_attn7,attn7_array))\n",
    "            final_attn8 = np.vstack((final_attn8,attn8_array))\n",
    "            final_attn9 = np.vstack((final_attn9,attn9_array))\n",
    "            final_attn10 = np.vstack((final_attn10,attn10_array))\n",
    "            final_attn11 = np.vstack((final_attn11,attn11_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34fc72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f002c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    l = 0.1\n",
    "    drop_prob = 0.1\n",
    "    lam = 0.0001\n",
    "    \n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_attn1_output = np.mean(final_attn1 , axis = 0)\n",
    "    final_attn2_output = np.mean(final_attn2 , axis = 0)\n",
    "    final_attn3_output = np.mean(final_attn3 , axis = 0)\n",
    "    final_attn4_output = np.mean(final_attn4 , axis = 0)\n",
    "    final_attn5_output = np.mean(final_attn5 , axis = 0)\n",
    "    \n",
    "    final_output_resp = np.mean(final_output , axis = 0)\n",
    "    final_var = np.var(final_output , axis = 0)\n",
    "    \n",
    "    tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    final_var += (tau**-1)\n",
    "    output_copy = final_output_resp\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    #final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "\n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "    print(final_var)\n",
    "#===============================================================================================================\n",
    "\n",
    "if input_conf == 'confe':\n",
    "    l = 1\n",
    "    drop_prob = 0.1\n",
    "    lam = 0.0001\n",
    "    \n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_attn1_output = np.mean(final_attn1 , axis = 0)\n",
    "    final_attn2_output = np.mean(final_attn2 , axis = 0)\n",
    "    final_attn3_output = np.mean(final_attn3 , axis = 0)\n",
    "    final_attn4_output = np.mean(final_attn4 , axis = 0)\n",
    "    final_attn5_output = np.mean(final_attn5 , axis = 0)\n",
    "    final_attn6_output = np.mean(final_attn6 , axis = 0)\n",
    "    final_attn7_output = np.mean(final_attn7 , axis = 0)\n",
    "    \n",
    "    final_output_resp = np.mean(final_output , axis = 0)\n",
    "    final_var = np.var(final_output , axis = 0)\n",
    "    print(final_var)\n",
    "    tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    final_var += (tau**-1)\n",
    "    \n",
    "    output_copy = final_output_resp\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee5f494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confb':\n",
    "    l = 0.01\n",
    "    drop_prob = 0.1\n",
    "    lam = 0.0001\n",
    "    \n",
    "    final_attn1_output = np.mean(final_attn1 , axis = 0)\n",
    "    final_attn2_output = np.mean(final_attn2 , axis = 0)\n",
    "    final_attn3_output = np.mean(final_attn3 , axis = 0)\n",
    "    final_attn4_output = np.mean(final_attn4 , axis = 0)\n",
    "    \n",
    "    final_output_rr = np.mean(final_output , axis = 0)\n",
    "    final_var = np.var(final_output , axis = 0)\n",
    "    tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    final_var += (tau**-1)\n",
    "    output_copy = final_output_rr\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    #final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "    \n",
    "    samples = np.arange(0,len(final_output_rr)).reshape(-1,1)\n",
    "    confb_data = np.hstack((samples,final_output_rr , final_var, error))\n",
    "    col_confb = ['Samples','Final RR Output (BrPM)' , 'Uncertainty', 'Absolute Error (BrPM)']\n",
    "    data_confb = pd.DataFrame(confb_data , columns = col_confb)\n",
    "\n",
    "#=====================================================================================================================\n",
    "if input_conf == 'confa':\n",
    "    l = 0.01\n",
    "    drop_prob = 0.1\n",
    "    lam = 0.0001\n",
    "    \n",
    "    final_attn1_output = np.mean(final_attn1 , axis = 0)\n",
    "    final_attn2_output = np.mean(final_attn2 , axis = 0)\n",
    "    final_attn3_output = np.mean(final_attn3 , axis = 0)\n",
    "    final_attn4_output = np.mean(final_attn4 , axis = 0)\n",
    "    \n",
    "    final_output_rr = np.mean(final_output , axis = 0)\n",
    "    final_var = np.var(final_output , axis = 0)\n",
    "    tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    final_var += (tau**-1)\n",
    "    output_copy = final_output_rr\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    #final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "    \n",
    "    samples = np.arange(0,len(final_output_rr)).reshape(-1,1)\n",
    "    confa_data = np.hstack((samples,final_output_rr ,final_var ,error))\n",
    "    col_confa = ['Samples','Final RR Output (BrPM)' ,'Uncertainty','Absolute Error (BrPM)']\n",
    "    data_confa = pd.DataFrame(confa_data , columns = col_confa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bfce84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error average wise for confd is: 2.3842515588533577\n",
      "Root Mean Square Error average wise for confd is: 3.009303035107382\n",
      "Mean Absolute Error instantaneous wise for confd is: 3.1475759739493174\n",
      "Root Mean Square Error instantaneous wise for confd is: 3.9461547957314766\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confd':\n",
    "    #l = 0.1\n",
    "    #drop_prob = 0.1\n",
    "    #lam = 0.0001\n",
    "    \n",
    "    #l_rr = 0.01\n",
    "    #drop_prob_rr = 0.1\n",
    "    #lam_rr = 0.0001\n",
    "    \n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_attn1_output = np.mean(final_attn1 , axis = 0)\n",
    "    final_attn2_output = np.mean(final_attn2 , axis = 0)\n",
    "    final_attn3_output = np.mean(final_attn3 , axis = 0)\n",
    "    final_attn4_output = np.mean(final_attn4 , axis = 0)\n",
    "    final_attn5_output = np.mean(final_attn5 , axis = 0)\n",
    "    final_attn6_output = np.mean(final_attn6 , axis = 0)\n",
    "    final_attn7_output = np.mean(final_attn7 , axis = 0)\n",
    "    final_attn8_output = np.mean(final_attn8 , axis = 0)\n",
    "    final_attn9_output = np.mean(final_attn9 , axis = 0)\n",
    "    \n",
    "    final_output_resp = np.mean(final_output,axis = 0)\n",
    "    final_rr = np.mean(final_output_rr,axis = 0)\n",
    "    #tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    #tau_rr = (l_rr**2) * (1-drop_prob_rr) / (2. * lam_rr)\n",
    "    \n",
    "    final_var = np.var(final_output,axis = 0)\n",
    "    final_var_rr = np.var(final_output_rr,axis = 0)\n",
    "    #final_var += (tau**-1)\n",
    "    #final_var_rr += (tau_rr**-1)\n",
    "    output_copy = final_output_resp\n",
    "    output_copy_rr = final_rr\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    std_dev_rr = np.sqrt(final_var_rr)\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    samples = np.arange(0,len(final_rr)).reshape(-1,1)\n",
    "    confd_data = np.hstack((samples,final_rr , std_dev_rr,error_avg_breaths, error_inst_breaths))\n",
    "    col_confd = ['Samples','Final RR Output (BrPM)' , 'Uncertainty', 'Error Avg Breath(BrPM)','Error Inst Breath(BrPM)']\n",
    "    data_confd = pd.DataFrame(confd_data , columns = col_confd)\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "    \n",
    "#===================================================================================================================\n",
    "if input_conf == 'conff':\n",
    "    l = 1\n",
    "    drop_prob = 0.1\n",
    "    lam = 0.0001\n",
    "    \n",
    "    l_rr = 0.01\n",
    "    drop_prob_rr = 0.1\n",
    "    lam_rr = 0.0001\n",
    "    \n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_attn1_output = np.mean(final_attn1 , axis = 0)\n",
    "    final_attn2_output = np.mean(final_attn2 , axis = 0)\n",
    "    final_attn3_output = np.mean(final_attn3 , axis = 0)\n",
    "    final_attn4_output = np.mean(final_attn4 , axis = 0)\n",
    "    final_attn5_output = np.mean(final_attn5 , axis = 0)\n",
    "    final_attn6_output = np.mean(final_attn6 , axis = 0)\n",
    "    final_attn7_output = np.mean(final_attn7 , axis = 0)\n",
    "    final_attn8_output = np.mean(final_attn8 , axis = 0)\n",
    "    final_attn9_output = np.mean(final_attn9 , axis = 0)\n",
    "    final_attn10_output = np.mean(final_attn10 , axis = 0)\n",
    "    final_attn11_output = np.mean(final_attn11 , axis = 0)\n",
    "    \n",
    "    final_output_resp = np.mean(final_output,axis = 0)\n",
    "    final_rr = np.mean(final_output_rr,axis = 0)\n",
    "    #tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    #tau_rr = (l_rr**2) * (1-drop_prob_rr) / (2. * lam_rr)\n",
    "    final_var = np.var(final_output,axis = 0)\n",
    "    final_var_rr = np.var(final_output_rr,axis = 0)\n",
    "    #final_var += (tau**-1)\n",
    "    #final_var_rr += (tau_rr**-1)\n",
    "    output_copy = final_output_resp\n",
    "    output_copy_rr = final_rr\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    std_dev_rr = np.sqrt(final_var_rr)\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    samples = np.arange(0,len(final_rr)).reshape(-1,1)\n",
    "    conff_data = np.hstack((samples,final_rr , final_var_rr, error_avg_breaths, error_inst_breaths))\n",
    "    col_conff = ['Samples','Final RR Output (BrPM)' , 'Uncertainty', 'Error Avg Breath(BrPM)','Error Inst Breath(BrPM)']\n",
    "    data_conff = pd.DataFrame(conff_data , columns = col_conff)\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2b28b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82703f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc83e805f474e129c88d3edd3a704b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Record_no:', max=814), Output()), _dom_classes=('widget-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if input_conf == 'confc' or input_conf == 'confe' or input_conf == 'confd' or input_conf == 'conff':\n",
    "    no_of_samples = 32*4\n",
    "    x_unc = np.linspace(start = 0,stop = no_of_samples, num = no_of_samples)\n",
    "    layout_epistemic = go.Layout(\n",
    "    title = \"Respiratory Waveform with Epistemic Uncertainty for \"+ input_conf.upper(),\n",
    "    yaxis = dict(\n",
    "        title = 'Output Respiration Signal' \n",
    "    ),\n",
    "    xaxis = dict(\n",
    "        title = 'samples'\n",
    "    )\n",
    "    )\n",
    "    def update_plot(signals):\n",
    "        data = []\n",
    "            # Reference ECG trace\n",
    "        trace_epistemic = go.Scatter(\n",
    "            x = x_unc,\n",
    "            y = final_output_resp_sig[signals], \n",
    "            mode = 'lines',\n",
    "            name = 'Respiration with Epistemic',\n",
    "                    line = dict(\n",
    "                    shape = 'spline',\n",
    "                    color = 'red',\n",
    "                    width = 5\n",
    "                     ),\n",
    "                error_y=dict(\n",
    "                    type='data', # value of error bar given in data coordinates\n",
    "                    array=final_var[signals],\n",
    "                    visible=True,\n",
    "                    color='black',\n",
    "                thickness=3,\n",
    "                width=5)\n",
    "                )\n",
    "        fig_epistemic = go.Figure(data = [trace_epistemic],layout = layout_epistemic)\n",
    "        py.offline.iplot(fig_epistemic)\n",
    "signals_epsitemic = widgets.IntSlider(min = 0,max = len(final_output_resp_sig), value = 0, description = 'Record_no:')\n",
    "widgets.interactive(update_plot, signals = signals_epsitemic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b6cf7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Samples=%{x}<br>Error Avg Breath(BrPM)=%{y}<br>Uncertainty=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           0.11800112575292587,
           0.13804320991039276,
           0.0350194051861763,
           0.12791873514652252,
           1.0306295156478882,
           0.2656440734863281,
           0.2687962055206299,
           0.2813800275325775,
           0.18250875174999237,
           0.2670319378376007,
           0.185589998960495,
           0.17697076499462128,
           0.17025817930698395,
           0.1275278627872467,
           0.1647997498512268,
           0.16639071702957153,
           0.12341368943452835,
           0.03430389240384102,
           0.13904625177383423,
           0.14213185012340546,
           0.11109805852174759,
           0.037542924284935,
           0.25056809186935425,
           0.1491357982158661,
           1.0356768369674683,
           0.102090023458004,
           0.5625126361846924,
           0.22729338705539703,
           0.23960968852043152,
           0.4117746651172638,
           0.10128413885831833,
           0.06663476675748825,
           0.12754255533218384,
           0.14249761402606964,
           0.12130685150623322,
           0.12973976135253906,
           2.297647476196289,
           0.40126731991767883,
           0.17922604084014893,
           0.26012861728668213,
           0.0007274135714396834,
           0.29243263602256775,
           0.5225510597229004,
           0.2678993046283722,
           0.0882745310664177,
           0.1690913587808609,
           0.6126404404640198,
           0.1376819759607315,
           0.14376872777938843,
           0.0031590028665959835,
           0.1291901022195816,
           0.26303568482398987,
           0.14393535256385803,
           0.07193301618099213,
           0.1515328735113144,
           0.18119607865810394,
           0.2787298262119293,
           0.03226647153496742,
           0.14395451545715332,
           0.26040831208229065,
           0.2906903326511383,
           0.05117477476596832,
           0.4164206385612488,
           0.05256551504135132,
           0.14520764350891113,
           0.029106853529810905,
           0.07890468090772629,
           0.17985107004642487,
           0.17864638566970825,
           0.1430080085992813,
           0.14200548827648163,
           0.013185170479118824,
           1.1458992958068848,
           0.1125371977686882,
           0.06426199525594711,
           0.44541123509407043,
           0.17631955444812775,
           1.0499247312545776,
           0.15490032732486725,
           0.13923609256744385,
           2.0050840377807617,
           0.2564767003059387,
           0.13027635216712952,
           0.17106159031391144,
           0.043346598744392395,
           0.41867485642433167,
           0.16984230279922485,
           0.5399168133735657,
           0.06674906611442566,
           0.11401861906051636,
           1.0505625009536743,
           0.4791984558105469,
           0.2170945703983307,
           0.5569477677345276,
           0.17721718549728394,
           0.06263849884271622,
           0.12657420337200165,
           1.094722867012024,
           0.11185184121131897,
           0.15261593461036682,
           0.128391832113266,
           0.18072271347045898,
           0.4483061134815216,
           0.09689084440469742,
           0.3381749093532562,
           0.121043860912323,
           0.20713236927986145,
           0.1933547854423523,
           0.10203687101602554,
           0.18159660696983337,
           0.032806091010570526,
           0.11194337904453278,
           0.10999803990125656,
           5.965674877166748,
           0.4168541133403778,
           0.25221744179725647,
           0.15646009147167206,
           0.026934612542390823,
           0.045153338462114334,
           0.03359484300017357,
           1.034989356994629,
           0.2351488173007965,
           0.22259990870952606,
           0.059478823095560074,
           0.07805730402469635,
           0.15906496345996857,
           0.15580429136753082,
           0.13951829075813293,
           1.0525990724563599,
           0.12730661034584045,
           0.1659907102584839,
           0.14144153892993927,
           0.20401664078235626,
           0.22123995423316956,
           0.4307885766029358,
           0.127266988158226,
           0.3159218728542328,
           0.04863940551877022,
           0.15406525135040283,
           0.5324276089668274,
           0.630420446395874,
           0.0458647795021534,
           0.43097198009490967,
           0.4551717936992645,
           0.14199112355709076,
           0.15841369330883026,
           0.08770525455474854,
           0.09069560468196869,
           0.031830254942178726,
           0.19046223163604736,
           0.05984167754650116,
           0.21851693093776703,
           1.0468133687973022,
           0.12734632194042206,
           0.0671614557504654,
           0.11048153787851334,
           0.04417915269732475,
           1.0516936779022217,
           0.160441055893898,
           0.08945313096046448,
           0.2380475252866745,
           1.2344599962234497,
           0.26153990626335144,
           0.5934309959411621,
           1.053792953491211,
           0.1557633876800537,
           0.1402558982372284,
           0.5653062462806702,
           0.16360829770565033,
           1.0366543531417847,
           0.14454804360866547,
           0.35322627425193787,
           0.03335058316588402,
           0.17838886380195618,
           0.23708882927894592,
           0.11331154406070709,
           0.16488765180110931,
           0.14632277190685272,
           0.3404153287410736,
           0.15701621770858765,
           0.12938064336776733,
           0.0317869670689106,
           0.13231615722179413,
           0.07006049901247025,
           0.0027386050205677748,
           0.0592387393116951,
           0.167439803481102,
           0.039508841931819916,
           0.4235692322254181,
           0.16265352070331573,
           0.16325971484184265,
           0.06643706560134888,
           0.14405269920825958,
           1.0429813861846924,
           0.4338938593864441,
           0.15703023970127106,
           0.09807394444942474,
           0.16509926319122314,
           0.28216812014579773,
           0.32110121846199036,
           0.17743127048015594,
           0.07483039796352386,
           0.20715810358524323,
           0.14456892013549805,
           0.4065377116203308,
           0.12699919939041138,
           0.0606924369931221,
           0.15011994540691376,
           0.18703189492225647,
           0.19371521472930908,
           0.17100709676742554,
           0.14203912019729614,
           0.1149686649441719,
           0.16804508864879608,
           0.03623395040631294,
           0.19259454309940338,
           0.12808823585510254,
           0.027315570041537285,
           0.11197272688150406,
           0.059720221906900406,
           0.8857371211051941,
           1.983691930770874,
           0.16780264675617218,
           0.17094409465789795,
           0.1516384780406952,
           0.11157236248254776,
           0.422665536403656,
           0.11517952382564545,
           0.037333693355321884,
           0.13451620936393738,
           0.14682313799858093,
           1.0424954891204834,
           0.3022487759590149,
           0.05262256786227226,
           0.15120401978492737,
           0.16548296809196472,
           0.30111196637153625,
           0.1685713529586792,
           0.12972529232501984,
           0.03337587043642998,
           0.1697489321231842,
           2.0189030170440674,
           0.22430871427059174,
           0.20053929090499878,
           0.05988571420311928,
           0.2548125386238098,
           0.23603542149066925,
           0.05846485123038292,
           0.9117397665977478,
           0.3601793646812439,
           0.03561467304825783,
           0.18566182255744934,
           0.1933019757270813,
           0.2086237668991089,
           0.2195928990840912,
           0.18498201668262482,
           0.0833643302321434,
           0.1533440202474594,
           0.11278499662876129,
           0.11411409825086594,
           0.11519874632358551,
           0.18325112760066986,
           0.11348788440227509,
           0.1782761961221695,
           0.23801496624946594,
           0.5115453004837036,
           0.008426659740507603,
           2.4660067558288574,
           0.5486398339271545,
           0.19071386754512787,
           0.17371462285518646,
           0.9022622108459473,
           0.16544659435749054,
           0.23077675700187683,
           0.12357480823993683,
           0.11421045660972595,
           0.11106516420841217,
           0.17743061482906342,
           0.35909608006477356,
           1.3636866807937622,
           0.24226562678813934,
           1.034818172454834,
           0.14154042303562164,
           0.03680070489645004,
           0.20307005941867828,
           0.3273506462574005,
           0.13898511230945587,
           0.14247415959835052,
           0.11272794008255005,
           1.0483673810958862,
           0.15454991161823273,
           0.12780211865901947,
           0.14485062658786774,
           0.25221455097198486,
           0.03488897159695625,
           1.0323071479797363,
           0.1674206703901291,
           1.033829689025879,
           0.0689767524600029,
           0.007784477435052395,
           0.11221156269311905,
           0.4101167619228363,
           0.1211933121085167,
           1.032975196838379,
           1.1267160177230835,
           0.07952306419610977,
           0.03577018156647682,
           0.013132937252521515,
           0.2378024160861969,
           0.20243270695209503,
           0.12872450053691864,
           0.030983613803982735,
           0.14032214879989624,
           0.1981728971004486,
           0.1453404575586319,
           0.17165322601795197,
           0.028034847229719162,
           0.11591378599405289,
           0.0024092255625873804,
           0.4532170295715332,
           0.12827222049236298,
           0.1109728068113327,
           0.10276342183351517,
           0.1398802548646927,
           0.1456063836812973,
           0.13920941948890686,
           0.052319202572107315,
           0.19130654633045197,
           0.15157420933246613,
           0.10346394777297974,
           0.1464606076478958,
           0.10896273702383041,
           0.15445439517498016,
           0.41076740622520447,
           0.2178698480129242,
           0.46009862422943115,
           0.3721928000450134,
           0.11130858212709427,
           0.1137920394539833,
           0.14219246804714203,
           0.42718270421028137,
           0.23382684588432312,
           1.0507190227508545,
           0.4403797686100006,
           1.0322844982147217,
           0.03203305974602699,
           0.18111997842788696,
           0.12971629202365875,
           1.9912244081497192,
           0.04135902598500252,
           0.17234519124031067,
           0.29563194513320923,
           0.1283438801765442,
           0.28972992300987244,
           0.08075948804616928,
           0.07797399163246155,
           0.06288701295852661,
           0.18586456775665283,
           0.17536792159080505,
           0.13553281128406525,
           1.030644416809082,
           1.0549125671386719,
           0.1693699061870575,
           0.07082200050354004,
           0.03625206649303436,
           0.05884015932679176,
           0.09955830127000809,
           0.14607828855514526,
           0.26075857877731323,
           0.22761112451553345,
           0.27223050594329834,
           0.0788191631436348,
           0.2236417680978775,
           1.0994024276733398,
           0.17652927339076996,
           1.9982644319534302,
           0.159513920545578,
           0.03830885514616966,
           0.16400490701198578,
           0.1666349619626999,
           1.0451931953430176,
           0.153423473238945,
           0.28277936577796936,
           0.03375546634197235,
           0.11948956549167633,
           0.5695326328277588,
           0.07534752786159515,
           0.19402620196342468,
           0.11771339178085327,
           0.08466627448797226,
           0.1887107789516449,
           0.0808899998664856,
           0.009257188066840172,
           1.3430309295654297,
           1.033473014831543,
           0.14468468725681305,
           0.13017770648002625,
           0.026182997971773148,
           0.028734752908349037,
           0.03700997307896614,
           0.31238847970962524,
           0.16768264770507812,
           0.08902325481176376,
           0.19582514464855194,
           0.9114909172058105,
           0.11177542805671692,
           0.16725192964076996,
           0.11447802186012268,
           0.6027058959007263,
           0.22134026885032654,
           0.1284007877111435,
           0.1297445148229599,
           0.05855565890669823,
           0.1716039925813675,
           0.148948535323143,
           0.17871737480163574,
           0.1553872525691986,
           0.1128711849451065,
           1.050357699394226,
           0.3689870536327362,
           0.05740739777684212,
           0.2766477167606354,
           0.22361113131046295,
           0.19150729477405548,
           1.0329620838165283,
           0.017470046877861023,
           0.032457638531923294,
           1.0568485260009766,
           0.042033080011606216,
           0.11134647578001022,
           0.11267485469579697,
           0.11383020132780075,
           1.065482497215271,
           0.21702435612678528,
           0.24715979397296906,
           1.1131083965301514,
           0.356523722410202,
           2.75298810005188,
           0.1327715367078781,
           0.26886892318725586,
           0.12472398579120636,
           0.03318971022963524,
           0.060074273496866226,
           1.388079047203064,
           0.11213868111371994,
           1.1452350616455078,
           0.026674970984458923,
           0.12038718909025192,
           0.2188684046268463,
           0.1312306672334671,
           0.11199545115232468,
           0.1772671490907669,
           0.1900649517774582,
           0.034299448132514954,
           0.2194005846977234,
           1.9906649589538574,
           0.03618817403912544,
           0.014476734213531017,
           0.41221943497657776,
           0.523613691329956,
           0.17328794300556183,
           0.14219719171524048,
           1.0591270923614502,
           0.11978091299533844,
           0.07522009313106537,
           0.4710986018180847,
           0.027101291343569756,
           0.02875090204179287,
           0.11935850232839584,
           0.11263542622327805,
           0.15480975806713104,
           1.0478227138519287,
           0.16364911198616028,
           0.148843914270401,
           0.019834985956549644,
           0.12697280943393707,
           0.1329641193151474,
           0.42908236384391785,
           0.4193737506866455,
           0.1553591638803482,
           0.13391008973121643,
           0.11285705119371414,
           0.06115679815411568,
           0.16917750239372253,
           0.16406972706317902,
           0.1806732714176178,
           0.11390915513038635,
           0.1483335644006729,
           0.08324477076530457,
           0.40037667751312256,
           0.29395416378974915,
           0.15225189924240112,
           0.3499993681907654,
           0.060697041451931,
           0.13057945668697357,
           0.06903287768363953,
           0.3791328966617584,
           0.3804436922073364,
           0.26791030168533325,
           0.19537118077278137,
           0.4136612117290497,
           0.18029522895812988,
           0.2482122927904129,
           2.310615301132202,
           0.15770605206489563,
           0.12345151603221893,
           0.2714194655418396,
           0.12741360068321228,
           0.12048288434743881,
           0.14399248361587524,
           0.5172065496444702,
           0.10133354365825653,
           0.45003074407577515,
           0.22631026804447174,
           0.026050424203276634,
           0.08458197116851807,
           1.0577986240386963,
           0.15430808067321777,
           0.049870800226926804,
           0.10706634819507599,
           1.0602997541427612,
           0.2069624364376068,
           0.4703746438026428,
           0.19839581847190857,
           0.1966746598482132,
           0.1683523803949356,
           0.12904290854930878,
           0.06333725154399872,
           0.053434427827596664,
           1.0809316635131836,
           0.4379236698150635,
           1.0270001888275146,
           0.18682189285755157,
           0.16956175863742828,
           0.18760348856449127,
           0.2867591083049774,
           0.4484640657901764,
           1.032275915145874,
           0.12944728136062622,
           0.4664052724838257,
           0.03214249759912491,
           0.10287179797887802,
           0.14579011499881744,
           0.11092346906661987,
           0.09022451192140579,
           0.10596123337745667,
           0.14571017026901245,
           0.08436188101768494,
           0.04464475437998772,
           0.07463128864765167,
           0.20336025953292847,
           0.15380750596523285,
           0.07628361135721207,
           1.029470443725586,
           1.041930079460144,
           0.2687359154224396,
           0.11194417625665665,
           0.13076341152191162,
           0.11281082779169083,
           0.07617490738630295,
           0.026528360322117805,
           0.261626660823822,
           1.1598762273788452,
           0.42503058910369873,
           0.08109290152788162,
           7.1709113121032715,
           0.1338677555322647,
           0.4407767951488495,
           0.04493878781795502,
           0.1183113157749176,
           0.12691275775432587,
           1.053215503692627,
           1.0559425354003906,
           0.12748880684375763,
           0.6073470115661621,
           0.2585568130016327,
           0.1879478543996811,
           0.11788252741098404,
           1.1958410739898682,
           0.02424342930316925,
           1.0363342761993408,
           0.27726420760154724,
           0.16731321811676025,
           0.13683442771434784,
           0.06821060180664062,
           0.4216727614402771,
           0.16876918077468872,
           0.13051928579807281,
           0.16931892931461334,
           0.1121673434972763,
           0.1741965264081955,
           0.153993621468544,
           0.6287137866020203,
           0.18887348473072052,
           0.27308526635169983,
           1.0383113622665405,
           0.4212327003479004,
           0.20713847875595093,
           0.05235126242041588,
           0.15406735241413116,
           0.12566640973091125,
           0.1384917050600052,
           0.112112857401371,
           0.17405565083026886,
           0.1893531233072281,
           0.03674692660570145,
           1.0493557453155518,
           0.21856500208377838,
           0.017729641869664192,
           0.17375154793262482,
           1.0489994287490845,
           0.12370911240577698,
           0.0635322779417038,
           0.026101525872945786,
           0.050583574920892715,
           0.25013014674186707,
           0.19997410476207733,
           0.042222581803798676,
           0.0038036240730434656,
           0.07118254154920578,
           0.1713070273399353,
           0.04985908791422844,
           1.0374658107757568,
           1.1084036827087402,
           0.8758909702301025,
           0.17531633377075195,
           0.000787279277574271,
           0.5286270976066589,
           0.8692032694816589,
           0.45204275846481323,
           1.0402357578277588,
           0.04972778260707855,
           0.2022101730108261,
           0.4750586450099945,
           0.282764732837677,
           0.141051784157753,
           0.08888788521289825,
           0.3051868677139282,
           0.16623127460479736,
           0.41199520230293274,
           0.0014008121797814965,
           0.1960178017616272,
           0.40853893756866455,
           0.05833682045340538,
           0.40817469358444214,
           0.1288788765668869,
           0.42314237356185913,
           0.6222479939460754,
           0.11022179573774338,
           0.06385663151741028,
           0.11351791024208069,
           0.10715416818857193,
           0.1109633594751358,
           0.14229750633239746,
           0.19468806684017181,
           0.024149619042873383,
           0.02622044086456299,
           0.4070632755756378,
           0.09146425873041153,
           0.2953895628452301,
           0.03843690827488899,
           0.12253016233444214,
           0.31189030408859253,
           0.12374501675367355,
           0.4438766539096832,
           0.08157966285943985,
           0.28394776582717896,
           0.26211997866630554,
           0.14931489527225494,
           0.14437198638916016,
           0.23153267800807953,
           0.05539543554186821,
           0.14908216893672943,
           1.0504264831542969,
           0.3452487885951996,
           0.12795093655586243,
           0.16540458798408508,
           0.18393903970718384,
           0.1057143285870552,
           0.06865322589874268,
           0.14806613326072693,
           0.15227490663528442,
           0.03805587813258171,
           1.4372351169586182,
           1.0375359058380127,
           0.27189674973487854,
           0.23554934561252594,
           0.11200625449419022,
           0.021226054057478905,
           0.09012197703123093,
           0.2519966661930084,
           0.28351831436157227,
           0.25267305970191956,
           0.1260865032672882,
           1.0552219152450562,
           0.16955861449241638,
           0.08441165834665298,
           0.13979128003120422,
           1.9658358097076416,
           0.08000122755765915,
           0.29635366797447205,
           1.7213727235794067,
           0.12416025996208191,
           0.07144930213689804,
           0.4345523715019226,
           0.4151330888271332,
           0.4258694648742676,
           0.3129725158214569,
           0.13149426877498627,
           0.2790524363517761,
           0.1313253492116928,
           0.027231590822339058,
           0.11225754767656326,
           0.43984875082969666,
           0.044446200132369995,
           0.5469399094581604,
           0.04206858575344086,
           0.1480218917131424,
           0.05786178633570671,
           0.11154814809560776,
           0.16651234030723572,
           0.14362531900405884,
           0.026340512558817863,
           0.088582843542099,
           0.07208326458930969,
           0.11168353259563446,
           0.10798273980617523,
           0.40184926986694336,
           0.25022873282432556,
           0.17755819857120514,
           0.16663379967212677,
           0.11102316528558731,
           0.16980108618736267,
           0.13201549649238586,
           0.20196478068828583,
           0.16091357171535492,
           0.11737697571516037,
           0.16214199364185333,
           0.17662134766578674,
           0.07545874267816544,
           0.14106503129005432,
           0.18568946421146393,
           0.13002263009548187,
           1.039513349533081,
           0.191276416182518,
           1.038540005683899,
           0.13973590731620789,
           1.030260682106018,
           0.18426719307899475,
           0.15608102083206177,
           0.028071900829672813,
           1.3672635555267334,
           0.1475050151348114,
           0.0778193548321724,
           0.1974591612815857,
           1.0440987348556519,
           0.12993410229682922,
           0.38718995451927185,
           0.10971251130104065,
           0.1901184320449829,
           0.10916697978973389,
           0.24622297286987305,
           0.13634754717350006,
           0.1573626846075058,
           0.15278077125549316,
           0.16753071546554565,
           0.25634872913360596,
           0.14900365471839905,
           0.0795404464006424,
           7.364580154418945,
           0.13133686780929565,
           0.11214838922023773,
           0.07278481125831604,
           0.03284572809934616,
           0.41986796259880066,
           0.111074298620224,
           0.1658150851726532,
           0.18911035358905792,
           0.17525672912597656,
           0.18987546861171722,
           0.3899165093898773,
           1.0318608283996582,
           0.276873379945755,
           0.20699423551559448,
           0.195530965924263,
           0.16209916770458221,
           0.21419984102249146,
           0.31226906180381775,
           0.11190027743577957,
           1.1101547479629517,
           2.2350199222564697,
           0.13019129633903503,
           0.1412736028432846,
           0.11195407807826996,
           0.12971150875091553,
           0.058049749583005905,
           1.2315922975540161,
           0.11151745170354843,
           0.16127535700798035,
           0.04215399920940399,
           0.4095078706741333,
           0.1538245975971222,
           1.205222249031067,
           0.4160816967487335,
           0.16317926347255707,
           0.11062892526388168,
           0.2834751605987549,
           0.17455214262008667,
           0.35127681493759155,
           0.42887648940086365,
           0.1222030520439148,
           1.0400872230529785,
           0.16552308201789856,
           0.11299928277730942
          ],
          "coloraxis": "coloraxis",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813
         ],
         "xaxis": "x",
         "y": [
          1.0596235524053164,
          5.222939366879672,
          1.3153578159028463,
          0.7743810974391145,
          1.7963205691987447,
          1.395134579818862,
          0.6955637298854036,
          0.762301858547513,
          1.4089857455903463,
          0.8295511566432161,
          2.9825222181237265,
          1.3565565463715963,
          3.093569805747583,
          1.2119481940018524,
          0.9323602977551921,
          1.2381799597489227,
          0.7698358856471224,
          1.3155828830415182,
          0.8189272247584505,
          2.9452433628318584,
          0.9172521892346843,
          0.9558740917005046,
          1.1526143927323211,
          3.3757478814376007,
          0.5734201732434734,
          2.83758544921875,
          0.7897718678350039,
          3.9048894735483017,
          1.110480604500605,
          0.788807517603825,
          1.4823790958949488,
          0.9614397961160392,
          5.364502555445622,
          0.3485356659448442,
          1.2716706374595894,
          1.2530744452225555,
          1.396349493381198,
          2.8131666685405516,
          2.9419546629253173,
          1.022935701453168,
          3.233421526457132,
          1.481810004024183,
          0.47259085518973265,
          1.734365463256836,
          0.6891111646379748,
          5.006000113698233,
          5.347661723261293,
          3.1240510477603074,
          2.981152584678247,
          1.8181037902832031,
          1.7116300222036003,
          1.0486971813699455,
          1.3172785159760885,
          2.9448638004539287,
          3.219360683275305,
          0.9824186626233562,
          2.729572296142578,
          1.878136243976531,
          2.6519475369840055,
          0.8255659404553874,
          0.6311506592066927,
          2.695503750362912,
          0.24265431175547292,
          0.35705769963625045,
          3.7065980093819775,
          1.3084303256684713,
          6.9884958596065125,
          1.1082541424295158,
          7.262609730596125,
          5.995832427474092,
          3.431328494991874,
          3.2362367730391632,
          0.6890144348144531,
          1.771291732788086,
          2.183797836303711,
          1.5934645053559713,
          1.0259855169998993,
          2.885341975999914,
          1.2186944861161102,
          2.2186431884765625,
          1.9425131198579244,
          4.734191791431323,
          0.9567228618421062,
          1.0785643536111564,
          4.026927774602715,
          8.156143330345468,
          1.3640714999848775,
          2.216039326565326,
          0.516623677434147,
          2.805151258196151,
          3.2704256649675045,
          0.4524346680200395,
          3.7489964621407665,
          0.4216799103053255,
          1.359905850570815,
          1.8240909576416016,
          1.3856076949682006,
          3.8798873023649207,
          2.076900151150287,
          8.708111132605602,
          2.239270952012804,
          0.9308019939221843,
          0.6093356294452015,
          1.7470930060561827,
          0.7077966991223796,
          1.030676551487133,
          4.248149871826172,
          2.1815698411729603,
          4.941338130405972,
          0.775332864406888,
          0.9562631908215984,
          5.033212256642569,
          0.9256407085217937,
          4.8579038130034,
          0.5959581695826692,
          3.100703446761422,
          2.9796839262309813,
          2.883924352711645,
          5.038608145924796,
          0.8054003082545442,
          2.926401993324019,
          1.0621039349099846,
          5.061948274311266,
          3.213011119676672,
          0.23373794555664062,
          0.9548956218518718,
          2.7406768798828125,
          3.112915370775305,
          1.465898313020407,
          3.055666973716333,
          1.0579622517461367,
          5.85403278895787,
          3.1300071218739376,
          1.5655623844691675,
          3.666729648556327,
          7.429803914037244,
          1.0265882740850039,
          3.577895683817344,
          2.033610174589068,
          1.2645461040994377,
          2.5088462829589844,
          1.0987051258916445,
          1.6281310490199488,
          1.0447996388310976,
          2.841022491455078,
          3.5083872871061317,
          1.8113008405341482,
          0.831118997219388,
          2.031896260159076,
          5.326454764918278,
          0.9553095776101799,
          0.9858138042947502,
          1.688467633407729,
          7.030446085436591,
          1.1242388020391054,
          6.036436065169404,
          2.507319190285422,
          1.4492490668045868,
          0.4293624774829752,
          4.067082541329521,
          0.7218202911647005,
          4.811097596821032,
          1.3043020148026336,
          2.671795895225122,
          2.4976816679302,
          1.112504793250043,
          1.934127447740087,
          0.5838346770315468,
          5.167862767758578,
          7.197710379576071,
          3.0549994016948485,
          4.870364737721671,
          3.182178829027258,
          3.06619295866593,
          2.83702230875471,
          2.1254947876261774,
          3.14181551725968,
          3.168545100999914,
          0.29692953986090487,
          2.9919214750591063,
          5.148002122577868,
          5.050954413624991,
          1.592664873277819,
          0.8103117309840364,
          3.0812540556255126,
          2.9580702823875225,
          2.209270265367296,
          3.197048518968664,
          0.9792345295781679,
          7.307248488716457,
          2.706256866455078,
          6.764116322228668,
          2.9944338840720928,
          0.5426145854749187,
          0.81264174611945,
          3.2481106725232376,
          2.981381897377757,
          2.9762335325542235,
          0.9132334056653484,
          2.771935944008616,
          0.9676233592786296,
          4.832746402637378,
          0.7397665344508333,
          3.020665649819163,
          4.8691974403583895,
          3.298828980018355,
          1.1254575628983368,
          2.6346445623433787,
          5.035941672536124,
          3.0106897856059813,
          3.0225840116802,
          2.8516535801170146,
          2.8928408664939678,
          1.2064931769120086,
          1.31483138768019,
          3.477295597042655,
          2.643227139034787,
          2.9421401066062725,
          1.070339037024457,
          2.9558444065330303,
          1.5744673687478752,
          1.679318137790844,
          0.7639250122340364,
          0.7956194244654817,
          4.124326669944908,
          0.9230734172620281,
          2.9102945829692626,
          2.780893325805664,
          1.4860202244349878,
          0.17673811511458482,
          1.3197240584935912,
          4.636411261769522,
          1.0975473652715273,
          1.117784299348532,
          5.423088676051091,
          3.493410785641288,
          1.0718504864236564,
          4.777316944019214,
          0.7605814300807161,
          0.8089517914088411,
          0.1434853990501317,
          3.7007120724382077,
          0.9906214009160585,
          1.161618985627829,
          1.3773643493652337,
          4.112094705755059,
          2.853682999062327,
          3.2270261864913117,
          2.1020055677069998,
          3.042992799178414,
          0.9489713969983562,
          1.1107165295144767,
          0.9648149739141054,
          2.9091677707908428,
          0.778790887478177,
          0.9770094830056877,
          2.913783554482249,
          3.084649136191919,
          3.0269327665630126,
          0.9262930217542156,
          3.2949697594893586,
          1.3817583438569478,
          0.917395301487133,
          1.0811575184697695,
          1.28333724705519,
          2.6882739109275615,
          0.9740301433362468,
          0.1214567485608562,
          0.6189627014430208,
          2.968648007041528,
          1.1257532368535585,
          0.5452474914820833,
          0.8843874298365755,
          3.1364643262780234,
          1.2310331244217743,
          1.2359826941239227,
          0.7776884399684114,
          0.9305120769299968,
          5.029162858661852,
          4.668998216327868,
          3.028554012900903,
          1.559699811433493,
          3.2798559289229523,
          1.1463563818680633,
          1.1633508581864227,
          0.9397009144658632,
          0.3929734999133707,
          1.726256859011766,
          1.1910207648026336,
          1.6278654452973775,
          0.11503970036741151,
          3.4577529029508582,
          2.059305503720143,
          0.0058611572765912,
          1.3161283847505025,
          2.570735458779124,
          0.22683948423804168,
          0.31690228571657286,
          0.1012591064953412,
          1.53837142452117,
          0.7767595611842317,
          2.1695237313547437,
          1.4565764835902613,
          1.9021077309885328,
          3.855847080196952,
          1.5142358349215606,
          2.799245834350586,
          1.9464823510035991,
          2.919231414794922,
          0.22722095396460418,
          5.995409836640228,
          2.0177810038995325,
          2.1977638151587513,
          6.196784973144531,
          3.9081945888331653,
          3.713004554190288,
          2.7615187508719323,
          1.6221231029879668,
          2.950376038002757,
          3.7257048682828895,
          3.6356866019112744,
          1.355938565414565,
          0.0952166260265912,
          1.7231351491567253,
          0.16778034117163543,
          3.1636154340661093,
          0.6886858258928577,
          2.4981968503038416,
          0.22005081176757812,
          5.575581339608249,
          3.3616574195123476,
          4.5273731651656135,
          3.508290567705707,
          1.6570884159633081,
          3.65381785801479,
          4.203964060003106,
          0.646090921047513,
          4.007397448430295,
          2.9491171879051006,
          4.773938092318447,
          2.6594161987304688,
          0.008846157886942763,
          2.2189603711737966,
          2.084375753635314,
          1.8193363096655872,
          3.668847525992046,
          3.798869574942241,
          1.32117904393019,
          2.3891654130889144,
          0.6431535993303577,
          1.8354431499134414,
          1.205097586421644,
          3.056481411582544,
          1.7607646104766097,
          5.427989221388291,
          1.719531547732469,
          0.11906039128538026,
          0.23860401060522918,
          0.33818067021730513,
          0.752921513148717,
          5.993186392435213,
          3.8066151526666445,
          1.7037774678823112,
          3.6796641000887256,
          0.6554865155901233,
          0.5288097278491861,
          0.24524158384741668,
          1.5487910679408472,
          1.7309934255239128,
          2.0837176588715103,
          3.7526566641671337,
          1.9971698073090103,
          1.5551082066127222,
          1.7194181796723775,
          3.541869440386371,
          0.5430198297268021,
          1.568608420235769,
          3.64118358067104,
          2.8871645969627178,
          2.1172145750464466,
          0.16406398866234895,
          0.5966982160295764,
          2.0246663953437185,
          5.775854383196151,
          3.462851801226215,
          2.423090496578732,
          3.5862557547433056,
          3.640496695913921,
          3.7244772562166553,
          1.3067804691010885,
          1.7844867706298828,
          2.1912574768066406,
          2.0772879866302993,
          1.9746367714621798,
          6.381152024140228,
          0.3848044557391468,
          5.380814200953434,
          3.6569914468904834,
          0.8118956335659675,
          1.8354736674915664,
          1.687757646715319,
          0.27890642227665197,
          1.4851313999720972,
          3.7751745828768115,
          1.9096444652926543,
          1.9138189221991873,
          0.187519492172612,
          5.547430329403635,
          3.8347394125802197,
          2.590227642574826,
          1.7742762681914535,
          1.738982689089891,
          2.822399139404297,
          0.11723178770483855,
          1.384421002548354,
          2.693222561398068,
          2.2427373086252516,
          0.7806619964869661,
          2.045043480105516,
          2.844504406577661,
          0.11959444890256776,
          1.7339153289794922,
          5.888617523445571,
          2.0083843735623965,
          4.043166841779438,
          1.304476391952651,
          0.3766580397082926,
          0.3991026760132854,
          1.9182230736598491,
          2.0167716292084243,
          0.08057736168223073,
          1.359398495834487,
          4.342010324651543,
          1.339560162704604,
          1.203590192292868,
          0.12389904115258332,
          1.427706372421401,
          18.19750114766563,
          1.3386808749848775,
          0.019701422714604178,
          3.8757198743583743,
          7.092366354806082,
          1.819234848022461,
          2.8021214108507166,
          0.07213162193613698,
          5.457751281990493,
          0.5082237140552408,
          0.10024821171995058,
          0.6883196197779817,
          5.042012763234366,
          3.587348665509907,
          4.683601276294604,
          2.0844882872046497,
          4.940804072788785,
          5.547793783792635,
          2.0415453953025615,
          0.6553491864885608,
          2.9389567417381084,
          1.904906761355516,
          0.410575321742467,
          0.1632446661228073,
          1.9084421064032888,
          0.3311361585344592,
          2.9135050815818584,
          1.6657023546172347,
          1.8170236156832793,
          0.3881460005237223,
          2.066862419003346,
          3.3890139655729286,
          0.06348025212522401,
          1.3030039188081197,
          3.765179355587577,
          2.159885778659728,
          2.692530193844357,
          1.3031355258637838,
          2.8808627170799053,
          2.8001537322998047,
          0.03091091062964324,
          1.6052829197474878,
          0.6683801923479358,
          2.1459811476410415,
          4.798395053760425,
          1.6873278734160628,
          1.7553954240752425,
          3.5478051093316836,
          0.7942690216334505,
          4.805698291675464,
          1.73212577075493,
          3.685212577261577,
          1.6282473972865503,
          3.7230088370186962,
          3.4267050819059364,
          0.5190119062151233,
          1.6860919115020003,
          3.6825308450838428,
          5.592259802469393,
          4.9428573372089755,
          1.5020948764497213,
          0.5790151868547717,
          0.29822020097212487,
          3.938357795157085,
          1.3663774844819478,
          1.8754420396758285,
          1.464012518161681,
          0.6481069837297717,
          3.5293629554010195,
          1.8283496019316878,
          3.669679129995952,
          1.5840019290730112,
          1.313408505600112,
          4.776651927403043,
          1.9739023949489116,
          2.7355213165283203,
          3.515960016558246,
          1.8627229596747732,
          2.9657816929099834,
          1.6492086764985494,
          7.648175588468227,
          1.6811366197539535,
          0.5363838092700846,
          2.1572137738837576,
          3.453951557125663,
          2.6708903354881084,
          1.4420157841273706,
          0.10414356138647918,
          2.737506866455078,
          1.7007257100698112,
          2.8263473510742188,
          3.8461661467681054,
          1.7838426944428853,
          5.456947928980778,
          1.5445650000321258,
          0.36299437445563143,
          2.0005575920924663,
          0.7657694183619661,
          3.63272980720766,
          3.8595940726143994,
          3.8224761085172645,
          0.7960657440455599,
          3.5537001685758582,
          3.665629828848491,
          0.009233963391011457,
          3.4550635413785926,
          1.597960810507498,
          3.603849138532368,
          3.862452553921056,
          0.587668827601842,
          0.12063204655881776,
          2.7847633361816406,
          0.6968931470598498,
          1.9009557630194998,
          5.638539103280124,
          1.6565629598256706,
          1.9032279423304956,
          4.020173514761577,
          3.606772144283866,
          4.00642470062756,
          0.6433080945696155,
          2.772247314453125,
          1.4452220371791284,
          3.486592569658832,
          1.1123040297935738,
          0.1936220441545764,
          3.8034188406808056,
          0.6954607282366077,
          4.384313174656459,
          4.215801239013672,
          1.7265377044677734,
          1.6592874446836845,
          0.5517646686450846,
          1.6126050868955986,
          1.5659701305886955,
          1.3242349544493095,
          3.083714692488961,
          1.448832503887786,
          3.940510546574826,
          2.6355261721853473,
          3.7427922417135804,
          3.5798156613209198,
          2.3604290585557948,
          0.46729611168223073,
          0.3460056201831705,
          1.8082027435302734,
          5.552778534970042,
          0.8333235435115469,
          2.4194412231445312,
          1.6743001857725517,
          0.35597241826418013,
          0.5587095533098498,
          4.8028682806552965,
          2.005357411282123,
          2.5385889926199177,
          1.5211016055756978,
          2.2823448181152344,
          7.866038178975604,
          0.8705151656578316,
          1.3220365423905243,
          3.455639560665702,
          4.929002235675682,
          4.115575617009942,
          5.844216831394885,
          4.585644188573806,
          3.5243466910669365,
          1.3413800948705443,
          2.21929931640625,
          5.564045695076999,
          1.2746705928770439,
          0.7786885775052568,
          4.7500118353427965,
          0.8066847571011238,
          0.6714536041772661,
          4.333216082148191,
          0.6853975568498889,
          3.6224839346749462,
          1.198905755977819,
          0.928030277120655,
          2.5361638455777555,
          5.048327994557608,
          4.231815302147057,
          1.3616819137182006,
          1.1143614727517814,
          5.531222132454928,
          0.6198768615722656,
          0.25489056696657286,
          0.1442253009693033,
          1.2008932013260711,
          0.6425305880033036,
          1.3675966182676689,
          1.4395027160644531,
          0.9846017856409048,
          2.6668968200683594,
          4.599050942113845,
          1.4196323459431284,
          3.3839113335860382,
          8.463949812560525,
          2.029363301174701,
          6.846481180636683,
          12.225078582763672,
          8.025507115135508,
          6.346773147583008,
          2.8701170559587155,
          0.913748050558155,
          10.212214878627233,
          5.979652389021943,
          6.60675155569654,
          2.050386741513112,
          0.25657324357466393,
          2.5805142025987635,
          3.2793562035811554,
          2.3170235257188807,
          6.45265798748664,
          2.3274128537218104,
          0.6172937665666858,
          0.34891141362550826,
          0.06993435631113698,
          1.3071085330659322,
          0.0945604980969037,
          1.0525617354955443,
          1.6636621114369987,
          4.838650141006859,
          6.816615618192234,
          3.89108757894547,
          1.0537497478982658,
          0.5357480453232597,
          0.0016916931652630751,
          1.2374661544273629,
          2.4196961026231776,
          1.2515935653295287,
          3.5042851981470147,
          0.870862420681302,
          0.13764234420356303,
          5.528589991341647,
          4.411981951288816,
          0.48348936633528794,
          4.254641523985104,
          1.3098683076746305,
          5.368587277599216,
          3.750598907470703,
          3.36671723990605,
          1.9025751854762554,
          5.853881156090463,
          2.0210197662638727,
          0.14657911853255357,
          2.574299609074826,
          1.5380626894393057,
          1.476002127437269,
          0.5434728072861503,
          3.4780261115690223,
          2.676458874264279,
          2.4152790559541195,
          3.082588527513586,
          0.7115621855764687,
          1.3619238254243307,
          4.159162485374596,
          5.515641486290658,
          4.673972780459398,
          0.8758345298396719,
          5.446372252244215,
          2.517728917738971,
          1.6669263759580986,
          1.2991151565160521,
          1.2378970554896753,
          1.0182806927224846,
          2.407679806236459,
          6.107954009505342,
          0.491416386195592,
          2.1463638810086856,
          1.3059701675023803,
          0.7792772613795442,
          2.1379360105933216,
          3.1603816488514767,
          3.0623941923442626,
          5.456555586594801,
          1.4018371730174835,
          1.0296642079072846,
          4.167954435972408,
          3.050395062095239,
          0.7507993257962724,
          0.8345751129420442,
          4.318421354917721,
          1.5407590785948173,
          2.6772303500417927,
          1.1422441382157196,
          1.8569122661243789,
          0.5209667102710611,
          2.204601075914171,
          3.547719341213421,
          2.0078626538886404,
          2.5320105471853473,
          3.1511663957075644,
          0.5210786269882988,
          1.8929106499537944,
          1.8132502343043804,
          0.5289044784287285,
          0.3063952607928577,
          4.88425500052316,
          4.559979290043543,
          6.50636892498664,
          0.4301511139428911,
          0.9980264964856609,
          3.687336080214557,
          1.2781762832250365,
          1.0054022747537346,
          2.9141072240369095,
          3.3500673394454132,
          3.297372930190143,
          0.820905145290677,
          2.5387682956931865,
          2.5621485629324177,
          0.3425713867700395,
          1.0096694946289055,
          3.7244722466719757,
          6.2397613525390625,
          5.565781382332858,
          0.041190612414652605,
          0.7008515686548051,
          3.9041889600517337,
          5.930029364193189,
          4.61409610812947,
          0.5967011855820488,
          4.248205184936523,
          4.6440872580318135,
          5.105273951654848,
          0.5781293319443535,
          1.4651881626674097,
          2.175061967637804,
          0.9208347320556634,
          4.015722101384942,
          1.1367815266484804,
          1.1502419800317583,
          4.600048485448806,
          0.6354326520647327,
          1.8403644561767578,
          1.6556348720518486,
          0.3120002746582031,
          0.381923803762227,
          2.0944420365262637,
          0.9243128546353034,
          0.8064329870815925,
          1.3105131503755025,
          4.7005480688971435,
          4.534020015171597,
          0.537716040090352,
          3.3228093171731032,
          1.0262144337529726,
          2.4254963498155604,
          1.4940418308064096,
          1.9425121523299307,
          2.5657496371511677,
          2.5584216160056865,
          2.9810933977644005,
          0.5954450879778186,
          2.93827963297346,
          1.3566465133275756,
          0.5056119369248222,
          0.634866861196663,
          1.3242921749082939,
          1.9088598992213726,
          1.783926010131836,
          0.17468877669868021,
          0.4997006744897661,
          2.1036624908447266,
          2.80594183016224,
          0.6296620773056816,
          0.339743180708453,
          0.6334566388811389,
          6.705871000128276,
          1.4760028294154566,
          0.538166563389666,
          0.6500211166123222,
          3.5141728934595147,
          6.101097394835273,
          2.6363153997457225,
          1.3005490022547086
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Uncertainty"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Uncertainty Distribution for CONFD for average RR error"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Samples"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Error Avg Breath(BrPM)"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"c9f74d44-247d-4235-9766-8ade224bfa2d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c9f74d44-247d-4235-9766-8ade224bfa2d\")) {                    Plotly.newPlot(                        \"c9f74d44-247d-4235-9766-8ade224bfa2d\",                        [{\"hovertemplate\":\"Samples=%{x}<br>Error Avg Breath(BrPM)=%{y}<br>Uncertainty=%{marker.color}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":[0.11800112575292587,0.13804320991039276,0.0350194051861763,0.12791873514652252,1.0306295156478882,0.2656440734863281,0.2687962055206299,0.2813800275325775,0.18250875174999237,0.2670319378376007,0.185589998960495,0.17697076499462128,0.17025817930698395,0.1275278627872467,0.1647997498512268,0.16639071702957153,0.12341368943452835,0.03430389240384102,0.13904625177383423,0.14213185012340546,0.11109805852174759,0.037542924284935,0.25056809186935425,0.1491357982158661,1.0356768369674683,0.102090023458004,0.5625126361846924,0.22729338705539703,0.23960968852043152,0.4117746651172638,0.10128413885831833,0.06663476675748825,0.12754255533218384,0.14249761402606964,0.12130685150623322,0.12973976135253906,2.297647476196289,0.40126731991767883,0.17922604084014893,0.26012861728668213,0.0007274135714396834,0.29243263602256775,0.5225510597229004,0.2678993046283722,0.0882745310664177,0.1690913587808609,0.6126404404640198,0.1376819759607315,0.14376872777938843,0.0031590028665959835,0.1291901022195816,0.26303568482398987,0.14393535256385803,0.07193301618099213,0.1515328735113144,0.18119607865810394,0.2787298262119293,0.03226647153496742,0.14395451545715332,0.26040831208229065,0.2906903326511383,0.05117477476596832,0.4164206385612488,0.05256551504135132,0.14520764350891113,0.029106853529810905,0.07890468090772629,0.17985107004642487,0.17864638566970825,0.1430080085992813,0.14200548827648163,0.013185170479118824,1.1458992958068848,0.1125371977686882,0.06426199525594711,0.44541123509407043,0.17631955444812775,1.0499247312545776,0.15490032732486725,0.13923609256744385,2.0050840377807617,0.2564767003059387,0.13027635216712952,0.17106159031391144,0.043346598744392395,0.41867485642433167,0.16984230279922485,0.5399168133735657,0.06674906611442566,0.11401861906051636,1.0505625009536743,0.4791984558105469,0.2170945703983307,0.5569477677345276,0.17721718549728394,0.06263849884271622,0.12657420337200165,1.094722867012024,0.11185184121131897,0.15261593461036682,0.128391832113266,0.18072271347045898,0.4483061134815216,0.09689084440469742,0.3381749093532562,0.121043860912323,0.20713236927986145,0.1933547854423523,0.10203687101602554,0.18159660696983337,0.032806091010570526,0.11194337904453278,0.10999803990125656,5.965674877166748,0.4168541133403778,0.25221744179725647,0.15646009147167206,0.026934612542390823,0.045153338462114334,0.03359484300017357,1.034989356994629,0.2351488173007965,0.22259990870952606,0.059478823095560074,0.07805730402469635,0.15906496345996857,0.15580429136753082,0.13951829075813293,1.0525990724563599,0.12730661034584045,0.1659907102584839,0.14144153892993927,0.20401664078235626,0.22123995423316956,0.4307885766029358,0.127266988158226,0.3159218728542328,0.04863940551877022,0.15406525135040283,0.5324276089668274,0.630420446395874,0.0458647795021534,0.43097198009490967,0.4551717936992645,0.14199112355709076,0.15841369330883026,0.08770525455474854,0.09069560468196869,0.031830254942178726,0.19046223163604736,0.05984167754650116,0.21851693093776703,1.0468133687973022,0.12734632194042206,0.0671614557504654,0.11048153787851334,0.04417915269732475,1.0516936779022217,0.160441055893898,0.08945313096046448,0.2380475252866745,1.2344599962234497,0.26153990626335144,0.5934309959411621,1.053792953491211,0.1557633876800537,0.1402558982372284,0.5653062462806702,0.16360829770565033,1.0366543531417847,0.14454804360866547,0.35322627425193787,0.03335058316588402,0.17838886380195618,0.23708882927894592,0.11331154406070709,0.16488765180110931,0.14632277190685272,0.3404153287410736,0.15701621770858765,0.12938064336776733,0.0317869670689106,0.13231615722179413,0.07006049901247025,0.0027386050205677748,0.0592387393116951,0.167439803481102,0.039508841931819916,0.4235692322254181,0.16265352070331573,0.16325971484184265,0.06643706560134888,0.14405269920825958,1.0429813861846924,0.4338938593864441,0.15703023970127106,0.09807394444942474,0.16509926319122314,0.28216812014579773,0.32110121846199036,0.17743127048015594,0.07483039796352386,0.20715810358524323,0.14456892013549805,0.4065377116203308,0.12699919939041138,0.0606924369931221,0.15011994540691376,0.18703189492225647,0.19371521472930908,0.17100709676742554,0.14203912019729614,0.1149686649441719,0.16804508864879608,0.03623395040631294,0.19259454309940338,0.12808823585510254,0.027315570041537285,0.11197272688150406,0.059720221906900406,0.8857371211051941,1.983691930770874,0.16780264675617218,0.17094409465789795,0.1516384780406952,0.11157236248254776,0.422665536403656,0.11517952382564545,0.037333693355321884,0.13451620936393738,0.14682313799858093,1.0424954891204834,0.3022487759590149,0.05262256786227226,0.15120401978492737,0.16548296809196472,0.30111196637153625,0.1685713529586792,0.12972529232501984,0.03337587043642998,0.1697489321231842,2.0189030170440674,0.22430871427059174,0.20053929090499878,0.05988571420311928,0.2548125386238098,0.23603542149066925,0.05846485123038292,0.9117397665977478,0.3601793646812439,0.03561467304825783,0.18566182255744934,0.1933019757270813,0.2086237668991089,0.2195928990840912,0.18498201668262482,0.0833643302321434,0.1533440202474594,0.11278499662876129,0.11411409825086594,0.11519874632358551,0.18325112760066986,0.11348788440227509,0.1782761961221695,0.23801496624946594,0.5115453004837036,0.008426659740507603,2.4660067558288574,0.5486398339271545,0.19071386754512787,0.17371462285518646,0.9022622108459473,0.16544659435749054,0.23077675700187683,0.12357480823993683,0.11421045660972595,0.11106516420841217,0.17743061482906342,0.35909608006477356,1.3636866807937622,0.24226562678813934,1.034818172454834,0.14154042303562164,0.03680070489645004,0.20307005941867828,0.3273506462574005,0.13898511230945587,0.14247415959835052,0.11272794008255005,1.0483673810958862,0.15454991161823273,0.12780211865901947,0.14485062658786774,0.25221455097198486,0.03488897159695625,1.0323071479797363,0.1674206703901291,1.033829689025879,0.0689767524600029,0.007784477435052395,0.11221156269311905,0.4101167619228363,0.1211933121085167,1.032975196838379,1.1267160177230835,0.07952306419610977,0.03577018156647682,0.013132937252521515,0.2378024160861969,0.20243270695209503,0.12872450053691864,0.030983613803982735,0.14032214879989624,0.1981728971004486,0.1453404575586319,0.17165322601795197,0.028034847229719162,0.11591378599405289,0.0024092255625873804,0.4532170295715332,0.12827222049236298,0.1109728068113327,0.10276342183351517,0.1398802548646927,0.1456063836812973,0.13920941948890686,0.052319202572107315,0.19130654633045197,0.15157420933246613,0.10346394777297974,0.1464606076478958,0.10896273702383041,0.15445439517498016,0.41076740622520447,0.2178698480129242,0.46009862422943115,0.3721928000450134,0.11130858212709427,0.1137920394539833,0.14219246804714203,0.42718270421028137,0.23382684588432312,1.0507190227508545,0.4403797686100006,1.0322844982147217,0.03203305974602699,0.18111997842788696,0.12971629202365875,1.9912244081497192,0.04135902598500252,0.17234519124031067,0.29563194513320923,0.1283438801765442,0.28972992300987244,0.08075948804616928,0.07797399163246155,0.06288701295852661,0.18586456775665283,0.17536792159080505,0.13553281128406525,1.030644416809082,1.0549125671386719,0.1693699061870575,0.07082200050354004,0.03625206649303436,0.05884015932679176,0.09955830127000809,0.14607828855514526,0.26075857877731323,0.22761112451553345,0.27223050594329834,0.0788191631436348,0.2236417680978775,1.0994024276733398,0.17652927339076996,1.9982644319534302,0.159513920545578,0.03830885514616966,0.16400490701198578,0.1666349619626999,1.0451931953430176,0.153423473238945,0.28277936577796936,0.03375546634197235,0.11948956549167633,0.5695326328277588,0.07534752786159515,0.19402620196342468,0.11771339178085327,0.08466627448797226,0.1887107789516449,0.0808899998664856,0.009257188066840172,1.3430309295654297,1.033473014831543,0.14468468725681305,0.13017770648002625,0.026182997971773148,0.028734752908349037,0.03700997307896614,0.31238847970962524,0.16768264770507812,0.08902325481176376,0.19582514464855194,0.9114909172058105,0.11177542805671692,0.16725192964076996,0.11447802186012268,0.6027058959007263,0.22134026885032654,0.1284007877111435,0.1297445148229599,0.05855565890669823,0.1716039925813675,0.148948535323143,0.17871737480163574,0.1553872525691986,0.1128711849451065,1.050357699394226,0.3689870536327362,0.05740739777684212,0.2766477167606354,0.22361113131046295,0.19150729477405548,1.0329620838165283,0.017470046877861023,0.032457638531923294,1.0568485260009766,0.042033080011606216,0.11134647578001022,0.11267485469579697,0.11383020132780075,1.065482497215271,0.21702435612678528,0.24715979397296906,1.1131083965301514,0.356523722410202,2.75298810005188,0.1327715367078781,0.26886892318725586,0.12472398579120636,0.03318971022963524,0.060074273496866226,1.388079047203064,0.11213868111371994,1.1452350616455078,0.026674970984458923,0.12038718909025192,0.2188684046268463,0.1312306672334671,0.11199545115232468,0.1772671490907669,0.1900649517774582,0.034299448132514954,0.2194005846977234,1.9906649589538574,0.03618817403912544,0.014476734213531017,0.41221943497657776,0.523613691329956,0.17328794300556183,0.14219719171524048,1.0591270923614502,0.11978091299533844,0.07522009313106537,0.4710986018180847,0.027101291343569756,0.02875090204179287,0.11935850232839584,0.11263542622327805,0.15480975806713104,1.0478227138519287,0.16364911198616028,0.148843914270401,0.019834985956549644,0.12697280943393707,0.1329641193151474,0.42908236384391785,0.4193737506866455,0.1553591638803482,0.13391008973121643,0.11285705119371414,0.06115679815411568,0.16917750239372253,0.16406972706317902,0.1806732714176178,0.11390915513038635,0.1483335644006729,0.08324477076530457,0.40037667751312256,0.29395416378974915,0.15225189924240112,0.3499993681907654,0.060697041451931,0.13057945668697357,0.06903287768363953,0.3791328966617584,0.3804436922073364,0.26791030168533325,0.19537118077278137,0.4136612117290497,0.18029522895812988,0.2482122927904129,2.310615301132202,0.15770605206489563,0.12345151603221893,0.2714194655418396,0.12741360068321228,0.12048288434743881,0.14399248361587524,0.5172065496444702,0.10133354365825653,0.45003074407577515,0.22631026804447174,0.026050424203276634,0.08458197116851807,1.0577986240386963,0.15430808067321777,0.049870800226926804,0.10706634819507599,1.0602997541427612,0.2069624364376068,0.4703746438026428,0.19839581847190857,0.1966746598482132,0.1683523803949356,0.12904290854930878,0.06333725154399872,0.053434427827596664,1.0809316635131836,0.4379236698150635,1.0270001888275146,0.18682189285755157,0.16956175863742828,0.18760348856449127,0.2867591083049774,0.4484640657901764,1.032275915145874,0.12944728136062622,0.4664052724838257,0.03214249759912491,0.10287179797887802,0.14579011499881744,0.11092346906661987,0.09022451192140579,0.10596123337745667,0.14571017026901245,0.08436188101768494,0.04464475437998772,0.07463128864765167,0.20336025953292847,0.15380750596523285,0.07628361135721207,1.029470443725586,1.041930079460144,0.2687359154224396,0.11194417625665665,0.13076341152191162,0.11281082779169083,0.07617490738630295,0.026528360322117805,0.261626660823822,1.1598762273788452,0.42503058910369873,0.08109290152788162,7.1709113121032715,0.1338677555322647,0.4407767951488495,0.04493878781795502,0.1183113157749176,0.12691275775432587,1.053215503692627,1.0559425354003906,0.12748880684375763,0.6073470115661621,0.2585568130016327,0.1879478543996811,0.11788252741098404,1.1958410739898682,0.02424342930316925,1.0363342761993408,0.27726420760154724,0.16731321811676025,0.13683442771434784,0.06821060180664062,0.4216727614402771,0.16876918077468872,0.13051928579807281,0.16931892931461334,0.1121673434972763,0.1741965264081955,0.153993621468544,0.6287137866020203,0.18887348473072052,0.27308526635169983,1.0383113622665405,0.4212327003479004,0.20713847875595093,0.05235126242041588,0.15406735241413116,0.12566640973091125,0.1384917050600052,0.112112857401371,0.17405565083026886,0.1893531233072281,0.03674692660570145,1.0493557453155518,0.21856500208377838,0.017729641869664192,0.17375154793262482,1.0489994287490845,0.12370911240577698,0.0635322779417038,0.026101525872945786,0.050583574920892715,0.25013014674186707,0.19997410476207733,0.042222581803798676,0.0038036240730434656,0.07118254154920578,0.1713070273399353,0.04985908791422844,1.0374658107757568,1.1084036827087402,0.8758909702301025,0.17531633377075195,0.000787279277574271,0.5286270976066589,0.8692032694816589,0.45204275846481323,1.0402357578277588,0.04972778260707855,0.2022101730108261,0.4750586450099945,0.282764732837677,0.141051784157753,0.08888788521289825,0.3051868677139282,0.16623127460479736,0.41199520230293274,0.0014008121797814965,0.1960178017616272,0.40853893756866455,0.05833682045340538,0.40817469358444214,0.1288788765668869,0.42314237356185913,0.6222479939460754,0.11022179573774338,0.06385663151741028,0.11351791024208069,0.10715416818857193,0.1109633594751358,0.14229750633239746,0.19468806684017181,0.024149619042873383,0.02622044086456299,0.4070632755756378,0.09146425873041153,0.2953895628452301,0.03843690827488899,0.12253016233444214,0.31189030408859253,0.12374501675367355,0.4438766539096832,0.08157966285943985,0.28394776582717896,0.26211997866630554,0.14931489527225494,0.14437198638916016,0.23153267800807953,0.05539543554186821,0.14908216893672943,1.0504264831542969,0.3452487885951996,0.12795093655586243,0.16540458798408508,0.18393903970718384,0.1057143285870552,0.06865322589874268,0.14806613326072693,0.15227490663528442,0.03805587813258171,1.4372351169586182,1.0375359058380127,0.27189674973487854,0.23554934561252594,0.11200625449419022,0.021226054057478905,0.09012197703123093,0.2519966661930084,0.28351831436157227,0.25267305970191956,0.1260865032672882,1.0552219152450562,0.16955861449241638,0.08441165834665298,0.13979128003120422,1.9658358097076416,0.08000122755765915,0.29635366797447205,1.7213727235794067,0.12416025996208191,0.07144930213689804,0.4345523715019226,0.4151330888271332,0.4258694648742676,0.3129725158214569,0.13149426877498627,0.2790524363517761,0.1313253492116928,0.027231590822339058,0.11225754767656326,0.43984875082969666,0.044446200132369995,0.5469399094581604,0.04206858575344086,0.1480218917131424,0.05786178633570671,0.11154814809560776,0.16651234030723572,0.14362531900405884,0.026340512558817863,0.088582843542099,0.07208326458930969,0.11168353259563446,0.10798273980617523,0.40184926986694336,0.25022873282432556,0.17755819857120514,0.16663379967212677,0.11102316528558731,0.16980108618736267,0.13201549649238586,0.20196478068828583,0.16091357171535492,0.11737697571516037,0.16214199364185333,0.17662134766578674,0.07545874267816544,0.14106503129005432,0.18568946421146393,0.13002263009548187,1.039513349533081,0.191276416182518,1.038540005683899,0.13973590731620789,1.030260682106018,0.18426719307899475,0.15608102083206177,0.028071900829672813,1.3672635555267334,0.1475050151348114,0.0778193548321724,0.1974591612815857,1.0440987348556519,0.12993410229682922,0.38718995451927185,0.10971251130104065,0.1901184320449829,0.10916697978973389,0.24622297286987305,0.13634754717350006,0.1573626846075058,0.15278077125549316,0.16753071546554565,0.25634872913360596,0.14900365471839905,0.0795404464006424,7.364580154418945,0.13133686780929565,0.11214838922023773,0.07278481125831604,0.03284572809934616,0.41986796259880066,0.111074298620224,0.1658150851726532,0.18911035358905792,0.17525672912597656,0.18987546861171722,0.3899165093898773,1.0318608283996582,0.276873379945755,0.20699423551559448,0.195530965924263,0.16209916770458221,0.21419984102249146,0.31226906180381775,0.11190027743577957,1.1101547479629517,2.2350199222564697,0.13019129633903503,0.1412736028432846,0.11195407807826996,0.12971150875091553,0.058049749583005905,1.2315922975540161,0.11151745170354843,0.16127535700798035,0.04215399920940399,0.4095078706741333,0.1538245975971222,1.205222249031067,0.4160816967487335,0.16317926347255707,0.11062892526388168,0.2834751605987549,0.17455214262008667,0.35127681493759155,0.42887648940086365,0.1222030520439148,1.0400872230529785,0.16552308201789856,0.11299928277730942],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"type\":\"scatter\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0,51.0,52.0,53.0,54.0,55.0,56.0,57.0,58.0,59.0,60.0,61.0,62.0,63.0,64.0,65.0,66.0,67.0,68.0,69.0,70.0,71.0,72.0,73.0,74.0,75.0,76.0,77.0,78.0,79.0,80.0,81.0,82.0,83.0,84.0,85.0,86.0,87.0,88.0,89.0,90.0,91.0,92.0,93.0,94.0,95.0,96.0,97.0,98.0,99.0,100.0,101.0,102.0,103.0,104.0,105.0,106.0,107.0,108.0,109.0,110.0,111.0,112.0,113.0,114.0,115.0,116.0,117.0,118.0,119.0,120.0,121.0,122.0,123.0,124.0,125.0,126.0,127.0,128.0,129.0,130.0,131.0,132.0,133.0,134.0,135.0,136.0,137.0,138.0,139.0,140.0,141.0,142.0,143.0,144.0,145.0,146.0,147.0,148.0,149.0,150.0,151.0,152.0,153.0,154.0,155.0,156.0,157.0,158.0,159.0,160.0,161.0,162.0,163.0,164.0,165.0,166.0,167.0,168.0,169.0,170.0,171.0,172.0,173.0,174.0,175.0,176.0,177.0,178.0,179.0,180.0,181.0,182.0,183.0,184.0,185.0,186.0,187.0,188.0,189.0,190.0,191.0,192.0,193.0,194.0,195.0,196.0,197.0,198.0,199.0,200.0,201.0,202.0,203.0,204.0,205.0,206.0,207.0,208.0,209.0,210.0,211.0,212.0,213.0,214.0,215.0,216.0,217.0,218.0,219.0,220.0,221.0,222.0,223.0,224.0,225.0,226.0,227.0,228.0,229.0,230.0,231.0,232.0,233.0,234.0,235.0,236.0,237.0,238.0,239.0,240.0,241.0,242.0,243.0,244.0,245.0,246.0,247.0,248.0,249.0,250.0,251.0,252.0,253.0,254.0,255.0,256.0,257.0,258.0,259.0,260.0,261.0,262.0,263.0,264.0,265.0,266.0,267.0,268.0,269.0,270.0,271.0,272.0,273.0,274.0,275.0,276.0,277.0,278.0,279.0,280.0,281.0,282.0,283.0,284.0,285.0,286.0,287.0,288.0,289.0,290.0,291.0,292.0,293.0,294.0,295.0,296.0,297.0,298.0,299.0,300.0,301.0,302.0,303.0,304.0,305.0,306.0,307.0,308.0,309.0,310.0,311.0,312.0,313.0,314.0,315.0,316.0,317.0,318.0,319.0,320.0,321.0,322.0,323.0,324.0,325.0,326.0,327.0,328.0,329.0,330.0,331.0,332.0,333.0,334.0,335.0,336.0,337.0,338.0,339.0,340.0,341.0,342.0,343.0,344.0,345.0,346.0,347.0,348.0,349.0,350.0,351.0,352.0,353.0,354.0,355.0,356.0,357.0,358.0,359.0,360.0,361.0,362.0,363.0,364.0,365.0,366.0,367.0,368.0,369.0,370.0,371.0,372.0,373.0,374.0,375.0,376.0,377.0,378.0,379.0,380.0,381.0,382.0,383.0,384.0,385.0,386.0,387.0,388.0,389.0,390.0,391.0,392.0,393.0,394.0,395.0,396.0,397.0,398.0,399.0,400.0,401.0,402.0,403.0,404.0,405.0,406.0,407.0,408.0,409.0,410.0,411.0,412.0,413.0,414.0,415.0,416.0,417.0,418.0,419.0,420.0,421.0,422.0,423.0,424.0,425.0,426.0,427.0,428.0,429.0,430.0,431.0,432.0,433.0,434.0,435.0,436.0,437.0,438.0,439.0,440.0,441.0,442.0,443.0,444.0,445.0,446.0,447.0,448.0,449.0,450.0,451.0,452.0,453.0,454.0,455.0,456.0,457.0,458.0,459.0,460.0,461.0,462.0,463.0,464.0,465.0,466.0,467.0,468.0,469.0,470.0,471.0,472.0,473.0,474.0,475.0,476.0,477.0,478.0,479.0,480.0,481.0,482.0,483.0,484.0,485.0,486.0,487.0,488.0,489.0,490.0,491.0,492.0,493.0,494.0,495.0,496.0,497.0,498.0,499.0,500.0,501.0,502.0,503.0,504.0,505.0,506.0,507.0,508.0,509.0,510.0,511.0,512.0,513.0,514.0,515.0,516.0,517.0,518.0,519.0,520.0,521.0,522.0,523.0,524.0,525.0,526.0,527.0,528.0,529.0,530.0,531.0,532.0,533.0,534.0,535.0,536.0,537.0,538.0,539.0,540.0,541.0,542.0,543.0,544.0,545.0,546.0,547.0,548.0,549.0,550.0,551.0,552.0,553.0,554.0,555.0,556.0,557.0,558.0,559.0,560.0,561.0,562.0,563.0,564.0,565.0,566.0,567.0,568.0,569.0,570.0,571.0,572.0,573.0,574.0,575.0,576.0,577.0,578.0,579.0,580.0,581.0,582.0,583.0,584.0,585.0,586.0,587.0,588.0,589.0,590.0,591.0,592.0,593.0,594.0,595.0,596.0,597.0,598.0,599.0,600.0,601.0,602.0,603.0,604.0,605.0,606.0,607.0,608.0,609.0,610.0,611.0,612.0,613.0,614.0,615.0,616.0,617.0,618.0,619.0,620.0,621.0,622.0,623.0,624.0,625.0,626.0,627.0,628.0,629.0,630.0,631.0,632.0,633.0,634.0,635.0,636.0,637.0,638.0,639.0,640.0,641.0,642.0,643.0,644.0,645.0,646.0,647.0,648.0,649.0,650.0,651.0,652.0,653.0,654.0,655.0,656.0,657.0,658.0,659.0,660.0,661.0,662.0,663.0,664.0,665.0,666.0,667.0,668.0,669.0,670.0,671.0,672.0,673.0,674.0,675.0,676.0,677.0,678.0,679.0,680.0,681.0,682.0,683.0,684.0,685.0,686.0,687.0,688.0,689.0,690.0,691.0,692.0,693.0,694.0,695.0,696.0,697.0,698.0,699.0,700.0,701.0,702.0,703.0,704.0,705.0,706.0,707.0,708.0,709.0,710.0,711.0,712.0,713.0,714.0,715.0,716.0,717.0,718.0,719.0,720.0,721.0,722.0,723.0,724.0,725.0,726.0,727.0,728.0,729.0,730.0,731.0,732.0,733.0,734.0,735.0,736.0,737.0,738.0,739.0,740.0,741.0,742.0,743.0,744.0,745.0,746.0,747.0,748.0,749.0,750.0,751.0,752.0,753.0,754.0,755.0,756.0,757.0,758.0,759.0,760.0,761.0,762.0,763.0,764.0,765.0,766.0,767.0,768.0,769.0,770.0,771.0,772.0,773.0,774.0,775.0,776.0,777.0,778.0,779.0,780.0,781.0,782.0,783.0,784.0,785.0,786.0,787.0,788.0,789.0,790.0,791.0,792.0,793.0,794.0,795.0,796.0,797.0,798.0,799.0,800.0,801.0,802.0,803.0,804.0,805.0,806.0,807.0,808.0,809.0,810.0,811.0,812.0,813.0],\"xaxis\":\"x\",\"y\":[1.0596235524053164,5.222939366879672,1.3153578159028463,0.7743810974391145,1.7963205691987447,1.395134579818862,0.6955637298854036,0.762301858547513,1.4089857455903463,0.8295511566432161,2.9825222181237265,1.3565565463715963,3.093569805747583,1.2119481940018524,0.9323602977551921,1.2381799597489227,0.7698358856471224,1.3155828830415182,0.8189272247584505,2.9452433628318584,0.9172521892346843,0.9558740917005046,1.1526143927323211,3.3757478814376007,0.5734201732434734,2.83758544921875,0.7897718678350039,3.9048894735483017,1.110480604500605,0.788807517603825,1.4823790958949488,0.9614397961160392,5.364502555445622,0.3485356659448442,1.2716706374595894,1.2530744452225555,1.396349493381198,2.8131666685405516,2.9419546629253173,1.022935701453168,3.233421526457132,1.481810004024183,0.47259085518973265,1.734365463256836,0.6891111646379748,5.006000113698233,5.347661723261293,3.1240510477603074,2.981152584678247,1.8181037902832031,1.7116300222036003,1.0486971813699455,1.3172785159760885,2.9448638004539287,3.219360683275305,0.9824186626233562,2.729572296142578,1.878136243976531,2.6519475369840055,0.8255659404553874,0.6311506592066927,2.695503750362912,0.24265431175547292,0.35705769963625045,3.7065980093819775,1.3084303256684713,6.9884958596065125,1.1082541424295158,7.262609730596125,5.995832427474092,3.431328494991874,3.2362367730391632,0.6890144348144531,1.771291732788086,2.183797836303711,1.5934645053559713,1.0259855169998993,2.885341975999914,1.2186944861161102,2.2186431884765625,1.9425131198579244,4.734191791431323,0.9567228618421062,1.0785643536111564,4.026927774602715,8.156143330345468,1.3640714999848775,2.216039326565326,0.516623677434147,2.805151258196151,3.2704256649675045,0.4524346680200395,3.7489964621407665,0.4216799103053255,1.359905850570815,1.8240909576416016,1.3856076949682006,3.8798873023649207,2.076900151150287,8.708111132605602,2.239270952012804,0.9308019939221843,0.6093356294452015,1.7470930060561827,0.7077966991223796,1.030676551487133,4.248149871826172,2.1815698411729603,4.941338130405972,0.775332864406888,0.9562631908215984,5.033212256642569,0.9256407085217937,4.8579038130034,0.5959581695826692,3.100703446761422,2.9796839262309813,2.883924352711645,5.038608145924796,0.8054003082545442,2.926401993324019,1.0621039349099846,5.061948274311266,3.213011119676672,0.23373794555664062,0.9548956218518718,2.7406768798828125,3.112915370775305,1.465898313020407,3.055666973716333,1.0579622517461367,5.85403278895787,3.1300071218739376,1.5655623844691675,3.666729648556327,7.429803914037244,1.0265882740850039,3.577895683817344,2.033610174589068,1.2645461040994377,2.5088462829589844,1.0987051258916445,1.6281310490199488,1.0447996388310976,2.841022491455078,3.5083872871061317,1.8113008405341482,0.831118997219388,2.031896260159076,5.326454764918278,0.9553095776101799,0.9858138042947502,1.688467633407729,7.030446085436591,1.1242388020391054,6.036436065169404,2.507319190285422,1.4492490668045868,0.4293624774829752,4.067082541329521,0.7218202911647005,4.811097596821032,1.3043020148026336,2.671795895225122,2.4976816679302,1.112504793250043,1.934127447740087,0.5838346770315468,5.167862767758578,7.197710379576071,3.0549994016948485,4.870364737721671,3.182178829027258,3.06619295866593,2.83702230875471,2.1254947876261774,3.14181551725968,3.168545100999914,0.29692953986090487,2.9919214750591063,5.148002122577868,5.050954413624991,1.592664873277819,0.8103117309840364,3.0812540556255126,2.9580702823875225,2.209270265367296,3.197048518968664,0.9792345295781679,7.307248488716457,2.706256866455078,6.764116322228668,2.9944338840720928,0.5426145854749187,0.81264174611945,3.2481106725232376,2.981381897377757,2.9762335325542235,0.9132334056653484,2.771935944008616,0.9676233592786296,4.832746402637378,0.7397665344508333,3.020665649819163,4.8691974403583895,3.298828980018355,1.1254575628983368,2.6346445623433787,5.035941672536124,3.0106897856059813,3.0225840116802,2.8516535801170146,2.8928408664939678,1.2064931769120086,1.31483138768019,3.477295597042655,2.643227139034787,2.9421401066062725,1.070339037024457,2.9558444065330303,1.5744673687478752,1.679318137790844,0.7639250122340364,0.7956194244654817,4.124326669944908,0.9230734172620281,2.9102945829692626,2.780893325805664,1.4860202244349878,0.17673811511458482,1.3197240584935912,4.636411261769522,1.0975473652715273,1.117784299348532,5.423088676051091,3.493410785641288,1.0718504864236564,4.777316944019214,0.7605814300807161,0.8089517914088411,0.1434853990501317,3.7007120724382077,0.9906214009160585,1.161618985627829,1.3773643493652337,4.112094705755059,2.853682999062327,3.2270261864913117,2.1020055677069998,3.042992799178414,0.9489713969983562,1.1107165295144767,0.9648149739141054,2.9091677707908428,0.778790887478177,0.9770094830056877,2.913783554482249,3.084649136191919,3.0269327665630126,0.9262930217542156,3.2949697594893586,1.3817583438569478,0.917395301487133,1.0811575184697695,1.28333724705519,2.6882739109275615,0.9740301433362468,0.1214567485608562,0.6189627014430208,2.968648007041528,1.1257532368535585,0.5452474914820833,0.8843874298365755,3.1364643262780234,1.2310331244217743,1.2359826941239227,0.7776884399684114,0.9305120769299968,5.029162858661852,4.668998216327868,3.028554012900903,1.559699811433493,3.2798559289229523,1.1463563818680633,1.1633508581864227,0.9397009144658632,0.3929734999133707,1.726256859011766,1.1910207648026336,1.6278654452973775,0.11503970036741151,3.4577529029508582,2.059305503720143,0.0058611572765912,1.3161283847505025,2.570735458779124,0.22683948423804168,0.31690228571657286,0.1012591064953412,1.53837142452117,0.7767595611842317,2.1695237313547437,1.4565764835902613,1.9021077309885328,3.855847080196952,1.5142358349215606,2.799245834350586,1.9464823510035991,2.919231414794922,0.22722095396460418,5.995409836640228,2.0177810038995325,2.1977638151587513,6.196784973144531,3.9081945888331653,3.713004554190288,2.7615187508719323,1.6221231029879668,2.950376038002757,3.7257048682828895,3.6356866019112744,1.355938565414565,0.0952166260265912,1.7231351491567253,0.16778034117163543,3.1636154340661093,0.6886858258928577,2.4981968503038416,0.22005081176757812,5.575581339608249,3.3616574195123476,4.5273731651656135,3.508290567705707,1.6570884159633081,3.65381785801479,4.203964060003106,0.646090921047513,4.007397448430295,2.9491171879051006,4.773938092318447,2.6594161987304688,0.008846157886942763,2.2189603711737966,2.084375753635314,1.8193363096655872,3.668847525992046,3.798869574942241,1.32117904393019,2.3891654130889144,0.6431535993303577,1.8354431499134414,1.205097586421644,3.056481411582544,1.7607646104766097,5.427989221388291,1.719531547732469,0.11906039128538026,0.23860401060522918,0.33818067021730513,0.752921513148717,5.993186392435213,3.8066151526666445,1.7037774678823112,3.6796641000887256,0.6554865155901233,0.5288097278491861,0.24524158384741668,1.5487910679408472,1.7309934255239128,2.0837176588715103,3.7526566641671337,1.9971698073090103,1.5551082066127222,1.7194181796723775,3.541869440386371,0.5430198297268021,1.568608420235769,3.64118358067104,2.8871645969627178,2.1172145750464466,0.16406398866234895,0.5966982160295764,2.0246663953437185,5.775854383196151,3.462851801226215,2.423090496578732,3.5862557547433056,3.640496695913921,3.7244772562166553,1.3067804691010885,1.7844867706298828,2.1912574768066406,2.0772879866302993,1.9746367714621798,6.381152024140228,0.3848044557391468,5.380814200953434,3.6569914468904834,0.8118956335659675,1.8354736674915664,1.687757646715319,0.27890642227665197,1.4851313999720972,3.7751745828768115,1.9096444652926543,1.9138189221991873,0.187519492172612,5.547430329403635,3.8347394125802197,2.590227642574826,1.7742762681914535,1.738982689089891,2.822399139404297,0.11723178770483855,1.384421002548354,2.693222561398068,2.2427373086252516,0.7806619964869661,2.045043480105516,2.844504406577661,0.11959444890256776,1.7339153289794922,5.888617523445571,2.0083843735623965,4.043166841779438,1.304476391952651,0.3766580397082926,0.3991026760132854,1.9182230736598491,2.0167716292084243,0.08057736168223073,1.359398495834487,4.342010324651543,1.339560162704604,1.203590192292868,0.12389904115258332,1.427706372421401,18.19750114766563,1.3386808749848775,0.019701422714604178,3.8757198743583743,7.092366354806082,1.819234848022461,2.8021214108507166,0.07213162193613698,5.457751281990493,0.5082237140552408,0.10024821171995058,0.6883196197779817,5.042012763234366,3.587348665509907,4.683601276294604,2.0844882872046497,4.940804072788785,5.547793783792635,2.0415453953025615,0.6553491864885608,2.9389567417381084,1.904906761355516,0.410575321742467,0.1632446661228073,1.9084421064032888,0.3311361585344592,2.9135050815818584,1.6657023546172347,1.8170236156832793,0.3881460005237223,2.066862419003346,3.3890139655729286,0.06348025212522401,1.3030039188081197,3.765179355587577,2.159885778659728,2.692530193844357,1.3031355258637838,2.8808627170799053,2.8001537322998047,0.03091091062964324,1.6052829197474878,0.6683801923479358,2.1459811476410415,4.798395053760425,1.6873278734160628,1.7553954240752425,3.5478051093316836,0.7942690216334505,4.805698291675464,1.73212577075493,3.685212577261577,1.6282473972865503,3.7230088370186962,3.4267050819059364,0.5190119062151233,1.6860919115020003,3.6825308450838428,5.592259802469393,4.9428573372089755,1.5020948764497213,0.5790151868547717,0.29822020097212487,3.938357795157085,1.3663774844819478,1.8754420396758285,1.464012518161681,0.6481069837297717,3.5293629554010195,1.8283496019316878,3.669679129995952,1.5840019290730112,1.313408505600112,4.776651927403043,1.9739023949489116,2.7355213165283203,3.515960016558246,1.8627229596747732,2.9657816929099834,1.6492086764985494,7.648175588468227,1.6811366197539535,0.5363838092700846,2.1572137738837576,3.453951557125663,2.6708903354881084,1.4420157841273706,0.10414356138647918,2.737506866455078,1.7007257100698112,2.8263473510742188,3.8461661467681054,1.7838426944428853,5.456947928980778,1.5445650000321258,0.36299437445563143,2.0005575920924663,0.7657694183619661,3.63272980720766,3.8595940726143994,3.8224761085172645,0.7960657440455599,3.5537001685758582,3.665629828848491,0.009233963391011457,3.4550635413785926,1.597960810507498,3.603849138532368,3.862452553921056,0.587668827601842,0.12063204655881776,2.7847633361816406,0.6968931470598498,1.9009557630194998,5.638539103280124,1.6565629598256706,1.9032279423304956,4.020173514761577,3.606772144283866,4.00642470062756,0.6433080945696155,2.772247314453125,1.4452220371791284,3.486592569658832,1.1123040297935738,0.1936220441545764,3.8034188406808056,0.6954607282366077,4.384313174656459,4.215801239013672,1.7265377044677734,1.6592874446836845,0.5517646686450846,1.6126050868955986,1.5659701305886955,1.3242349544493095,3.083714692488961,1.448832503887786,3.940510546574826,2.6355261721853473,3.7427922417135804,3.5798156613209198,2.3604290585557948,0.46729611168223073,0.3460056201831705,1.8082027435302734,5.552778534970042,0.8333235435115469,2.4194412231445312,1.6743001857725517,0.35597241826418013,0.5587095533098498,4.8028682806552965,2.005357411282123,2.5385889926199177,1.5211016055756978,2.2823448181152344,7.866038178975604,0.8705151656578316,1.3220365423905243,3.455639560665702,4.929002235675682,4.115575617009942,5.844216831394885,4.585644188573806,3.5243466910669365,1.3413800948705443,2.21929931640625,5.564045695076999,1.2746705928770439,0.7786885775052568,4.7500118353427965,0.8066847571011238,0.6714536041772661,4.333216082148191,0.6853975568498889,3.6224839346749462,1.198905755977819,0.928030277120655,2.5361638455777555,5.048327994557608,4.231815302147057,1.3616819137182006,1.1143614727517814,5.531222132454928,0.6198768615722656,0.25489056696657286,0.1442253009693033,1.2008932013260711,0.6425305880033036,1.3675966182676689,1.4395027160644531,0.9846017856409048,2.6668968200683594,4.599050942113845,1.4196323459431284,3.3839113335860382,8.463949812560525,2.029363301174701,6.846481180636683,12.225078582763672,8.025507115135508,6.346773147583008,2.8701170559587155,0.913748050558155,10.212214878627233,5.979652389021943,6.60675155569654,2.050386741513112,0.25657324357466393,2.5805142025987635,3.2793562035811554,2.3170235257188807,6.45265798748664,2.3274128537218104,0.6172937665666858,0.34891141362550826,0.06993435631113698,1.3071085330659322,0.0945604980969037,1.0525617354955443,1.6636621114369987,4.838650141006859,6.816615618192234,3.89108757894547,1.0537497478982658,0.5357480453232597,0.0016916931652630751,1.2374661544273629,2.4196961026231776,1.2515935653295287,3.5042851981470147,0.870862420681302,0.13764234420356303,5.528589991341647,4.411981951288816,0.48348936633528794,4.254641523985104,1.3098683076746305,5.368587277599216,3.750598907470703,3.36671723990605,1.9025751854762554,5.853881156090463,2.0210197662638727,0.14657911853255357,2.574299609074826,1.5380626894393057,1.476002127437269,0.5434728072861503,3.4780261115690223,2.676458874264279,2.4152790559541195,3.082588527513586,0.7115621855764687,1.3619238254243307,4.159162485374596,5.515641486290658,4.673972780459398,0.8758345298396719,5.446372252244215,2.517728917738971,1.6669263759580986,1.2991151565160521,1.2378970554896753,1.0182806927224846,2.407679806236459,6.107954009505342,0.491416386195592,2.1463638810086856,1.3059701675023803,0.7792772613795442,2.1379360105933216,3.1603816488514767,3.0623941923442626,5.456555586594801,1.4018371730174835,1.0296642079072846,4.167954435972408,3.050395062095239,0.7507993257962724,0.8345751129420442,4.318421354917721,1.5407590785948173,2.6772303500417927,1.1422441382157196,1.8569122661243789,0.5209667102710611,2.204601075914171,3.547719341213421,2.0078626538886404,2.5320105471853473,3.1511663957075644,0.5210786269882988,1.8929106499537944,1.8132502343043804,0.5289044784287285,0.3063952607928577,4.88425500052316,4.559979290043543,6.50636892498664,0.4301511139428911,0.9980264964856609,3.687336080214557,1.2781762832250365,1.0054022747537346,2.9141072240369095,3.3500673394454132,3.297372930190143,0.820905145290677,2.5387682956931865,2.5621485629324177,0.3425713867700395,1.0096694946289055,3.7244722466719757,6.2397613525390625,5.565781382332858,0.041190612414652605,0.7008515686548051,3.9041889600517337,5.930029364193189,4.61409610812947,0.5967011855820488,4.248205184936523,4.6440872580318135,5.105273951654848,0.5781293319443535,1.4651881626674097,2.175061967637804,0.9208347320556634,4.015722101384942,1.1367815266484804,1.1502419800317583,4.600048485448806,0.6354326520647327,1.8403644561767578,1.6556348720518486,0.3120002746582031,0.381923803762227,2.0944420365262637,0.9243128546353034,0.8064329870815925,1.3105131503755025,4.7005480688971435,4.534020015171597,0.537716040090352,3.3228093171731032,1.0262144337529726,2.4254963498155604,1.4940418308064096,1.9425121523299307,2.5657496371511677,2.5584216160056865,2.9810933977644005,0.5954450879778186,2.93827963297346,1.3566465133275756,0.5056119369248222,0.634866861196663,1.3242921749082939,1.9088598992213726,1.783926010131836,0.17468877669868021,0.4997006744897661,2.1036624908447266,2.80594183016224,0.6296620773056816,0.339743180708453,0.6334566388811389,6.705871000128276,1.4760028294154566,0.538166563389666,0.6500211166123222,3.5141728934595147,6.101097394835273,2.6363153997457225,1.3005490022547086],\"yaxis\":\"y\"}],                        {\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Uncertainty\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"legend\":{\"tracegroupgap\":0},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Uncertainty Distribution for CONFD for average RR error\"},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Samples\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Error Avg Breath(BrPM)\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('c9f74d44-247d-4235-9766-8ade224bfa2d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Samples=%{x}<br>Error Inst Breath(BrPM)=%{y}<br>Uncertainty=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           0.11800112575292587,
           0.13804320991039276,
           0.0350194051861763,
           0.12791873514652252,
           1.0306295156478882,
           0.2656440734863281,
           0.2687962055206299,
           0.2813800275325775,
           0.18250875174999237,
           0.2670319378376007,
           0.185589998960495,
           0.17697076499462128,
           0.17025817930698395,
           0.1275278627872467,
           0.1647997498512268,
           0.16639071702957153,
           0.12341368943452835,
           0.03430389240384102,
           0.13904625177383423,
           0.14213185012340546,
           0.11109805852174759,
           0.037542924284935,
           0.25056809186935425,
           0.1491357982158661,
           1.0356768369674683,
           0.102090023458004,
           0.5625126361846924,
           0.22729338705539703,
           0.23960968852043152,
           0.4117746651172638,
           0.10128413885831833,
           0.06663476675748825,
           0.12754255533218384,
           0.14249761402606964,
           0.12130685150623322,
           0.12973976135253906,
           2.297647476196289,
           0.40126731991767883,
           0.17922604084014893,
           0.26012861728668213,
           0.0007274135714396834,
           0.29243263602256775,
           0.5225510597229004,
           0.2678993046283722,
           0.0882745310664177,
           0.1690913587808609,
           0.6126404404640198,
           0.1376819759607315,
           0.14376872777938843,
           0.0031590028665959835,
           0.1291901022195816,
           0.26303568482398987,
           0.14393535256385803,
           0.07193301618099213,
           0.1515328735113144,
           0.18119607865810394,
           0.2787298262119293,
           0.03226647153496742,
           0.14395451545715332,
           0.26040831208229065,
           0.2906903326511383,
           0.05117477476596832,
           0.4164206385612488,
           0.05256551504135132,
           0.14520764350891113,
           0.029106853529810905,
           0.07890468090772629,
           0.17985107004642487,
           0.17864638566970825,
           0.1430080085992813,
           0.14200548827648163,
           0.013185170479118824,
           1.1458992958068848,
           0.1125371977686882,
           0.06426199525594711,
           0.44541123509407043,
           0.17631955444812775,
           1.0499247312545776,
           0.15490032732486725,
           0.13923609256744385,
           2.0050840377807617,
           0.2564767003059387,
           0.13027635216712952,
           0.17106159031391144,
           0.043346598744392395,
           0.41867485642433167,
           0.16984230279922485,
           0.5399168133735657,
           0.06674906611442566,
           0.11401861906051636,
           1.0505625009536743,
           0.4791984558105469,
           0.2170945703983307,
           0.5569477677345276,
           0.17721718549728394,
           0.06263849884271622,
           0.12657420337200165,
           1.094722867012024,
           0.11185184121131897,
           0.15261593461036682,
           0.128391832113266,
           0.18072271347045898,
           0.4483061134815216,
           0.09689084440469742,
           0.3381749093532562,
           0.121043860912323,
           0.20713236927986145,
           0.1933547854423523,
           0.10203687101602554,
           0.18159660696983337,
           0.032806091010570526,
           0.11194337904453278,
           0.10999803990125656,
           5.965674877166748,
           0.4168541133403778,
           0.25221744179725647,
           0.15646009147167206,
           0.026934612542390823,
           0.045153338462114334,
           0.03359484300017357,
           1.034989356994629,
           0.2351488173007965,
           0.22259990870952606,
           0.059478823095560074,
           0.07805730402469635,
           0.15906496345996857,
           0.15580429136753082,
           0.13951829075813293,
           1.0525990724563599,
           0.12730661034584045,
           0.1659907102584839,
           0.14144153892993927,
           0.20401664078235626,
           0.22123995423316956,
           0.4307885766029358,
           0.127266988158226,
           0.3159218728542328,
           0.04863940551877022,
           0.15406525135040283,
           0.5324276089668274,
           0.630420446395874,
           0.0458647795021534,
           0.43097198009490967,
           0.4551717936992645,
           0.14199112355709076,
           0.15841369330883026,
           0.08770525455474854,
           0.09069560468196869,
           0.031830254942178726,
           0.19046223163604736,
           0.05984167754650116,
           0.21851693093776703,
           1.0468133687973022,
           0.12734632194042206,
           0.0671614557504654,
           0.11048153787851334,
           0.04417915269732475,
           1.0516936779022217,
           0.160441055893898,
           0.08945313096046448,
           0.2380475252866745,
           1.2344599962234497,
           0.26153990626335144,
           0.5934309959411621,
           1.053792953491211,
           0.1557633876800537,
           0.1402558982372284,
           0.5653062462806702,
           0.16360829770565033,
           1.0366543531417847,
           0.14454804360866547,
           0.35322627425193787,
           0.03335058316588402,
           0.17838886380195618,
           0.23708882927894592,
           0.11331154406070709,
           0.16488765180110931,
           0.14632277190685272,
           0.3404153287410736,
           0.15701621770858765,
           0.12938064336776733,
           0.0317869670689106,
           0.13231615722179413,
           0.07006049901247025,
           0.0027386050205677748,
           0.0592387393116951,
           0.167439803481102,
           0.039508841931819916,
           0.4235692322254181,
           0.16265352070331573,
           0.16325971484184265,
           0.06643706560134888,
           0.14405269920825958,
           1.0429813861846924,
           0.4338938593864441,
           0.15703023970127106,
           0.09807394444942474,
           0.16509926319122314,
           0.28216812014579773,
           0.32110121846199036,
           0.17743127048015594,
           0.07483039796352386,
           0.20715810358524323,
           0.14456892013549805,
           0.4065377116203308,
           0.12699919939041138,
           0.0606924369931221,
           0.15011994540691376,
           0.18703189492225647,
           0.19371521472930908,
           0.17100709676742554,
           0.14203912019729614,
           0.1149686649441719,
           0.16804508864879608,
           0.03623395040631294,
           0.19259454309940338,
           0.12808823585510254,
           0.027315570041537285,
           0.11197272688150406,
           0.059720221906900406,
           0.8857371211051941,
           1.983691930770874,
           0.16780264675617218,
           0.17094409465789795,
           0.1516384780406952,
           0.11157236248254776,
           0.422665536403656,
           0.11517952382564545,
           0.037333693355321884,
           0.13451620936393738,
           0.14682313799858093,
           1.0424954891204834,
           0.3022487759590149,
           0.05262256786227226,
           0.15120401978492737,
           0.16548296809196472,
           0.30111196637153625,
           0.1685713529586792,
           0.12972529232501984,
           0.03337587043642998,
           0.1697489321231842,
           2.0189030170440674,
           0.22430871427059174,
           0.20053929090499878,
           0.05988571420311928,
           0.2548125386238098,
           0.23603542149066925,
           0.05846485123038292,
           0.9117397665977478,
           0.3601793646812439,
           0.03561467304825783,
           0.18566182255744934,
           0.1933019757270813,
           0.2086237668991089,
           0.2195928990840912,
           0.18498201668262482,
           0.0833643302321434,
           0.1533440202474594,
           0.11278499662876129,
           0.11411409825086594,
           0.11519874632358551,
           0.18325112760066986,
           0.11348788440227509,
           0.1782761961221695,
           0.23801496624946594,
           0.5115453004837036,
           0.008426659740507603,
           2.4660067558288574,
           0.5486398339271545,
           0.19071386754512787,
           0.17371462285518646,
           0.9022622108459473,
           0.16544659435749054,
           0.23077675700187683,
           0.12357480823993683,
           0.11421045660972595,
           0.11106516420841217,
           0.17743061482906342,
           0.35909608006477356,
           1.3636866807937622,
           0.24226562678813934,
           1.034818172454834,
           0.14154042303562164,
           0.03680070489645004,
           0.20307005941867828,
           0.3273506462574005,
           0.13898511230945587,
           0.14247415959835052,
           0.11272794008255005,
           1.0483673810958862,
           0.15454991161823273,
           0.12780211865901947,
           0.14485062658786774,
           0.25221455097198486,
           0.03488897159695625,
           1.0323071479797363,
           0.1674206703901291,
           1.033829689025879,
           0.0689767524600029,
           0.007784477435052395,
           0.11221156269311905,
           0.4101167619228363,
           0.1211933121085167,
           1.032975196838379,
           1.1267160177230835,
           0.07952306419610977,
           0.03577018156647682,
           0.013132937252521515,
           0.2378024160861969,
           0.20243270695209503,
           0.12872450053691864,
           0.030983613803982735,
           0.14032214879989624,
           0.1981728971004486,
           0.1453404575586319,
           0.17165322601795197,
           0.028034847229719162,
           0.11591378599405289,
           0.0024092255625873804,
           0.4532170295715332,
           0.12827222049236298,
           0.1109728068113327,
           0.10276342183351517,
           0.1398802548646927,
           0.1456063836812973,
           0.13920941948890686,
           0.052319202572107315,
           0.19130654633045197,
           0.15157420933246613,
           0.10346394777297974,
           0.1464606076478958,
           0.10896273702383041,
           0.15445439517498016,
           0.41076740622520447,
           0.2178698480129242,
           0.46009862422943115,
           0.3721928000450134,
           0.11130858212709427,
           0.1137920394539833,
           0.14219246804714203,
           0.42718270421028137,
           0.23382684588432312,
           1.0507190227508545,
           0.4403797686100006,
           1.0322844982147217,
           0.03203305974602699,
           0.18111997842788696,
           0.12971629202365875,
           1.9912244081497192,
           0.04135902598500252,
           0.17234519124031067,
           0.29563194513320923,
           0.1283438801765442,
           0.28972992300987244,
           0.08075948804616928,
           0.07797399163246155,
           0.06288701295852661,
           0.18586456775665283,
           0.17536792159080505,
           0.13553281128406525,
           1.030644416809082,
           1.0549125671386719,
           0.1693699061870575,
           0.07082200050354004,
           0.03625206649303436,
           0.05884015932679176,
           0.09955830127000809,
           0.14607828855514526,
           0.26075857877731323,
           0.22761112451553345,
           0.27223050594329834,
           0.0788191631436348,
           0.2236417680978775,
           1.0994024276733398,
           0.17652927339076996,
           1.9982644319534302,
           0.159513920545578,
           0.03830885514616966,
           0.16400490701198578,
           0.1666349619626999,
           1.0451931953430176,
           0.153423473238945,
           0.28277936577796936,
           0.03375546634197235,
           0.11948956549167633,
           0.5695326328277588,
           0.07534752786159515,
           0.19402620196342468,
           0.11771339178085327,
           0.08466627448797226,
           0.1887107789516449,
           0.0808899998664856,
           0.009257188066840172,
           1.3430309295654297,
           1.033473014831543,
           0.14468468725681305,
           0.13017770648002625,
           0.026182997971773148,
           0.028734752908349037,
           0.03700997307896614,
           0.31238847970962524,
           0.16768264770507812,
           0.08902325481176376,
           0.19582514464855194,
           0.9114909172058105,
           0.11177542805671692,
           0.16725192964076996,
           0.11447802186012268,
           0.6027058959007263,
           0.22134026885032654,
           0.1284007877111435,
           0.1297445148229599,
           0.05855565890669823,
           0.1716039925813675,
           0.148948535323143,
           0.17871737480163574,
           0.1553872525691986,
           0.1128711849451065,
           1.050357699394226,
           0.3689870536327362,
           0.05740739777684212,
           0.2766477167606354,
           0.22361113131046295,
           0.19150729477405548,
           1.0329620838165283,
           0.017470046877861023,
           0.032457638531923294,
           1.0568485260009766,
           0.042033080011606216,
           0.11134647578001022,
           0.11267485469579697,
           0.11383020132780075,
           1.065482497215271,
           0.21702435612678528,
           0.24715979397296906,
           1.1131083965301514,
           0.356523722410202,
           2.75298810005188,
           0.1327715367078781,
           0.26886892318725586,
           0.12472398579120636,
           0.03318971022963524,
           0.060074273496866226,
           1.388079047203064,
           0.11213868111371994,
           1.1452350616455078,
           0.026674970984458923,
           0.12038718909025192,
           0.2188684046268463,
           0.1312306672334671,
           0.11199545115232468,
           0.1772671490907669,
           0.1900649517774582,
           0.034299448132514954,
           0.2194005846977234,
           1.9906649589538574,
           0.03618817403912544,
           0.014476734213531017,
           0.41221943497657776,
           0.523613691329956,
           0.17328794300556183,
           0.14219719171524048,
           1.0591270923614502,
           0.11978091299533844,
           0.07522009313106537,
           0.4710986018180847,
           0.027101291343569756,
           0.02875090204179287,
           0.11935850232839584,
           0.11263542622327805,
           0.15480975806713104,
           1.0478227138519287,
           0.16364911198616028,
           0.148843914270401,
           0.019834985956549644,
           0.12697280943393707,
           0.1329641193151474,
           0.42908236384391785,
           0.4193737506866455,
           0.1553591638803482,
           0.13391008973121643,
           0.11285705119371414,
           0.06115679815411568,
           0.16917750239372253,
           0.16406972706317902,
           0.1806732714176178,
           0.11390915513038635,
           0.1483335644006729,
           0.08324477076530457,
           0.40037667751312256,
           0.29395416378974915,
           0.15225189924240112,
           0.3499993681907654,
           0.060697041451931,
           0.13057945668697357,
           0.06903287768363953,
           0.3791328966617584,
           0.3804436922073364,
           0.26791030168533325,
           0.19537118077278137,
           0.4136612117290497,
           0.18029522895812988,
           0.2482122927904129,
           2.310615301132202,
           0.15770605206489563,
           0.12345151603221893,
           0.2714194655418396,
           0.12741360068321228,
           0.12048288434743881,
           0.14399248361587524,
           0.5172065496444702,
           0.10133354365825653,
           0.45003074407577515,
           0.22631026804447174,
           0.026050424203276634,
           0.08458197116851807,
           1.0577986240386963,
           0.15430808067321777,
           0.049870800226926804,
           0.10706634819507599,
           1.0602997541427612,
           0.2069624364376068,
           0.4703746438026428,
           0.19839581847190857,
           0.1966746598482132,
           0.1683523803949356,
           0.12904290854930878,
           0.06333725154399872,
           0.053434427827596664,
           1.0809316635131836,
           0.4379236698150635,
           1.0270001888275146,
           0.18682189285755157,
           0.16956175863742828,
           0.18760348856449127,
           0.2867591083049774,
           0.4484640657901764,
           1.032275915145874,
           0.12944728136062622,
           0.4664052724838257,
           0.03214249759912491,
           0.10287179797887802,
           0.14579011499881744,
           0.11092346906661987,
           0.09022451192140579,
           0.10596123337745667,
           0.14571017026901245,
           0.08436188101768494,
           0.04464475437998772,
           0.07463128864765167,
           0.20336025953292847,
           0.15380750596523285,
           0.07628361135721207,
           1.029470443725586,
           1.041930079460144,
           0.2687359154224396,
           0.11194417625665665,
           0.13076341152191162,
           0.11281082779169083,
           0.07617490738630295,
           0.026528360322117805,
           0.261626660823822,
           1.1598762273788452,
           0.42503058910369873,
           0.08109290152788162,
           7.1709113121032715,
           0.1338677555322647,
           0.4407767951488495,
           0.04493878781795502,
           0.1183113157749176,
           0.12691275775432587,
           1.053215503692627,
           1.0559425354003906,
           0.12748880684375763,
           0.6073470115661621,
           0.2585568130016327,
           0.1879478543996811,
           0.11788252741098404,
           1.1958410739898682,
           0.02424342930316925,
           1.0363342761993408,
           0.27726420760154724,
           0.16731321811676025,
           0.13683442771434784,
           0.06821060180664062,
           0.4216727614402771,
           0.16876918077468872,
           0.13051928579807281,
           0.16931892931461334,
           0.1121673434972763,
           0.1741965264081955,
           0.153993621468544,
           0.6287137866020203,
           0.18887348473072052,
           0.27308526635169983,
           1.0383113622665405,
           0.4212327003479004,
           0.20713847875595093,
           0.05235126242041588,
           0.15406735241413116,
           0.12566640973091125,
           0.1384917050600052,
           0.112112857401371,
           0.17405565083026886,
           0.1893531233072281,
           0.03674692660570145,
           1.0493557453155518,
           0.21856500208377838,
           0.017729641869664192,
           0.17375154793262482,
           1.0489994287490845,
           0.12370911240577698,
           0.0635322779417038,
           0.026101525872945786,
           0.050583574920892715,
           0.25013014674186707,
           0.19997410476207733,
           0.042222581803798676,
           0.0038036240730434656,
           0.07118254154920578,
           0.1713070273399353,
           0.04985908791422844,
           1.0374658107757568,
           1.1084036827087402,
           0.8758909702301025,
           0.17531633377075195,
           0.000787279277574271,
           0.5286270976066589,
           0.8692032694816589,
           0.45204275846481323,
           1.0402357578277588,
           0.04972778260707855,
           0.2022101730108261,
           0.4750586450099945,
           0.282764732837677,
           0.141051784157753,
           0.08888788521289825,
           0.3051868677139282,
           0.16623127460479736,
           0.41199520230293274,
           0.0014008121797814965,
           0.1960178017616272,
           0.40853893756866455,
           0.05833682045340538,
           0.40817469358444214,
           0.1288788765668869,
           0.42314237356185913,
           0.6222479939460754,
           0.11022179573774338,
           0.06385663151741028,
           0.11351791024208069,
           0.10715416818857193,
           0.1109633594751358,
           0.14229750633239746,
           0.19468806684017181,
           0.024149619042873383,
           0.02622044086456299,
           0.4070632755756378,
           0.09146425873041153,
           0.2953895628452301,
           0.03843690827488899,
           0.12253016233444214,
           0.31189030408859253,
           0.12374501675367355,
           0.4438766539096832,
           0.08157966285943985,
           0.28394776582717896,
           0.26211997866630554,
           0.14931489527225494,
           0.14437198638916016,
           0.23153267800807953,
           0.05539543554186821,
           0.14908216893672943,
           1.0504264831542969,
           0.3452487885951996,
           0.12795093655586243,
           0.16540458798408508,
           0.18393903970718384,
           0.1057143285870552,
           0.06865322589874268,
           0.14806613326072693,
           0.15227490663528442,
           0.03805587813258171,
           1.4372351169586182,
           1.0375359058380127,
           0.27189674973487854,
           0.23554934561252594,
           0.11200625449419022,
           0.021226054057478905,
           0.09012197703123093,
           0.2519966661930084,
           0.28351831436157227,
           0.25267305970191956,
           0.1260865032672882,
           1.0552219152450562,
           0.16955861449241638,
           0.08441165834665298,
           0.13979128003120422,
           1.9658358097076416,
           0.08000122755765915,
           0.29635366797447205,
           1.7213727235794067,
           0.12416025996208191,
           0.07144930213689804,
           0.4345523715019226,
           0.4151330888271332,
           0.4258694648742676,
           0.3129725158214569,
           0.13149426877498627,
           0.2790524363517761,
           0.1313253492116928,
           0.027231590822339058,
           0.11225754767656326,
           0.43984875082969666,
           0.044446200132369995,
           0.5469399094581604,
           0.04206858575344086,
           0.1480218917131424,
           0.05786178633570671,
           0.11154814809560776,
           0.16651234030723572,
           0.14362531900405884,
           0.026340512558817863,
           0.088582843542099,
           0.07208326458930969,
           0.11168353259563446,
           0.10798273980617523,
           0.40184926986694336,
           0.25022873282432556,
           0.17755819857120514,
           0.16663379967212677,
           0.11102316528558731,
           0.16980108618736267,
           0.13201549649238586,
           0.20196478068828583,
           0.16091357171535492,
           0.11737697571516037,
           0.16214199364185333,
           0.17662134766578674,
           0.07545874267816544,
           0.14106503129005432,
           0.18568946421146393,
           0.13002263009548187,
           1.039513349533081,
           0.191276416182518,
           1.038540005683899,
           0.13973590731620789,
           1.030260682106018,
           0.18426719307899475,
           0.15608102083206177,
           0.028071900829672813,
           1.3672635555267334,
           0.1475050151348114,
           0.0778193548321724,
           0.1974591612815857,
           1.0440987348556519,
           0.12993410229682922,
           0.38718995451927185,
           0.10971251130104065,
           0.1901184320449829,
           0.10916697978973389,
           0.24622297286987305,
           0.13634754717350006,
           0.1573626846075058,
           0.15278077125549316,
           0.16753071546554565,
           0.25634872913360596,
           0.14900365471839905,
           0.0795404464006424,
           7.364580154418945,
           0.13133686780929565,
           0.11214838922023773,
           0.07278481125831604,
           0.03284572809934616,
           0.41986796259880066,
           0.111074298620224,
           0.1658150851726532,
           0.18911035358905792,
           0.17525672912597656,
           0.18987546861171722,
           0.3899165093898773,
           1.0318608283996582,
           0.276873379945755,
           0.20699423551559448,
           0.195530965924263,
           0.16209916770458221,
           0.21419984102249146,
           0.31226906180381775,
           0.11190027743577957,
           1.1101547479629517,
           2.2350199222564697,
           0.13019129633903503,
           0.1412736028432846,
           0.11195407807826996,
           0.12971150875091553,
           0.058049749583005905,
           1.2315922975540161,
           0.11151745170354843,
           0.16127535700798035,
           0.04215399920940399,
           0.4095078706741333,
           0.1538245975971222,
           1.205222249031067,
           0.4160816967487335,
           0.16317926347255707,
           0.11062892526388168,
           0.2834751605987549,
           0.17455214262008667,
           0.35127681493759155,
           0.42887648940086365,
           0.1222030520439148,
           1.0400872230529785,
           0.16552308201789856,
           0.11299928277730942
          ],
          "coloraxis": "coloraxis",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813
         ],
         "xaxis": "x",
         "y": [
          0.5848803701744885,
          3.674894709377467,
          2.195631528964867,
          0.0741464417934985,
          1.4517260517260517,
          1.3067781891311334,
          0.6296620046620092,
          2.459927327574391,
          0.038115266376134826,
          1.1460892640560125,
          3.441191567053636,
          1.4519897061126414,
          6.981579102012535,
          0.8799749728542317,
          3.503810682071549,
          0.24495874495874048,
          3.1990137055926517,
          2.7471861471861487,
          3.8220205720205698,
          3.4393083941956135,
          3.468519225872164,
          4.898476523476525,
          2.2875185816362276,
          6.3946562209720135,
          1.6316672153811353,
          3.589100957522014,
          3.9552381790513884,
          4.83445892624392,
          0.481550099516852,
          1.7725588839472657,
          0.11836311836312063,
          4.0225346548876,
          3.4978034235000166,
          0.03917215681921249,
          1.9502112219503545,
          1.6594201289853423,
          3.4193639693639675,
          0.53148821621728,
          5.898259853247062,
          2.5214677298010635,
          5.856840985101854,
          3.650368150368152,
          0.9383000489138631,
          3.941123908770969,
          0.8000294320626793,
          7.970946597262385,
          2.506735688553867,
          6.541585398728259,
          2.2009799058123196,
          2.933669816022757,
          4.148196345564774,
          1.2564238880028356,
          1.0984940984941005,
          3.237170237170236,
          2.3849987535589143,
          1.0123765123765125,
          1.2048390206284942,
          4.248526308796869,
          1.2874073957886445,
          0.6074385582604016,
          3.025226625226626,
          3.1732554528121035,
          1.5561138208197036,
          0.6879155702685118,
          4.37157170315065,
          3.6988408781512234,
          3.646551086206255,
          2.26386013342535,
          1.9556277056277018,
          8.164870980141913,
          5.522161172161169,
          4.98238605220029,
          0.9309220764329105,
          1.780668496354771,
          1.0824668498465293,
          4.487989871448519,
          2.4027824027824067,
          3.0485617712508457,
          1.8876558876558818,
          6.791561920162325,
          1.3731317415527968,
          4.980852480852478,
          0.027597402597404397,
          1.9262246754506798,
          1.704971795880887,
          9.279706288109654,
          1.8690664531737795,
          5.87706572603598,
          3.5939705222313947,
          2.188369937595944,
          0.21139840551605005,
          2.6971165286954744,
          5.875712693103996,
          1.1600129173658544,
          1.165012765012765,
          0.26734522787154447,
          5.650811907390853,
          0.03362602309971052,
          2.3359020866760787,
          6.305002187355132,
          3.61394660800433,
          2.1258177915040655,
          1.5530028794734676,
          2.5723981900452486,
          2.8929420252949676,
          0.4935623153014461,
          5.211810396242374,
          1.7524601301691085,
          0.23753089016246953,
          5.042668442668447,
          1.5574148074148049,
          2.8069187413167622,
          0.43680709742090684,
          3.9761793761793776,
          0.6789183039183051,
          0.38590429178664465,
          4.066303149894484,
          0.5844155844155878,
          4.666831078230421,
          2.5058639696320846,
          2.513498694779104,
          2.500693285720022,
          0.14700703493273437,
          2.8191903334760475,
          0.14028892254698277,
          1.2438009616802148,
          1.659159293087864,
          5.387527383508383,
          4.25471913707208,
          0.5012242561114704,
          2.0759058401915578,
          4.031341207811796,
          0.3886890052303613,
          0.7610280786751389,
          2.8857810121567233,
          8.034699777346837,
          3.300034146716065,
          5.099260388734072,
          0.33635884239599534,
          0.21526784762079387,
          0.8587791861449166,
          4.501028383381321,
          1.4620675620675598,
          0.9194677871148471,
          2.9481744446030174,
          4.925388145688892,
          7.402289819681123,
          0.9752024291497996,
          0.915750915750916,
          8.245095255621575,
          3.4892311886964293,
          0.5010545010545009,
          2.9830743588483486,
          4.116984464810557,
          1.8929557284820433,
          5.049080004962363,
          3.3902842124867796,
          0.7331557331557335,
          0.492619085056063,
          0.383502045156181,
          3.0211564035093446,
          4.99587667234726,
          4.7722241556828,
          8.617537158404028,
          1.9153325665930723,
          2.7536485253876553,
          3.1951093958285846,
          1.566744032909444,
          4.455154322801379,
          10.257537669302373,
          2.561739847454131,
          11.042922344357754,
          2.871913800485226,
          2.052072927072926,
          1.0905587262508956,
          3.4137312008460476,
          1.6894914609200313,
          3.6401227322953,
          0.3579198579198497,
          5.658767319636887,
          10.624165952352786,
          6.85755478574162,
          2.3026824775551447,
          2.1531968466190428,
          5.274078862314159,
          3.851540387708397,
          7.0871153646916625,
          4.998537721226796,
          1.6969190326112091,
          8.661238566501725,
          0.5729907347554466,
          6.308510961654978,
          1.5923726032421683,
          0.8004864502542546,
          3.4098279171808556,
          4.9638157358307105,
          0.5142926735911786,
          2.7311614300892764,
          4.0787438558736735,
          2.7723870332565994,
          0.3155622941116114,
          7.536985563456154,
          0.08096070596070604,
          4.453546453546455,
          7.371360837305108,
          0.6635602959132392,
          2.4647598044656895,
          0.27701927701927787,
          9.101510405858235,
          6.382426127889525,
          8.377093494740551,
          5.263087789403581,
          1.6968286517158706,
          3.367116602730409,
          1.5067821067821079,
          5.923742923742928,
          8.89469931513275,
          6.276441102756891,
          4.614868464868458,
          2.7741106932283337,
          1.6372805041535727,
          1.6085719119774886,
          1.989262371615311,
          0.5607311791522314,
          2.038296344178697,
          0.8701590806853936,
          4.745894206044579,
          3.7380649720322463,
          2.7631970139710056,
          0.6617582727831142,
          3.3943556443556453,
          5.1146927146927155,
          2.219594462561215,
          4.379043886396833,
          5.301298701298702,
          0.9256620572410021,
          0.23676323676323463,
          3.3318420101394164,
          0.0014167470701771379,
          1.2084857866591605,
          1.0436230436230396,
          1.1984584043407551,
          5.261533229412482,
          4.5449902546676775,
          4.880991213808549,
          0.701779701779703,
          2.8984084698370403,
          0.5252747252747234,
          1.4420130594043634,
          0.8652224968014437,
          0.8616536971800137,
          4.507418507418507,
          1.91360363774157,
          3.653970612584537,
          1.5211163516790123,
          1.3293743293743319,
          3.9338845062982983,
          5.7617890881048766,
          0.37886035533094287,
          1.9375777479225746,
          0.36673326673326656,
          1.376428639586532,
          1.9430090606561166,
          0.24675531054249333,
          0.24066072672883365,
          1.3138269293731497,
          4.557382432382429,
          4.339025467286341,
          1.973024223798216,
          3.962015624554322,
          0.6487811705203015,
          1.6581999155528564,
          5.54426901214827,
          1.844410135319226,
          0.3419913419913385,
          3.3576914358128,
          1.372138997912991,
          0.8806141484934074,
          5.794440841809262,
          5.347498906322437,
          7.279662251356191,
          3.356680356680357,
          0.5665445665445645,
          1.1491656491656457,
          6.95130055130055,
          2.112248105214853,
          1.4153545256486453,
          1.7496478753444684,
          3.666765398344346,
          3.4021978021978043,
          7.111048863990046,
          0.42518461930226437,
          0.049803866821054754,
          2.728643954207868,
          5.193865145125653,
          0.7289720947387899,
          1.836255113831406,
          1.6319002634792064,
          0.29537053335680596,
          3.1941822882999347,
          4.175532800532803,
          2.57215153267785,
          0.36970436970436893,
          0.27572439232103463,
          4.791500166500171,
          0.2386837563308113,
          3.8635706030664014,
          1.4749818955922436,
          1.385270336422412,
          1.6623251762570632,
          6.635191875793382,
          2.3588263588263594,
          7.0422205245734695,
          1.3793787911435018,
          9.6275145540562,
          0.9811373811373834,
          3.1756751655428808,
          1.5830086580086515,
          1.0160544855153795,
          9.626148705096073,
          1.9028605381546555,
          2.506107589234528,
          0.4258459119140241,
          2.469371587018646,
          2.700160999626238,
          1.5448990055128107,
          10.129318780634573,
          4.405642256902766,
          0.8453674985915818,
          0.7931523022432145,
          0.3593162630595792,
          5.93556476203535,
          9.826141179082356,
          0.20833632598338525,
          3.862272727272728,
          2.667499853312208,
          1.1795139004218278,
          0.7060719024451885,
          1.0943006573258671,
          6.261271843624787,
          7.615548641245233,
          1.8632787615243807,
          0.13987863987864202,
          7.355161823041083,
          4.50733216059303,
          4.755355755355755,
          5.264778668387979,
          0.19109270502459452,
          0.1951479892656316,
          0.10028533557945707,
          0.8044083730358231,
          4.5676661573720345,
          8.326483652799439,
          2.162011598328732,
          9.104741550989017,
          6.87046534476875,
          2.0478595478595487,
          5.308108506560519,
          1.2015898331687822,
          0.5139073173128921,
          1.8087643350801237,
          2.460187340570112,
          2.669416857652152,
          0.9959091944737857,
          2.804736929736926,
          1.0173076923076962,
          4.04652153258964,
          8.39448061016689,
          4.9654161488747945,
          4.0184385789648935,
          2.5395361203410793,
          5.291117923470864,
          0.9409849409849436,
          6.311196203535747,
          1.7136668628928717,
          1.0193880193880176,
          3.85338922916322,
          2.6403078403078446,
          8.9119582734556,
          2.209469670635375,
          1.546601546601547,
          5.808749934276246,
          4.2999413945656535,
          8.639748130657225,
          8.158315854419751,
          5.012851523721093,
          3.9538466177785025,
          1.7831442273141889,
          0.2805921538823348,
          1.3745143745143729,
          2.5200661236154396,
          2.262642971064029,
          4.040401537460365,
          3.106782106782102,
          2.686912560430347,
          1.7975680191069188,
          2.8577921273573494,
          4.042366427393166,
          0.4285712758365037,
          8.594021446962627,
          4.672173502779433,
          1.650781296695957,
          3.5247715247715234,
          0.6410574932314077,
          1.5883512199301677,
          6.746539354365439,
          5.8815153826595505,
          1.1727016214411154,
          3.112630506748147,
          8.84927194018103,
          1.1501400560224049,
          3.8928551244340746,
          7.392141192141192,
          0.10292210369609833,
          4.286932294285233,
          2.1360249330174135,
          0.5165532680243352,
          1.705323915850233,
          6.832893772893772,
          6.126775825505408,
          2.370901240466459,
          1.940270303460224,
          7.549713032065972,
          1.6856587856587808,
          4.26791405557438,
          1.49168750639339,
          2.3099615452556606,
          8.107334633031229,
          0.25027341079972487,
          0.9104281425488878,
          5.2231725220283565,
          0.008938698593869532,
          0.2313635327989374,
          1.7094877258963947,
          2.191438191438195,
          0.5107212475633531,
          3.053887389413706,
          0.33953984221363953,
          1.7835630127190214,
          1.5853655603655596,
          6.583344448890669,
          5.9877661554132136,
          3.2694342694342673,
          4.719749694749698,
          0.7510567863509046,
          10.888385253091135,
          5.194547583479476,
          4.475460487225195,
          0.8196981123451721,
          9.074890469008116,
          2.066430330113196,
          7.09756829571071,
          6.634071810542395,
          7.238900315370904,
          10.686741363211956,
          1.9102980352980374,
          0.6906719833762516,
          5.986650137910644,
          0.5553040354897938,
          3.3092349892221993,
          4.326395608748548,
          0.8976715292504771,
          0.7670008354218929,
          0.9906918564260465,
          3.0840833323605708,
          3.145310107848811,
          3.1320444261620786,
          4.620879120879124,
          2.387642904051578,
          2.6220030972352966,
          6.1509171636664295,
          4.937518037518039,
          2.66812577873959,
          3.655656388429499,
          0.2978241801771233,
          3.3358452692818013,
          1.08491935235633,
          5.315548503783798,
          3.8579462095853714,
          5.671122080846253,
          5.945363125007088,
          3.8697971364932897,
          1.273472141893194,
          3.187092235495598,
          4.19491496473594,
          1.1410173160173152,
          6.338639115728901,
          1.4866370471633665,
          0.2675657675657668,
          3.0140084316554905,
          2.2918081918081903,
          0.5165577342047953,
          0.553728778960977,
          2.6161172161172175,
          4.544865562245242,
          3.873755802161373,
          4.734752164473527,
          1.6272877449347973,
          1.6686801760331136,
          1.33915901493301,
          5.7468805704099815,
          2.383951560422151,
          3.125354057707,
          4.787362792006757,
          5.921356421356421,
          1.3433494609965173,
          1.2719769119769175,
          4.568982710693938,
          0.3841232121592668,
          0.3823267375898993,
          12.246004541571052,
          4.43827690770415,
          7.345772932922621,
          0.21831577513395573,
          0.7963293855553957,
          5.753123347241001,
          0.7637771814242384,
          5.754282754282759,
          0.0948509580088519,
          2.323464712251898,
          4.528080897430744,
          1.5098166539343048,
          5.164517162526893,
          0.8691197691197701,
          1.859943977591037,
          1.0352263982516092,
          0.5968576086223152,
          3.944900775506703,
          5.004670819376706,
          1.3156609472398912,
          6.648048030400972,
          2.899111781464722,
          3.754745676094444,
          0.5779054279054243,
          0.6115288220551349,
          4.956284357353876,
          3.7802036199095,
          2.993870010278677,
          2.8125538949068343,
          0.5206077147253652,
          2.1322139536043316,
          1.4756907580437044,
          0.7922958810830636,
          0.09583618995383958,
          4.849489725960311,
          3.1209574738986454,
          2.773161668302336,
          0.3091144235881096,
          4.572996253668524,
          4.6129782915497195,
          3.553491436100135,
          1.5367965367965368,
          1.4520640579464121,
          3.4936161333220177,
          0.9960157489569283,
          2.3898868638364448,
          8.798545414976198,
          5.549737843855489,
          7.394645064183358,
          3.5722904546433973,
          1.7483518659989237,
          1.889474904180787,
          0.38533225647238467,
          4.078389721733377,
          1.2959910459910446,
          1.9392660038843914,
          7.263389500561583,
          6.614630872845883,
          1.0539143396286228,
          3.366564341354259,
          2.6850066600066604,
          3.0231126897793565,
          2.394586667618995,
          5.774330431473292,
          1.094522144522145,
          6.488315916887343,
          3.8387740079469417,
          2.767740196311628,
          1.1119498250298392,
          5.395414389532036,
          1.2908415400675501,
          2.9936221186221204,
          1.5018315018314965,
          1.1481472833221744,
          1.8377994554465182,
          2.0009466024171907,
          4.381300888653829,
          3.8508326998029503,
          1.903268358598826,
          3.3828563593269436,
          5.695504495504494,
          6.7155955155955205,
          1.2657988344262847,
          2.827656141588033,
          7.02332613393995,
          0.8837415071430463,
          0.9311588995799518,
          0.464800112168529,
          6.607908109206811,
          4.911203082631655,
          1.073411033411034,
          2.253950921330599,
          4.549097544156002,
          1.3880752445661138,
          4.197959992077639,
          3.84129813541578,
          5.240965113318055,
          0.5244316141374945,
          4.7151724092900515,
          3.5772005772005784,
          8.611708334196372,
          1.4995744995744964,
          1.0485558559087949,
          1.4691587903929069,
          5.616983016983017,
          2.8454138454138445,
          1.808338707068284,
          10.588267941209121,
          2.2247346306943854,
          1.8951716364229654,
          0.8920728792851556,
          5.7417818143562975,
          4.923329319210325,
          2.570250039815253,
          0.03664391164391034,
          1.1395863395863408,
          2.6995303438585516,
          6.481389248160404,
          0.746358380916103,
          0.239693750971945,
          1.2351550410373946,
          4.638016826804016,
          2.232051282051284,
          4.334279385539894,
          7.813438023964341,
          5.815681833694256,
          4.404845154845155,
          8.75364846793418,
          2.135762633088838,
          8.47162913339384,
          0.841723773302725,
          3.672275139148198,
          6.967782217782219,
          2.2983682983683025,
          5.30113657386385,
          2.0688233335292097,
          1.139637536376668,
          3.4321850263026725,
          3.874133737816603,
          1.4140325431885543,
          8.64896331738437,
          6.737803677803679,
          1.0655300581771172,
          2.6908450481979855,
          5.742492801316331,
          3.5915696503931756,
          3.276080461219781,
          0.8728291316526615,
          6.269021070725483,
          0.5141129814926657,
          3.535569985569989,
          7.170647441280035,
          5.100176626492416,
          0.6078741182189482,
          2.539605034341875,
          1.9398671503934644,
          0.5034743034743023,
          2.468236568923068,
          1.8131909141761327,
          1.1194994664265714,
          1.0650308755571913,
          0.217488393958984,
          5.647332234329134,
          1.6376296117675437,
          6.6994224099487205,
          3.076664977534545,
          4.215048719396547,
          1.8103184454933388,
          6.552855164885241,
          0.12242187636924484,
          7.456808688387634,
          3.248314710499585,
          3.2750760072188676,
          3.6388731569182706,
          2.2103349498307487,
          3.0656565656565604,
          1.9397084397084434,
          3.6720936675096283,
          6.059315839866958,
          2.0741812109459197,
          2.9650550463580494,
          0.49773785112130753,
          2.758007243301357,
          3.9512820512820515,
          6.223217305570246,
          2.886654687798849,
          2.3260739260739243,
          8.29329189329189,
          5.090806547949409,
          4.8161582670203344,
          3.16135416870711,
          1.2802515283333662,
          4.957838620119322,
          4.0810334592943285,
          0.44577644577644193,
          1.1122710622710628,
          4.1380328821505294,
          2.8389124316543644,
          5.150375939849626,
          0.20197112337758227,
          2.198545105687966,
          5.300089328660757,
          6.632910802274109,
          0.15806994126322138,
          1.9908963585434165,
          8.884786008625019,
          2.6894021609860097,
          2.2825643492310164,
          2.5252376622345594,
          5.965510959628608,
          0.2839748339527226,
          3.1677975533238687,
          1.7282238458709038,
          1.098244348244343,
          3.3187799043062185,
          2.029718014061226,
          3.2124640065816514,
          7.024463118580767,
          1.152849684428631,
          1.4579864579864577,
          2.4665822064318306,
          0.4287878787878796,
          3.709723171565278,
          3.0142172642172653,
          2.2389016212545627,
          8.662337662337661,
          2.1252754309385633,
          7.008449720214426,
          0.31467443232148895,
          4.255346614170147,
          2.2334430930749285,
          3.3918791734581255,
          1.0545193368722785,
          1.702775002775006,
          3.055144855144853,
          0.9754379505932285,
          0.3063329613528616,
          1.7205710955710956,
          2.486455211455212,
          0.478252575311398,
          5.084084866924314,
          4.5121794009012035,
          4.0335802828062945,
          8.386946386946395,
          1.8995951476769903,
          3.1490005923442403,
          5.492969301663694,
          3.5182181182181154,
          5.827766916286723,
          1.0460128639476451,
          6.383533886573048,
          8.344266377879826,
          9.15809837439932,
          2.0651175039046876,
          1.0662177328844002,
          0.4843353626315121,
          2.15145556198188,
          0.2976996859349761,
          0.01830506095211959,
          1.139248405915069,
          4.505201438490214,
          1.5410584016722098,
          0.7568764568764585,
          3.150910979858349,
          0.9301131616921126,
          4.697388885624177,
          1.1525659525659542,
          0.8127854094240625,
          0.25536062378167657,
          3.993792450935313,
          7.394819994819992,
          4.5813445813445774,
          1.5177110184850093,
          4.177880243006296,
          1.403649154423146,
          5.695371295371299,
          5.0751569284177975,
          2.162372651503091,
          0.49444964697802973,
          5.049565954327861,
          5.824696001166586,
          3.2423944286072413,
          2.415905756241891,
          3.846055851090176,
          1.8118210765269573,
          2.9567531883321365,
          3.6432380761429037,
          1.233173572459286,
          7.763819513819513,
          3.529437229437228,
          2.2636191618647743,
          3.2610293215556396,
          0.6331433272609743,
          0.5914100423904394,
          2.078728289254606,
          2.3566849816849818,
          4.0011489883612725,
          4.376881619848373,
          1.1281552585900414,
          0.595185279499006,
          0.48729166339688845,
          4.709959322577827,
          5.453684193179992,
          1.3971283520155673
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Uncertainty"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Uncertainty Distribution for CONFD for instantaneous RR error"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Samples"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Error Inst Breath(BrPM)"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"55e73c91-30d4-43b9-b698-284c7ec7f948\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"55e73c91-30d4-43b9-b698-284c7ec7f948\")) {                    Plotly.newPlot(                        \"55e73c91-30d4-43b9-b698-284c7ec7f948\",                        [{\"hovertemplate\":\"Samples=%{x}<br>Error Inst Breath(BrPM)=%{y}<br>Uncertainty=%{marker.color}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":[0.11800112575292587,0.13804320991039276,0.0350194051861763,0.12791873514652252,1.0306295156478882,0.2656440734863281,0.2687962055206299,0.2813800275325775,0.18250875174999237,0.2670319378376007,0.185589998960495,0.17697076499462128,0.17025817930698395,0.1275278627872467,0.1647997498512268,0.16639071702957153,0.12341368943452835,0.03430389240384102,0.13904625177383423,0.14213185012340546,0.11109805852174759,0.037542924284935,0.25056809186935425,0.1491357982158661,1.0356768369674683,0.102090023458004,0.5625126361846924,0.22729338705539703,0.23960968852043152,0.4117746651172638,0.10128413885831833,0.06663476675748825,0.12754255533218384,0.14249761402606964,0.12130685150623322,0.12973976135253906,2.297647476196289,0.40126731991767883,0.17922604084014893,0.26012861728668213,0.0007274135714396834,0.29243263602256775,0.5225510597229004,0.2678993046283722,0.0882745310664177,0.1690913587808609,0.6126404404640198,0.1376819759607315,0.14376872777938843,0.0031590028665959835,0.1291901022195816,0.26303568482398987,0.14393535256385803,0.07193301618099213,0.1515328735113144,0.18119607865810394,0.2787298262119293,0.03226647153496742,0.14395451545715332,0.26040831208229065,0.2906903326511383,0.05117477476596832,0.4164206385612488,0.05256551504135132,0.14520764350891113,0.029106853529810905,0.07890468090772629,0.17985107004642487,0.17864638566970825,0.1430080085992813,0.14200548827648163,0.013185170479118824,1.1458992958068848,0.1125371977686882,0.06426199525594711,0.44541123509407043,0.17631955444812775,1.0499247312545776,0.15490032732486725,0.13923609256744385,2.0050840377807617,0.2564767003059387,0.13027635216712952,0.17106159031391144,0.043346598744392395,0.41867485642433167,0.16984230279922485,0.5399168133735657,0.06674906611442566,0.11401861906051636,1.0505625009536743,0.4791984558105469,0.2170945703983307,0.5569477677345276,0.17721718549728394,0.06263849884271622,0.12657420337200165,1.094722867012024,0.11185184121131897,0.15261593461036682,0.128391832113266,0.18072271347045898,0.4483061134815216,0.09689084440469742,0.3381749093532562,0.121043860912323,0.20713236927986145,0.1933547854423523,0.10203687101602554,0.18159660696983337,0.032806091010570526,0.11194337904453278,0.10999803990125656,5.965674877166748,0.4168541133403778,0.25221744179725647,0.15646009147167206,0.026934612542390823,0.045153338462114334,0.03359484300017357,1.034989356994629,0.2351488173007965,0.22259990870952606,0.059478823095560074,0.07805730402469635,0.15906496345996857,0.15580429136753082,0.13951829075813293,1.0525990724563599,0.12730661034584045,0.1659907102584839,0.14144153892993927,0.20401664078235626,0.22123995423316956,0.4307885766029358,0.127266988158226,0.3159218728542328,0.04863940551877022,0.15406525135040283,0.5324276089668274,0.630420446395874,0.0458647795021534,0.43097198009490967,0.4551717936992645,0.14199112355709076,0.15841369330883026,0.08770525455474854,0.09069560468196869,0.031830254942178726,0.19046223163604736,0.05984167754650116,0.21851693093776703,1.0468133687973022,0.12734632194042206,0.0671614557504654,0.11048153787851334,0.04417915269732475,1.0516936779022217,0.160441055893898,0.08945313096046448,0.2380475252866745,1.2344599962234497,0.26153990626335144,0.5934309959411621,1.053792953491211,0.1557633876800537,0.1402558982372284,0.5653062462806702,0.16360829770565033,1.0366543531417847,0.14454804360866547,0.35322627425193787,0.03335058316588402,0.17838886380195618,0.23708882927894592,0.11331154406070709,0.16488765180110931,0.14632277190685272,0.3404153287410736,0.15701621770858765,0.12938064336776733,0.0317869670689106,0.13231615722179413,0.07006049901247025,0.0027386050205677748,0.0592387393116951,0.167439803481102,0.039508841931819916,0.4235692322254181,0.16265352070331573,0.16325971484184265,0.06643706560134888,0.14405269920825958,1.0429813861846924,0.4338938593864441,0.15703023970127106,0.09807394444942474,0.16509926319122314,0.28216812014579773,0.32110121846199036,0.17743127048015594,0.07483039796352386,0.20715810358524323,0.14456892013549805,0.4065377116203308,0.12699919939041138,0.0606924369931221,0.15011994540691376,0.18703189492225647,0.19371521472930908,0.17100709676742554,0.14203912019729614,0.1149686649441719,0.16804508864879608,0.03623395040631294,0.19259454309940338,0.12808823585510254,0.027315570041537285,0.11197272688150406,0.059720221906900406,0.8857371211051941,1.983691930770874,0.16780264675617218,0.17094409465789795,0.1516384780406952,0.11157236248254776,0.422665536403656,0.11517952382564545,0.037333693355321884,0.13451620936393738,0.14682313799858093,1.0424954891204834,0.3022487759590149,0.05262256786227226,0.15120401978492737,0.16548296809196472,0.30111196637153625,0.1685713529586792,0.12972529232501984,0.03337587043642998,0.1697489321231842,2.0189030170440674,0.22430871427059174,0.20053929090499878,0.05988571420311928,0.2548125386238098,0.23603542149066925,0.05846485123038292,0.9117397665977478,0.3601793646812439,0.03561467304825783,0.18566182255744934,0.1933019757270813,0.2086237668991089,0.2195928990840912,0.18498201668262482,0.0833643302321434,0.1533440202474594,0.11278499662876129,0.11411409825086594,0.11519874632358551,0.18325112760066986,0.11348788440227509,0.1782761961221695,0.23801496624946594,0.5115453004837036,0.008426659740507603,2.4660067558288574,0.5486398339271545,0.19071386754512787,0.17371462285518646,0.9022622108459473,0.16544659435749054,0.23077675700187683,0.12357480823993683,0.11421045660972595,0.11106516420841217,0.17743061482906342,0.35909608006477356,1.3636866807937622,0.24226562678813934,1.034818172454834,0.14154042303562164,0.03680070489645004,0.20307005941867828,0.3273506462574005,0.13898511230945587,0.14247415959835052,0.11272794008255005,1.0483673810958862,0.15454991161823273,0.12780211865901947,0.14485062658786774,0.25221455097198486,0.03488897159695625,1.0323071479797363,0.1674206703901291,1.033829689025879,0.0689767524600029,0.007784477435052395,0.11221156269311905,0.4101167619228363,0.1211933121085167,1.032975196838379,1.1267160177230835,0.07952306419610977,0.03577018156647682,0.013132937252521515,0.2378024160861969,0.20243270695209503,0.12872450053691864,0.030983613803982735,0.14032214879989624,0.1981728971004486,0.1453404575586319,0.17165322601795197,0.028034847229719162,0.11591378599405289,0.0024092255625873804,0.4532170295715332,0.12827222049236298,0.1109728068113327,0.10276342183351517,0.1398802548646927,0.1456063836812973,0.13920941948890686,0.052319202572107315,0.19130654633045197,0.15157420933246613,0.10346394777297974,0.1464606076478958,0.10896273702383041,0.15445439517498016,0.41076740622520447,0.2178698480129242,0.46009862422943115,0.3721928000450134,0.11130858212709427,0.1137920394539833,0.14219246804714203,0.42718270421028137,0.23382684588432312,1.0507190227508545,0.4403797686100006,1.0322844982147217,0.03203305974602699,0.18111997842788696,0.12971629202365875,1.9912244081497192,0.04135902598500252,0.17234519124031067,0.29563194513320923,0.1283438801765442,0.28972992300987244,0.08075948804616928,0.07797399163246155,0.06288701295852661,0.18586456775665283,0.17536792159080505,0.13553281128406525,1.030644416809082,1.0549125671386719,0.1693699061870575,0.07082200050354004,0.03625206649303436,0.05884015932679176,0.09955830127000809,0.14607828855514526,0.26075857877731323,0.22761112451553345,0.27223050594329834,0.0788191631436348,0.2236417680978775,1.0994024276733398,0.17652927339076996,1.9982644319534302,0.159513920545578,0.03830885514616966,0.16400490701198578,0.1666349619626999,1.0451931953430176,0.153423473238945,0.28277936577796936,0.03375546634197235,0.11948956549167633,0.5695326328277588,0.07534752786159515,0.19402620196342468,0.11771339178085327,0.08466627448797226,0.1887107789516449,0.0808899998664856,0.009257188066840172,1.3430309295654297,1.033473014831543,0.14468468725681305,0.13017770648002625,0.026182997971773148,0.028734752908349037,0.03700997307896614,0.31238847970962524,0.16768264770507812,0.08902325481176376,0.19582514464855194,0.9114909172058105,0.11177542805671692,0.16725192964076996,0.11447802186012268,0.6027058959007263,0.22134026885032654,0.1284007877111435,0.1297445148229599,0.05855565890669823,0.1716039925813675,0.148948535323143,0.17871737480163574,0.1553872525691986,0.1128711849451065,1.050357699394226,0.3689870536327362,0.05740739777684212,0.2766477167606354,0.22361113131046295,0.19150729477405548,1.0329620838165283,0.017470046877861023,0.032457638531923294,1.0568485260009766,0.042033080011606216,0.11134647578001022,0.11267485469579697,0.11383020132780075,1.065482497215271,0.21702435612678528,0.24715979397296906,1.1131083965301514,0.356523722410202,2.75298810005188,0.1327715367078781,0.26886892318725586,0.12472398579120636,0.03318971022963524,0.060074273496866226,1.388079047203064,0.11213868111371994,1.1452350616455078,0.026674970984458923,0.12038718909025192,0.2188684046268463,0.1312306672334671,0.11199545115232468,0.1772671490907669,0.1900649517774582,0.034299448132514954,0.2194005846977234,1.9906649589538574,0.03618817403912544,0.014476734213531017,0.41221943497657776,0.523613691329956,0.17328794300556183,0.14219719171524048,1.0591270923614502,0.11978091299533844,0.07522009313106537,0.4710986018180847,0.027101291343569756,0.02875090204179287,0.11935850232839584,0.11263542622327805,0.15480975806713104,1.0478227138519287,0.16364911198616028,0.148843914270401,0.019834985956549644,0.12697280943393707,0.1329641193151474,0.42908236384391785,0.4193737506866455,0.1553591638803482,0.13391008973121643,0.11285705119371414,0.06115679815411568,0.16917750239372253,0.16406972706317902,0.1806732714176178,0.11390915513038635,0.1483335644006729,0.08324477076530457,0.40037667751312256,0.29395416378974915,0.15225189924240112,0.3499993681907654,0.060697041451931,0.13057945668697357,0.06903287768363953,0.3791328966617584,0.3804436922073364,0.26791030168533325,0.19537118077278137,0.4136612117290497,0.18029522895812988,0.2482122927904129,2.310615301132202,0.15770605206489563,0.12345151603221893,0.2714194655418396,0.12741360068321228,0.12048288434743881,0.14399248361587524,0.5172065496444702,0.10133354365825653,0.45003074407577515,0.22631026804447174,0.026050424203276634,0.08458197116851807,1.0577986240386963,0.15430808067321777,0.049870800226926804,0.10706634819507599,1.0602997541427612,0.2069624364376068,0.4703746438026428,0.19839581847190857,0.1966746598482132,0.1683523803949356,0.12904290854930878,0.06333725154399872,0.053434427827596664,1.0809316635131836,0.4379236698150635,1.0270001888275146,0.18682189285755157,0.16956175863742828,0.18760348856449127,0.2867591083049774,0.4484640657901764,1.032275915145874,0.12944728136062622,0.4664052724838257,0.03214249759912491,0.10287179797887802,0.14579011499881744,0.11092346906661987,0.09022451192140579,0.10596123337745667,0.14571017026901245,0.08436188101768494,0.04464475437998772,0.07463128864765167,0.20336025953292847,0.15380750596523285,0.07628361135721207,1.029470443725586,1.041930079460144,0.2687359154224396,0.11194417625665665,0.13076341152191162,0.11281082779169083,0.07617490738630295,0.026528360322117805,0.261626660823822,1.1598762273788452,0.42503058910369873,0.08109290152788162,7.1709113121032715,0.1338677555322647,0.4407767951488495,0.04493878781795502,0.1183113157749176,0.12691275775432587,1.053215503692627,1.0559425354003906,0.12748880684375763,0.6073470115661621,0.2585568130016327,0.1879478543996811,0.11788252741098404,1.1958410739898682,0.02424342930316925,1.0363342761993408,0.27726420760154724,0.16731321811676025,0.13683442771434784,0.06821060180664062,0.4216727614402771,0.16876918077468872,0.13051928579807281,0.16931892931461334,0.1121673434972763,0.1741965264081955,0.153993621468544,0.6287137866020203,0.18887348473072052,0.27308526635169983,1.0383113622665405,0.4212327003479004,0.20713847875595093,0.05235126242041588,0.15406735241413116,0.12566640973091125,0.1384917050600052,0.112112857401371,0.17405565083026886,0.1893531233072281,0.03674692660570145,1.0493557453155518,0.21856500208377838,0.017729641869664192,0.17375154793262482,1.0489994287490845,0.12370911240577698,0.0635322779417038,0.026101525872945786,0.050583574920892715,0.25013014674186707,0.19997410476207733,0.042222581803798676,0.0038036240730434656,0.07118254154920578,0.1713070273399353,0.04985908791422844,1.0374658107757568,1.1084036827087402,0.8758909702301025,0.17531633377075195,0.000787279277574271,0.5286270976066589,0.8692032694816589,0.45204275846481323,1.0402357578277588,0.04972778260707855,0.2022101730108261,0.4750586450099945,0.282764732837677,0.141051784157753,0.08888788521289825,0.3051868677139282,0.16623127460479736,0.41199520230293274,0.0014008121797814965,0.1960178017616272,0.40853893756866455,0.05833682045340538,0.40817469358444214,0.1288788765668869,0.42314237356185913,0.6222479939460754,0.11022179573774338,0.06385663151741028,0.11351791024208069,0.10715416818857193,0.1109633594751358,0.14229750633239746,0.19468806684017181,0.024149619042873383,0.02622044086456299,0.4070632755756378,0.09146425873041153,0.2953895628452301,0.03843690827488899,0.12253016233444214,0.31189030408859253,0.12374501675367355,0.4438766539096832,0.08157966285943985,0.28394776582717896,0.26211997866630554,0.14931489527225494,0.14437198638916016,0.23153267800807953,0.05539543554186821,0.14908216893672943,1.0504264831542969,0.3452487885951996,0.12795093655586243,0.16540458798408508,0.18393903970718384,0.1057143285870552,0.06865322589874268,0.14806613326072693,0.15227490663528442,0.03805587813258171,1.4372351169586182,1.0375359058380127,0.27189674973487854,0.23554934561252594,0.11200625449419022,0.021226054057478905,0.09012197703123093,0.2519966661930084,0.28351831436157227,0.25267305970191956,0.1260865032672882,1.0552219152450562,0.16955861449241638,0.08441165834665298,0.13979128003120422,1.9658358097076416,0.08000122755765915,0.29635366797447205,1.7213727235794067,0.12416025996208191,0.07144930213689804,0.4345523715019226,0.4151330888271332,0.4258694648742676,0.3129725158214569,0.13149426877498627,0.2790524363517761,0.1313253492116928,0.027231590822339058,0.11225754767656326,0.43984875082969666,0.044446200132369995,0.5469399094581604,0.04206858575344086,0.1480218917131424,0.05786178633570671,0.11154814809560776,0.16651234030723572,0.14362531900405884,0.026340512558817863,0.088582843542099,0.07208326458930969,0.11168353259563446,0.10798273980617523,0.40184926986694336,0.25022873282432556,0.17755819857120514,0.16663379967212677,0.11102316528558731,0.16980108618736267,0.13201549649238586,0.20196478068828583,0.16091357171535492,0.11737697571516037,0.16214199364185333,0.17662134766578674,0.07545874267816544,0.14106503129005432,0.18568946421146393,0.13002263009548187,1.039513349533081,0.191276416182518,1.038540005683899,0.13973590731620789,1.030260682106018,0.18426719307899475,0.15608102083206177,0.028071900829672813,1.3672635555267334,0.1475050151348114,0.0778193548321724,0.1974591612815857,1.0440987348556519,0.12993410229682922,0.38718995451927185,0.10971251130104065,0.1901184320449829,0.10916697978973389,0.24622297286987305,0.13634754717350006,0.1573626846075058,0.15278077125549316,0.16753071546554565,0.25634872913360596,0.14900365471839905,0.0795404464006424,7.364580154418945,0.13133686780929565,0.11214838922023773,0.07278481125831604,0.03284572809934616,0.41986796259880066,0.111074298620224,0.1658150851726532,0.18911035358905792,0.17525672912597656,0.18987546861171722,0.3899165093898773,1.0318608283996582,0.276873379945755,0.20699423551559448,0.195530965924263,0.16209916770458221,0.21419984102249146,0.31226906180381775,0.11190027743577957,1.1101547479629517,2.2350199222564697,0.13019129633903503,0.1412736028432846,0.11195407807826996,0.12971150875091553,0.058049749583005905,1.2315922975540161,0.11151745170354843,0.16127535700798035,0.04215399920940399,0.4095078706741333,0.1538245975971222,1.205222249031067,0.4160816967487335,0.16317926347255707,0.11062892526388168,0.2834751605987549,0.17455214262008667,0.35127681493759155,0.42887648940086365,0.1222030520439148,1.0400872230529785,0.16552308201789856,0.11299928277730942],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"type\":\"scatter\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0,51.0,52.0,53.0,54.0,55.0,56.0,57.0,58.0,59.0,60.0,61.0,62.0,63.0,64.0,65.0,66.0,67.0,68.0,69.0,70.0,71.0,72.0,73.0,74.0,75.0,76.0,77.0,78.0,79.0,80.0,81.0,82.0,83.0,84.0,85.0,86.0,87.0,88.0,89.0,90.0,91.0,92.0,93.0,94.0,95.0,96.0,97.0,98.0,99.0,100.0,101.0,102.0,103.0,104.0,105.0,106.0,107.0,108.0,109.0,110.0,111.0,112.0,113.0,114.0,115.0,116.0,117.0,118.0,119.0,120.0,121.0,122.0,123.0,124.0,125.0,126.0,127.0,128.0,129.0,130.0,131.0,132.0,133.0,134.0,135.0,136.0,137.0,138.0,139.0,140.0,141.0,142.0,143.0,144.0,145.0,146.0,147.0,148.0,149.0,150.0,151.0,152.0,153.0,154.0,155.0,156.0,157.0,158.0,159.0,160.0,161.0,162.0,163.0,164.0,165.0,166.0,167.0,168.0,169.0,170.0,171.0,172.0,173.0,174.0,175.0,176.0,177.0,178.0,179.0,180.0,181.0,182.0,183.0,184.0,185.0,186.0,187.0,188.0,189.0,190.0,191.0,192.0,193.0,194.0,195.0,196.0,197.0,198.0,199.0,200.0,201.0,202.0,203.0,204.0,205.0,206.0,207.0,208.0,209.0,210.0,211.0,212.0,213.0,214.0,215.0,216.0,217.0,218.0,219.0,220.0,221.0,222.0,223.0,224.0,225.0,226.0,227.0,228.0,229.0,230.0,231.0,232.0,233.0,234.0,235.0,236.0,237.0,238.0,239.0,240.0,241.0,242.0,243.0,244.0,245.0,246.0,247.0,248.0,249.0,250.0,251.0,252.0,253.0,254.0,255.0,256.0,257.0,258.0,259.0,260.0,261.0,262.0,263.0,264.0,265.0,266.0,267.0,268.0,269.0,270.0,271.0,272.0,273.0,274.0,275.0,276.0,277.0,278.0,279.0,280.0,281.0,282.0,283.0,284.0,285.0,286.0,287.0,288.0,289.0,290.0,291.0,292.0,293.0,294.0,295.0,296.0,297.0,298.0,299.0,300.0,301.0,302.0,303.0,304.0,305.0,306.0,307.0,308.0,309.0,310.0,311.0,312.0,313.0,314.0,315.0,316.0,317.0,318.0,319.0,320.0,321.0,322.0,323.0,324.0,325.0,326.0,327.0,328.0,329.0,330.0,331.0,332.0,333.0,334.0,335.0,336.0,337.0,338.0,339.0,340.0,341.0,342.0,343.0,344.0,345.0,346.0,347.0,348.0,349.0,350.0,351.0,352.0,353.0,354.0,355.0,356.0,357.0,358.0,359.0,360.0,361.0,362.0,363.0,364.0,365.0,366.0,367.0,368.0,369.0,370.0,371.0,372.0,373.0,374.0,375.0,376.0,377.0,378.0,379.0,380.0,381.0,382.0,383.0,384.0,385.0,386.0,387.0,388.0,389.0,390.0,391.0,392.0,393.0,394.0,395.0,396.0,397.0,398.0,399.0,400.0,401.0,402.0,403.0,404.0,405.0,406.0,407.0,408.0,409.0,410.0,411.0,412.0,413.0,414.0,415.0,416.0,417.0,418.0,419.0,420.0,421.0,422.0,423.0,424.0,425.0,426.0,427.0,428.0,429.0,430.0,431.0,432.0,433.0,434.0,435.0,436.0,437.0,438.0,439.0,440.0,441.0,442.0,443.0,444.0,445.0,446.0,447.0,448.0,449.0,450.0,451.0,452.0,453.0,454.0,455.0,456.0,457.0,458.0,459.0,460.0,461.0,462.0,463.0,464.0,465.0,466.0,467.0,468.0,469.0,470.0,471.0,472.0,473.0,474.0,475.0,476.0,477.0,478.0,479.0,480.0,481.0,482.0,483.0,484.0,485.0,486.0,487.0,488.0,489.0,490.0,491.0,492.0,493.0,494.0,495.0,496.0,497.0,498.0,499.0,500.0,501.0,502.0,503.0,504.0,505.0,506.0,507.0,508.0,509.0,510.0,511.0,512.0,513.0,514.0,515.0,516.0,517.0,518.0,519.0,520.0,521.0,522.0,523.0,524.0,525.0,526.0,527.0,528.0,529.0,530.0,531.0,532.0,533.0,534.0,535.0,536.0,537.0,538.0,539.0,540.0,541.0,542.0,543.0,544.0,545.0,546.0,547.0,548.0,549.0,550.0,551.0,552.0,553.0,554.0,555.0,556.0,557.0,558.0,559.0,560.0,561.0,562.0,563.0,564.0,565.0,566.0,567.0,568.0,569.0,570.0,571.0,572.0,573.0,574.0,575.0,576.0,577.0,578.0,579.0,580.0,581.0,582.0,583.0,584.0,585.0,586.0,587.0,588.0,589.0,590.0,591.0,592.0,593.0,594.0,595.0,596.0,597.0,598.0,599.0,600.0,601.0,602.0,603.0,604.0,605.0,606.0,607.0,608.0,609.0,610.0,611.0,612.0,613.0,614.0,615.0,616.0,617.0,618.0,619.0,620.0,621.0,622.0,623.0,624.0,625.0,626.0,627.0,628.0,629.0,630.0,631.0,632.0,633.0,634.0,635.0,636.0,637.0,638.0,639.0,640.0,641.0,642.0,643.0,644.0,645.0,646.0,647.0,648.0,649.0,650.0,651.0,652.0,653.0,654.0,655.0,656.0,657.0,658.0,659.0,660.0,661.0,662.0,663.0,664.0,665.0,666.0,667.0,668.0,669.0,670.0,671.0,672.0,673.0,674.0,675.0,676.0,677.0,678.0,679.0,680.0,681.0,682.0,683.0,684.0,685.0,686.0,687.0,688.0,689.0,690.0,691.0,692.0,693.0,694.0,695.0,696.0,697.0,698.0,699.0,700.0,701.0,702.0,703.0,704.0,705.0,706.0,707.0,708.0,709.0,710.0,711.0,712.0,713.0,714.0,715.0,716.0,717.0,718.0,719.0,720.0,721.0,722.0,723.0,724.0,725.0,726.0,727.0,728.0,729.0,730.0,731.0,732.0,733.0,734.0,735.0,736.0,737.0,738.0,739.0,740.0,741.0,742.0,743.0,744.0,745.0,746.0,747.0,748.0,749.0,750.0,751.0,752.0,753.0,754.0,755.0,756.0,757.0,758.0,759.0,760.0,761.0,762.0,763.0,764.0,765.0,766.0,767.0,768.0,769.0,770.0,771.0,772.0,773.0,774.0,775.0,776.0,777.0,778.0,779.0,780.0,781.0,782.0,783.0,784.0,785.0,786.0,787.0,788.0,789.0,790.0,791.0,792.0,793.0,794.0,795.0,796.0,797.0,798.0,799.0,800.0,801.0,802.0,803.0,804.0,805.0,806.0,807.0,808.0,809.0,810.0,811.0,812.0,813.0],\"xaxis\":\"x\",\"y\":[0.5848803701744885,3.674894709377467,2.195631528964867,0.0741464417934985,1.4517260517260517,1.3067781891311334,0.6296620046620092,2.459927327574391,0.038115266376134826,1.1460892640560125,3.441191567053636,1.4519897061126414,6.981579102012535,0.8799749728542317,3.503810682071549,0.24495874495874048,3.1990137055926517,2.7471861471861487,3.8220205720205698,3.4393083941956135,3.468519225872164,4.898476523476525,2.2875185816362276,6.3946562209720135,1.6316672153811353,3.589100957522014,3.9552381790513884,4.83445892624392,0.481550099516852,1.7725588839472657,0.11836311836312063,4.0225346548876,3.4978034235000166,0.03917215681921249,1.9502112219503545,1.6594201289853423,3.4193639693639675,0.53148821621728,5.898259853247062,2.5214677298010635,5.856840985101854,3.650368150368152,0.9383000489138631,3.941123908770969,0.8000294320626793,7.970946597262385,2.506735688553867,6.541585398728259,2.2009799058123196,2.933669816022757,4.148196345564774,1.2564238880028356,1.0984940984941005,3.237170237170236,2.3849987535589143,1.0123765123765125,1.2048390206284942,4.248526308796869,1.2874073957886445,0.6074385582604016,3.025226625226626,3.1732554528121035,1.5561138208197036,0.6879155702685118,4.37157170315065,3.6988408781512234,3.646551086206255,2.26386013342535,1.9556277056277018,8.164870980141913,5.522161172161169,4.98238605220029,0.9309220764329105,1.780668496354771,1.0824668498465293,4.487989871448519,2.4027824027824067,3.0485617712508457,1.8876558876558818,6.791561920162325,1.3731317415527968,4.980852480852478,0.027597402597404397,1.9262246754506798,1.704971795880887,9.279706288109654,1.8690664531737795,5.87706572603598,3.5939705222313947,2.188369937595944,0.21139840551605005,2.6971165286954744,5.875712693103996,1.1600129173658544,1.165012765012765,0.26734522787154447,5.650811907390853,0.03362602309971052,2.3359020866760787,6.305002187355132,3.61394660800433,2.1258177915040655,1.5530028794734676,2.5723981900452486,2.8929420252949676,0.4935623153014461,5.211810396242374,1.7524601301691085,0.23753089016246953,5.042668442668447,1.5574148074148049,2.8069187413167622,0.43680709742090684,3.9761793761793776,0.6789183039183051,0.38590429178664465,4.066303149894484,0.5844155844155878,4.666831078230421,2.5058639696320846,2.513498694779104,2.500693285720022,0.14700703493273437,2.8191903334760475,0.14028892254698277,1.2438009616802148,1.659159293087864,5.387527383508383,4.25471913707208,0.5012242561114704,2.0759058401915578,4.031341207811796,0.3886890052303613,0.7610280786751389,2.8857810121567233,8.034699777346837,3.300034146716065,5.099260388734072,0.33635884239599534,0.21526784762079387,0.8587791861449166,4.501028383381321,1.4620675620675598,0.9194677871148471,2.9481744446030174,4.925388145688892,7.402289819681123,0.9752024291497996,0.915750915750916,8.245095255621575,3.4892311886964293,0.5010545010545009,2.9830743588483486,4.116984464810557,1.8929557284820433,5.049080004962363,3.3902842124867796,0.7331557331557335,0.492619085056063,0.383502045156181,3.0211564035093446,4.99587667234726,4.7722241556828,8.617537158404028,1.9153325665930723,2.7536485253876553,3.1951093958285846,1.566744032909444,4.455154322801379,10.257537669302373,2.561739847454131,11.042922344357754,2.871913800485226,2.052072927072926,1.0905587262508956,3.4137312008460476,1.6894914609200313,3.6401227322953,0.3579198579198497,5.658767319636887,10.624165952352786,6.85755478574162,2.3026824775551447,2.1531968466190428,5.274078862314159,3.851540387708397,7.0871153646916625,4.998537721226796,1.6969190326112091,8.661238566501725,0.5729907347554466,6.308510961654978,1.5923726032421683,0.8004864502542546,3.4098279171808556,4.9638157358307105,0.5142926735911786,2.7311614300892764,4.0787438558736735,2.7723870332565994,0.3155622941116114,7.536985563456154,0.08096070596070604,4.453546453546455,7.371360837305108,0.6635602959132392,2.4647598044656895,0.27701927701927787,9.101510405858235,6.382426127889525,8.377093494740551,5.263087789403581,1.6968286517158706,3.367116602730409,1.5067821067821079,5.923742923742928,8.89469931513275,6.276441102756891,4.614868464868458,2.7741106932283337,1.6372805041535727,1.6085719119774886,1.989262371615311,0.5607311791522314,2.038296344178697,0.8701590806853936,4.745894206044579,3.7380649720322463,2.7631970139710056,0.6617582727831142,3.3943556443556453,5.1146927146927155,2.219594462561215,4.379043886396833,5.301298701298702,0.9256620572410021,0.23676323676323463,3.3318420101394164,0.0014167470701771379,1.2084857866591605,1.0436230436230396,1.1984584043407551,5.261533229412482,4.5449902546676775,4.880991213808549,0.701779701779703,2.8984084698370403,0.5252747252747234,1.4420130594043634,0.8652224968014437,0.8616536971800137,4.507418507418507,1.91360363774157,3.653970612584537,1.5211163516790123,1.3293743293743319,3.9338845062982983,5.7617890881048766,0.37886035533094287,1.9375777479225746,0.36673326673326656,1.376428639586532,1.9430090606561166,0.24675531054249333,0.24066072672883365,1.3138269293731497,4.557382432382429,4.339025467286341,1.973024223798216,3.962015624554322,0.6487811705203015,1.6581999155528564,5.54426901214827,1.844410135319226,0.3419913419913385,3.3576914358128,1.372138997912991,0.8806141484934074,5.794440841809262,5.347498906322437,7.279662251356191,3.356680356680357,0.5665445665445645,1.1491656491656457,6.95130055130055,2.112248105214853,1.4153545256486453,1.7496478753444684,3.666765398344346,3.4021978021978043,7.111048863990046,0.42518461930226437,0.049803866821054754,2.728643954207868,5.193865145125653,0.7289720947387899,1.836255113831406,1.6319002634792064,0.29537053335680596,3.1941822882999347,4.175532800532803,2.57215153267785,0.36970436970436893,0.27572439232103463,4.791500166500171,0.2386837563308113,3.8635706030664014,1.4749818955922436,1.385270336422412,1.6623251762570632,6.635191875793382,2.3588263588263594,7.0422205245734695,1.3793787911435018,9.6275145540562,0.9811373811373834,3.1756751655428808,1.5830086580086515,1.0160544855153795,9.626148705096073,1.9028605381546555,2.506107589234528,0.4258459119140241,2.469371587018646,2.700160999626238,1.5448990055128107,10.129318780634573,4.405642256902766,0.8453674985915818,0.7931523022432145,0.3593162630595792,5.93556476203535,9.826141179082356,0.20833632598338525,3.862272727272728,2.667499853312208,1.1795139004218278,0.7060719024451885,1.0943006573258671,6.261271843624787,7.615548641245233,1.8632787615243807,0.13987863987864202,7.355161823041083,4.50733216059303,4.755355755355755,5.264778668387979,0.19109270502459452,0.1951479892656316,0.10028533557945707,0.8044083730358231,4.5676661573720345,8.326483652799439,2.162011598328732,9.104741550989017,6.87046534476875,2.0478595478595487,5.308108506560519,1.2015898331687822,0.5139073173128921,1.8087643350801237,2.460187340570112,2.669416857652152,0.9959091944737857,2.804736929736926,1.0173076923076962,4.04652153258964,8.39448061016689,4.9654161488747945,4.0184385789648935,2.5395361203410793,5.291117923470864,0.9409849409849436,6.311196203535747,1.7136668628928717,1.0193880193880176,3.85338922916322,2.6403078403078446,8.9119582734556,2.209469670635375,1.546601546601547,5.808749934276246,4.2999413945656535,8.639748130657225,8.158315854419751,5.012851523721093,3.9538466177785025,1.7831442273141889,0.2805921538823348,1.3745143745143729,2.5200661236154396,2.262642971064029,4.040401537460365,3.106782106782102,2.686912560430347,1.7975680191069188,2.8577921273573494,4.042366427393166,0.4285712758365037,8.594021446962627,4.672173502779433,1.650781296695957,3.5247715247715234,0.6410574932314077,1.5883512199301677,6.746539354365439,5.8815153826595505,1.1727016214411154,3.112630506748147,8.84927194018103,1.1501400560224049,3.8928551244340746,7.392141192141192,0.10292210369609833,4.286932294285233,2.1360249330174135,0.5165532680243352,1.705323915850233,6.832893772893772,6.126775825505408,2.370901240466459,1.940270303460224,7.549713032065972,1.6856587856587808,4.26791405557438,1.49168750639339,2.3099615452556606,8.107334633031229,0.25027341079972487,0.9104281425488878,5.2231725220283565,0.008938698593869532,0.2313635327989374,1.7094877258963947,2.191438191438195,0.5107212475633531,3.053887389413706,0.33953984221363953,1.7835630127190214,1.5853655603655596,6.583344448890669,5.9877661554132136,3.2694342694342673,4.719749694749698,0.7510567863509046,10.888385253091135,5.194547583479476,4.475460487225195,0.8196981123451721,9.074890469008116,2.066430330113196,7.09756829571071,6.634071810542395,7.238900315370904,10.686741363211956,1.9102980352980374,0.6906719833762516,5.986650137910644,0.5553040354897938,3.3092349892221993,4.326395608748548,0.8976715292504771,0.7670008354218929,0.9906918564260465,3.0840833323605708,3.145310107848811,3.1320444261620786,4.620879120879124,2.387642904051578,2.6220030972352966,6.1509171636664295,4.937518037518039,2.66812577873959,3.655656388429499,0.2978241801771233,3.3358452692818013,1.08491935235633,5.315548503783798,3.8579462095853714,5.671122080846253,5.945363125007088,3.8697971364932897,1.273472141893194,3.187092235495598,4.19491496473594,1.1410173160173152,6.338639115728901,1.4866370471633665,0.2675657675657668,3.0140084316554905,2.2918081918081903,0.5165577342047953,0.553728778960977,2.6161172161172175,4.544865562245242,3.873755802161373,4.734752164473527,1.6272877449347973,1.6686801760331136,1.33915901493301,5.7468805704099815,2.383951560422151,3.125354057707,4.787362792006757,5.921356421356421,1.3433494609965173,1.2719769119769175,4.568982710693938,0.3841232121592668,0.3823267375898993,12.246004541571052,4.43827690770415,7.345772932922621,0.21831577513395573,0.7963293855553957,5.753123347241001,0.7637771814242384,5.754282754282759,0.0948509580088519,2.323464712251898,4.528080897430744,1.5098166539343048,5.164517162526893,0.8691197691197701,1.859943977591037,1.0352263982516092,0.5968576086223152,3.944900775506703,5.004670819376706,1.3156609472398912,6.648048030400972,2.899111781464722,3.754745676094444,0.5779054279054243,0.6115288220551349,4.956284357353876,3.7802036199095,2.993870010278677,2.8125538949068343,0.5206077147253652,2.1322139536043316,1.4756907580437044,0.7922958810830636,0.09583618995383958,4.849489725960311,3.1209574738986454,2.773161668302336,0.3091144235881096,4.572996253668524,4.6129782915497195,3.553491436100135,1.5367965367965368,1.4520640579464121,3.4936161333220177,0.9960157489569283,2.3898868638364448,8.798545414976198,5.549737843855489,7.394645064183358,3.5722904546433973,1.7483518659989237,1.889474904180787,0.38533225647238467,4.078389721733377,1.2959910459910446,1.9392660038843914,7.263389500561583,6.614630872845883,1.0539143396286228,3.366564341354259,2.6850066600066604,3.0231126897793565,2.394586667618995,5.774330431473292,1.094522144522145,6.488315916887343,3.8387740079469417,2.767740196311628,1.1119498250298392,5.395414389532036,1.2908415400675501,2.9936221186221204,1.5018315018314965,1.1481472833221744,1.8377994554465182,2.0009466024171907,4.381300888653829,3.8508326998029503,1.903268358598826,3.3828563593269436,5.695504495504494,6.7155955155955205,1.2657988344262847,2.827656141588033,7.02332613393995,0.8837415071430463,0.9311588995799518,0.464800112168529,6.607908109206811,4.911203082631655,1.073411033411034,2.253950921330599,4.549097544156002,1.3880752445661138,4.197959992077639,3.84129813541578,5.240965113318055,0.5244316141374945,4.7151724092900515,3.5772005772005784,8.611708334196372,1.4995744995744964,1.0485558559087949,1.4691587903929069,5.616983016983017,2.8454138454138445,1.808338707068284,10.588267941209121,2.2247346306943854,1.8951716364229654,0.8920728792851556,5.7417818143562975,4.923329319210325,2.570250039815253,0.03664391164391034,1.1395863395863408,2.6995303438585516,6.481389248160404,0.746358380916103,0.239693750971945,1.2351550410373946,4.638016826804016,2.232051282051284,4.334279385539894,7.813438023964341,5.815681833694256,4.404845154845155,8.75364846793418,2.135762633088838,8.47162913339384,0.841723773302725,3.672275139148198,6.967782217782219,2.2983682983683025,5.30113657386385,2.0688233335292097,1.139637536376668,3.4321850263026725,3.874133737816603,1.4140325431885543,8.64896331738437,6.737803677803679,1.0655300581771172,2.6908450481979855,5.742492801316331,3.5915696503931756,3.276080461219781,0.8728291316526615,6.269021070725483,0.5141129814926657,3.535569985569989,7.170647441280035,5.100176626492416,0.6078741182189482,2.539605034341875,1.9398671503934644,0.5034743034743023,2.468236568923068,1.8131909141761327,1.1194994664265714,1.0650308755571913,0.217488393958984,5.647332234329134,1.6376296117675437,6.6994224099487205,3.076664977534545,4.215048719396547,1.8103184454933388,6.552855164885241,0.12242187636924484,7.456808688387634,3.248314710499585,3.2750760072188676,3.6388731569182706,2.2103349498307487,3.0656565656565604,1.9397084397084434,3.6720936675096283,6.059315839866958,2.0741812109459197,2.9650550463580494,0.49773785112130753,2.758007243301357,3.9512820512820515,6.223217305570246,2.886654687798849,2.3260739260739243,8.29329189329189,5.090806547949409,4.8161582670203344,3.16135416870711,1.2802515283333662,4.957838620119322,4.0810334592943285,0.44577644577644193,1.1122710622710628,4.1380328821505294,2.8389124316543644,5.150375939849626,0.20197112337758227,2.198545105687966,5.300089328660757,6.632910802274109,0.15806994126322138,1.9908963585434165,8.884786008625019,2.6894021609860097,2.2825643492310164,2.5252376622345594,5.965510959628608,0.2839748339527226,3.1677975533238687,1.7282238458709038,1.098244348244343,3.3187799043062185,2.029718014061226,3.2124640065816514,7.024463118580767,1.152849684428631,1.4579864579864577,2.4665822064318306,0.4287878787878796,3.709723171565278,3.0142172642172653,2.2389016212545627,8.662337662337661,2.1252754309385633,7.008449720214426,0.31467443232148895,4.255346614170147,2.2334430930749285,3.3918791734581255,1.0545193368722785,1.702775002775006,3.055144855144853,0.9754379505932285,0.3063329613528616,1.7205710955710956,2.486455211455212,0.478252575311398,5.084084866924314,4.5121794009012035,4.0335802828062945,8.386946386946395,1.8995951476769903,3.1490005923442403,5.492969301663694,3.5182181182181154,5.827766916286723,1.0460128639476451,6.383533886573048,8.344266377879826,9.15809837439932,2.0651175039046876,1.0662177328844002,0.4843353626315121,2.15145556198188,0.2976996859349761,0.01830506095211959,1.139248405915069,4.505201438490214,1.5410584016722098,0.7568764568764585,3.150910979858349,0.9301131616921126,4.697388885624177,1.1525659525659542,0.8127854094240625,0.25536062378167657,3.993792450935313,7.394819994819992,4.5813445813445774,1.5177110184850093,4.177880243006296,1.403649154423146,5.695371295371299,5.0751569284177975,2.162372651503091,0.49444964697802973,5.049565954327861,5.824696001166586,3.2423944286072413,2.415905756241891,3.846055851090176,1.8118210765269573,2.9567531883321365,3.6432380761429037,1.233173572459286,7.763819513819513,3.529437229437228,2.2636191618647743,3.2610293215556396,0.6331433272609743,0.5914100423904394,2.078728289254606,2.3566849816849818,4.0011489883612725,4.376881619848373,1.1281552585900414,0.595185279499006,0.48729166339688845,4.709959322577827,5.453684193179992,1.3971283520155673],\"yaxis\":\"y\"}],                        {\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Uncertainty\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"legend\":{\"tracegroupgap\":0},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Uncertainty Distribution for CONFD for instantaneous RR error\"},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Samples\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Error Inst Breath(BrPM)\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('55e73c91-30d4-43b9-b698-284c7ec7f948');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if input_conf == 'confb':\n",
    "    fig1 = px.scatter(data_confb,x = 'Samples', y=\"Absolute Error (BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper(),\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    fig1.show()\n",
    "\n",
    "if input_conf == 'confa':\n",
    "    fig1 = px.scatter(data_confa,x = 'Samples', y=\"Absolute Error (BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper(),\n",
    "                   color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    fig1.show()\n",
    "\n",
    "if input_conf == 'confd':\n",
    "    fig1 = px.scatter(data_confd,x = 'Samples', y=\"Error Avg Breath(BrPM)\",title=\"Uncertainty Distribution for \"+input_conf.upper()+ \" for average RR error\" ,\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    \n",
    "    fig2 = px.scatter(data_confd,x = 'Samples', y=\"Error Inst Breath(BrPM)\",title=\"Uncertainty Distribution for \"+input_conf.upper()+ \" for instantaneous RR error\" ,\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    fig1.show()\n",
    "    fig2.show()\n",
    "     \n",
    "\n",
    "if input_conf == 'conff':\n",
    "    fig1 = px.scatter(data_conff,x = 'Samples', y=\"Error Avg Breath(BrPM)\",title=\"Uncertainty Distribution for \"+input_conf.upper()+ \" for average RR error\" ,\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    \n",
    "    fig2 = px.scatter(data_conff,x = 'Samples', y=\"Error Inst Breath(BrPM)\",title=\"Uncertainty Distribution for \"+input_conf.upper()+ \" for instantaneous RR error\" ,\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    fig1.show()\n",
    "    fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fada58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a0930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68293d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75710940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e0d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu25",
   "language": "python",
   "name": "tf_gpu25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
