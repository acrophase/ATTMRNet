{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "SEED = 0\n",
    "#------------------------------------------------------------------------------------\n",
    "def set_seeds(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "#------------------------------------------------------------------------------------\n",
    "def set_global_determinism(seed=SEED):\n",
    "    set_seeds(seed=seed)\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    \n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Call the above function with seed value\n",
    "set_global_determinism(seed=SEED)\n",
    "#-----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.4.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "from data_extraction import *\n",
    "from resp_signal_extraction import *\n",
    "from rr_extration import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "import pickle as pkl\n",
    "from tf_model import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber\n",
    "import matplotlib.pyplot as plt\n",
    "from filters import *\n",
    "import tqdm\n",
    "import plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import ipywidgets as widgets\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "py.offline.init_notebook_mode(connected = True)\n",
    "from plotly import tools\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_conf = 'conff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-10 17:30:43.135355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-10 17:30:43.140526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-10 17:30:43.140854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-10 17:30:43.141782: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-10 17:30:43.141948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-10 17:30:43.142417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-10 17:30:43.142716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-10 17:30:43.466822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-10 17:30:43.467178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-10 17:30:43.467488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-10 17:30:43.467813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10345 MB memory:  -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "with open('output','rb') as f:\n",
    "    output_data = pkl.load(f)\n",
    "\n",
    "with open('input','rb') as f:\n",
    "    input_data = pkl.load(f)\n",
    "\n",
    "with open('raw_signal.pkl','rb') as f:\n",
    "    raw_data = pkl.load(f)\n",
    "\n",
    "input_data = np.transpose(input_data, (0,2,1))\n",
    "raw_data = np.transpose(raw_data, (0,2,1))\n",
    "annotation = pd.read_pickle('/media/acrophase/pose1/charan/BR_Uncertainty/MONTE_CARLO/annotation.pkl')\n",
    "reference_rr = (annotation['Reference_RR'].values).reshape(-1,1)\n",
    "\n",
    "input_data = np.around(input_data , decimals = 4)\n",
    "raw_data = np.around(raw_data , decimals = 4)\n",
    "output_data = np.around(output_data , decimals = 4)\n",
    "reference_rr = np.around(reference_rr , decimals = 4)\n",
    "\n",
    "tensor_input = tf.convert_to_tensor(input_data, dtype = 'float32')\n",
    "tensor_output = tf.convert_to_tensor(output_data, dtype = 'float32')\n",
    "tensor_ref_rr = tf.convert_to_tensor(reference_rr, dtype = 'float32')\n",
    "tensor_raw_data = tf.convert_to_tensor(raw_data, dtype = 'float32')\n",
    "training_ids = annotation['patient_id'] < 13\n",
    "\n",
    "x_train_data = tensor_input[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_data = tensor_input[tf.convert_to_tensor(~(training_ids.values))]\n",
    "x_train_ref_rr = tensor_ref_rr[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_ref_rr = tensor_ref_rr[tf.convert_to_tensor(~(training_ids.values))]\n",
    "x_train_raw_sig = tensor_raw_data[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_raw_sig = tensor_raw_data[tf.convert_to_tensor(~(training_ids.values))]\n",
    "\n",
    "y_train_data = tensor_output[tf.convert_to_tensor(training_ids.values)]\n",
    "y_test_data = tensor_output[tf.convert_to_tensor(~(training_ids.values))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , y_train_data))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , y_test_data))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confb':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confd':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , y_train_data, x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , y_test_data, x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "if input_conf == 'confa':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_raw_sig)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confe':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , y_train_data))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_raw_sig)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , y_test_data))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "if input_conf == 'conff':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , y_train_data, x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , y_test_data, x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-10 17:30:44.552234: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8202\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confc':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/MONTE_CARLO/TEST_SAVE_MODEL/confc/best_model_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,y_batch_test) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = loss_fn(y_batch_test , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "        \n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confd':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Multi_resp(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/MONTE_CARLO/TEST_SAVE_MODEL/confd/best_model_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,y_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr = model(x_batch_test)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "            \n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confb':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Encoder(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/MONTE_CARLO/TEST_SAVE_MODEL/confb/best_model_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confe':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/MONTE_CARLO/TEST_SAVE_MODEL/confe/best_model_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw,y_batch_test) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(y_batch_test , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "        \n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confa':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_encoder(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/MONTE_CARLO/TEST_SAVE_MODEL/confa/best_model_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw, x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_multi(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/MONTE_CARLO/TEST_SAVE_MODEL/conff/best_model_100.h5')        \n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    for step , (x_batch_test_raw , y_batch_test , x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr = model(x_batch_test_raw)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MONTE CARLO WITH SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:17<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confc':\n",
    "    final_output = np.array([])\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/MONTE_CARLO/TEST_SAVE_MODEL/confc/best_model_100.h5')\n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        for step,(x_batch_test , y_batch_test) in enumerate(test_dataset):\n",
    "            output = model(x_batch_test)\n",
    "            test_loss = loss_fn(y_batch_test,output)\n",
    "            if step == 0:\n",
    "                output_data = output\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , output] , axis = 0)\n",
    "            test_loss_list.append(test_loss)\n",
    "        output_array = output_data.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confd':\n",
    "    final_output = np.array([])\n",
    "    final_output_rr = np.array([])\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Multi_resp(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/MONTE_CARLO/TEST_SAVE_MODEL/confd/best_model_100.h5')\n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        output_data_rr = tf.convert_to_tensor([])\n",
    "        for step , (x_batch_test,y_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "            test_output,test_out_rr = model(x_batch_test)\n",
    "            test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "            test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "            test_loss = test_loss_resp + test_loss_rr\n",
    "            if step == 0:\n",
    "                output_data = test_output\n",
    "                output_data_rr = test_out_rr\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , test_output] , axis = 0)\n",
    "                output_data_rr = tf.concat([output_data_rr , test_out_rr] , axis = 0)\n",
    "            test_loss_list.append(test_loss)\n",
    "        output_array = output_data.numpy()\n",
    "        output_array_rr = output_data_rr.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        output_array_rr = output_array_rr.reshape(output_array_rr.shape[-1],output_array_rr.shape[0],output_array_rr.shape[1])\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "            final_output_rr = output_array_rr\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "            final_output_rr = np.vstack((final_output_rr,output_array_rr))\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confb':\n",
    "    final_output = np.array([])\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Encoder(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/MONTE_CARLO/TEST_SAVE_MODEL/confb/best_model_100.h5')\n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        for step , (x_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "            output = model(x_batch_test)\n",
    "            test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "            if step == 0:\n",
    "                output_data = output\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , output] , axis = 0)\n",
    "            test_loss_list.append(test_loss)\n",
    "        output_array = output_data.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confe':\n",
    "    final_output = np.array([])\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/MONTE_CARLO/TEST_SAVE_MODEL/confe/best_model_100.h5')\n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])        \n",
    "        for step , (x_batch_test_raw,y_batch_test) in enumerate(test_dataset):\n",
    "            output = model(x_batch_test_raw)\n",
    "            test_loss = loss_fn(y_batch_test , output)\n",
    "            if step == 0:\n",
    "                output_data = output\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , output] , axis = 0)\n",
    "            test_loss_list.append(test_loss)\n",
    "        output_array = output_data.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confa':\n",
    "    final_output = np.array([])\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_encoder(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/MONTE_CARLO/TEST_SAVE_MODEL/confa/best_model_100.h5')\n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        for step , (x_batch_test_raw, x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "            output = model(x_batch_test_raw)\n",
    "            test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "            if step == 0:\n",
    "                output_data = output\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , output] , axis = 0)\n",
    "            test_loss_list.append(test_loss)  \n",
    "        output_array = output_data.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "            \n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    final_output = np.array([])\n",
    "    final_output_rr = np.array([])\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_multi(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/BR_Uncertainty/MONTE_CARLO/TEST_SAVE_MODEL/conff/best_model_100.h5') \n",
    "    for i in tqdm.tqdm(range(10)):\n",
    "        test_loss_list = []\n",
    "        output_data = tf.convert_to_tensor([])\n",
    "        output_data_rr = tf.convert_to_tensor([])\n",
    "        for step , (x_batch_test_raw , y_batch_test , x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "            test_output,test_out_rr = model(x_batch_test_raw)\n",
    "            test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "            test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "            test_loss = test_loss_resp + test_loss_rr\n",
    "            if step == 0:\n",
    "                output_data = test_output\n",
    "                output_data_rr = test_out_rr\n",
    "            else:\n",
    "                output_data = tf.concat([output_data , test_output] , axis = 0)\n",
    "                output_data_rr = tf.concat([output_data_rr , test_out_rr] , axis = 0)\n",
    "            test_loss_list.append(test_loss)\n",
    "        output_array = output_data.numpy()\n",
    "        output_array_rr = output_data_rr.numpy()\n",
    "        output_array = output_array.reshape(output_array.shape[-1],output_array.shape[0],output_array.shape[1])\n",
    "        output_array_rr = output_array_rr.reshape(output_array_rr.shape[-1],output_array_rr.shape[0],output_array_rr.shape[1])\n",
    "        if i == 0:\n",
    "            final_output = output_array\n",
    "            final_output_rr = output_array_rr\n",
    "        else:\n",
    "            final_output = np.vstack((final_output,output_array))\n",
    "            final_output_rr = np.vstack((final_output_rr,output_array_rr))\n",
    "#-------------------------------------------------------------------------------------------------------------------------------            \n",
    "        \n",
    "                        \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extremas_extraction(signal):\n",
    "    avg_breath_duration = np.array([])\n",
    "    extrema_relevent = []\n",
    "    for item in signal:\n",
    "        amplitude = np.array([])\n",
    "        pos_peaks , _ = scipy.signal.find_peaks(item , height = [-3000,3000])\n",
    "        neg_peaks , _ = scipy.signal.find_peaks(-1*item , height = [-3000 , 3000])\n",
    "        extremas = np.concatenate((pos_peaks , neg_peaks))\n",
    "        extremas = np.sort(extremas)\n",
    "        for i in range(len(extremas)):\n",
    "            amplitude = np.append(amplitude , item[int(extremas[i])])\n",
    "        amplitude_diff = np.abs(np.diff(amplitude))\n",
    "        q3 = np.percentile(amplitude_diff , 75)\n",
    "        threshold = 0.3*q3\n",
    "        eliminate_pairs_of_extrema = 1\n",
    "        while(eliminate_pairs_of_extrema):\n",
    "            amps = np.array([])\n",
    "            if len(extremas)<3:\n",
    "                eliminate_pairs_of_extrema = 0\n",
    "                continue\n",
    "            for i in range(len(extremas)):\n",
    "                amps = np.append(amps , item[int(extremas[i])])\n",
    "            amp_diff = np.abs(np.diff(amps)) \n",
    "            min_amp_diff , index = min(amp_diff) , np.argmin(amp_diff)\n",
    "            #print(min_amp_diff)\n",
    "            if min_amp_diff > threshold:\n",
    "                eliminate_pairs_of_extrema = 0\n",
    "                #extrema_relevent = extremas\n",
    "            else:\n",
    "                extremas = np.concatenate((extremas[0:index] , extremas[index+2 :]))\n",
    "                #amplitude_diff = np.delete(amplitude_diff , index)\n",
    "        if item[int(extremas[0])] < item[int(extremas[1])]:\n",
    "            extremas = extremas[1:]\n",
    "        if item[int(extremas[-1])] < item[int(extremas[-2])]:\n",
    "            extremas = extremas[:-1]\n",
    "        no_of_breaths = (len(extremas)-1)/2\n",
    "        breath_duration = extremas[-1] - extremas[0]\n",
    "        avg_breath_duration = np.append(avg_breath_duration , breath_duration/no_of_breaths)\n",
    "        extrema_relevent.append(extremas)\n",
    "    return avg_breath_duration , extrema_relevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sig = y_test_data.numpy()\n",
    "fbpB , fbpA = band_pass(0.1,0.7,8)\n",
    "final_ref_resp_sig = []\n",
    "for item in ref_sig:\n",
    "    final_ref_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "final_ref_resp_sig = np.array(final_ref_resp_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confa':\n",
    "    l = 0.05\n",
    "    drop_prob = 0.1\n",
    "    lam = 0.01\n",
    "    final_output_rr = np.mean(final_output , axis = 0)\n",
    "    final_var = np.var(final_output , axis = 0)\n",
    "    tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    final_var += (tau**-1)\n",
    "    output_copy = final_output_rr\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    #final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "    \n",
    "    samples = np.arange(0,len(final_output_rr)).reshape(-1,1)\n",
    "    confa_data = np.hstack((samples,final_output_rr ,final_var ,error))\n",
    "    col_confa = ['Samples','Final RR Output (BrPM)' ,'Uncertainty','Absolute Error']\n",
    "    data_confa = pd.DataFrame(confa_data , columns = col_confa)\n",
    "#----------------------------------------------------------------------------------------------------------------   \n",
    "if input_conf == 'confb':\n",
    "    l = 0.005\n",
    "    drop_prob = 0.1\n",
    "    lam = 0.005\n",
    "    final_output_rr = np.mean(final_output , axis = 0)\n",
    "    final_var = np.var(final_output , axis = 0)\n",
    "    tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    final_var += (tau**-1)\n",
    "    output_copy = final_output_rr\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    #final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "    \n",
    "    samples = np.arange(0,len(final_output_rr)).reshape(-1,1)\n",
    "    confb_data = np.hstack((samples,final_output_rr , final_var, error))\n",
    "    col_confb = ['Samples','Final RR Output (BrPM)' , 'Uncertainty', 'Absolute Error']\n",
    "    data_confb = pd.DataFrame(confb_data , columns = col_confb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    l = 5\n",
    "    drop_prob = 0.1\n",
    "    lam = 0.01\n",
    "    \n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = np.mean(final_output , axis = 0)\n",
    "    final_var = np.var(final_output , axis = 0)\n",
    "    tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    final_var += (tau**-1)\n",
    "    output_copy = final_output_resp\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    #final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "\n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "    print(final_var)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------    \n",
    "if input_conf == 'confe':\n",
    "    l = 1\n",
    "    drop_prob = 0.1\n",
    "    lam = 0.005\n",
    "    \n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    final_output_resp = np.mean(final_output , axis = 0)\n",
    "    final_var = np.var(final_output , axis = 0)\n",
    "    tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    final_var += (tau**-1)\n",
    "    \n",
    "    output_copy = final_output_resp\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error average wise for conff is: 2.3999964148995265\n",
      "Root Mean Square Error average wise for conff is: 3.0197687783233733\n",
      "Mean Absolute Error instantaneous wise for conff is: 4.704081278889187\n",
      "Root Mean Square Error instantaneous wise for conff is: 5.7085605603985865\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confd':\n",
    "    l = 5\n",
    "    drop_prob = 0.1\n",
    "    lam = 0.01\n",
    "    \n",
    "    l_rr = 0.05\n",
    "    drop_prob_rr = 0.1\n",
    "    lam_rr = 0.01\n",
    "    \n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = np.mean(final_output,axis = 0)\n",
    "    final_rr = np.mean(final_output_rr,axis = 0)\n",
    "    tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    tau_rr = (l_rr**2) * (1-drop_prob_rr) / (2. * lam_rr)\n",
    "    \n",
    "    final_var = np.var(final_output,axis = 0)\n",
    "    final_var_rr = np.var(final_output_rr,axis = 0)\n",
    "    final_var += (tau**-1)\n",
    "    final_var_rr += (tau_rr**-1)\n",
    "    output_copy = final_output_resp\n",
    "    output_copy_rr = final_rr\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    std_dev_rr = np.sqrt(final_var_rr)\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    samples = np.arange(0,len(final_rr)).reshape(-1,1)\n",
    "    confd_data = np.hstack((samples,final_rr , final_var_rr))\n",
    "    col_confd = ['Samples','Final RR Output (BrPM)' , 'Uncertainty']\n",
    "    data_confd = pd.DataFrame(confd_data , columns = col_confd)\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "    \n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'conff':\n",
    "    l = 10\n",
    "    drop_prob = 0.1\n",
    "    lam = 0.05\n",
    "    \n",
    "    l_rr = 0.05\n",
    "    drop_prob_rr = 0.1\n",
    "    lam_rr = 0.05\n",
    "    \n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = np.mean(final_output,axis = 0)\n",
    "    final_rr = np.mean(final_output_rr,axis = 0)\n",
    "    tau = (l**2) * (1-drop_prob) / (2. * lam)\n",
    "    tau_rr = (l_rr**2) * (1-drop_prob_rr) / (2. * lam_rr)\n",
    "    final_var = np.var(final_output,axis = 0)\n",
    "    final_var_rr = np.var(final_output_rr,axis = 0)\n",
    "    final_var += (tau**-1)\n",
    "    final_var_rr += (tau_rr**-1)\n",
    "    output_copy = final_output_resp\n",
    "    output_copy_rr = final_rr\n",
    "    std_dev = np.sqrt(final_var)\n",
    "    std_dev_rr = np.sqrt(final_var_rr)\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    samples = np.arange(0,len(final_rr)).reshape(-1,1)\n",
    "    conff_data = np.hstack((samples,final_rr , final_var_rr))\n",
    "    col_conff = ['Samples','Final RR Output (BrPM)' , 'Uncertainty']\n",
    "    data_conff = pd.DataFrame(conff_data , columns = col_conff)\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da18323514af4e6fbfed4a925516dd05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Record_no:', max=814), Output()), _dom_classes=('widget-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if input_conf == 'confc' or input_conf == 'confe' or input_conf == 'confd' or input_conf == 'conff':\n",
    "    no_of_samples = 32*4\n",
    "    x_unc = np.linspace(start = 0,stop = no_of_samples, num = no_of_samples)\n",
    "    layout_epistemic = go.Layout(\n",
    "    title = \"Respiratory Waveform with Epistemic Uncertainty for \"+ input_conf.upper(),\n",
    "    yaxis = dict(\n",
    "        title = 'Output Respiration Signal' \n",
    "    ),\n",
    "    xaxis = dict(\n",
    "        title = 'samples'\n",
    "    )\n",
    "    )\n",
    "    def update_plot(signals):\n",
    "        data = []\n",
    "            # Reference ECG trace\n",
    "        trace_epistemic = go.Scatter(\n",
    "            x = x_unc,\n",
    "            y = final_output_resp_sig[signals], \n",
    "            mode = 'lines',\n",
    "            name = 'Respiration with Epistemic',\n",
    "                    line = dict(\n",
    "                    shape = 'spline',\n",
    "                    color = 'red',\n",
    "                    width = 5\n",
    "                     ),\n",
    "                error_y=dict(\n",
    "                    type='data', # value of error bar given in data coordinates\n",
    "                    array=final_var[signals],\n",
    "                    visible=True,\n",
    "                    color='black',\n",
    "                thickness=3,\n",
    "                width=5)\n",
    "                )\n",
    "        fig_epistemic = go.Figure(data = [trace_epistemic],layout = layout_epistemic)\n",
    "        py.offline.iplot(fig_epistemic)\n",
    "signals_epsitemic = widgets.IntSlider(min = 0,max = len(final_output_resp_sig), value = 0, description = 'Record_no:')\n",
    "widgets.interactive(update_plot, signals = signals_epsitemic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Samples=%{x}<br>Final RR Output (BrPM)=%{y}<br>Uncertainty=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           44.46677780151367,
           44.48190689086914,
           44.493228912353516,
           44.464759826660156,
           44.47869110107422,
           44.48808670043945,
           44.45536804199219,
           44.452823638916016,
           44.47793960571289,
           44.46826934814453,
           44.46737289428711,
           44.45511245727539,
           44.474124908447266,
           44.470458984375,
           44.47135543823242,
           44.50764083862305,
           44.51530075073242,
           44.48397445678711,
           44.473411560058594,
           44.455387115478516,
           44.48299026489258,
           44.46820068359375,
           44.46551513671875,
           44.493507385253906,
           44.51985168457031,
           44.48424530029297,
           44.484439849853516,
           44.47222900390625,
           44.50489807128906,
           44.47018051147461,
           44.532203674316406,
           44.51932907104492,
           44.48004150390625,
           44.49953079223633,
           44.45798110961914,
           44.4657096862793,
           44.46287536621094,
           44.499053955078125,
           44.55548858642578,
           44.472557067871094,
           44.46790313720703,
           44.54537582397461,
           44.470577239990234,
           44.45614242553711,
           44.46287536621094,
           44.477657318115234,
           44.45863342285156,
           44.469940185546875,
           44.45845031738281,
           44.48273468017578,
           44.47230911254883,
           44.49484634399414,
           44.47888946533203,
           44.46012878417969,
           44.473262786865234,
           44.498374938964844,
           44.578277587890625,
           44.453102111816406,
           44.47730255126953,
           44.51901626586914,
           44.492977142333984,
           44.502201080322266,
           44.45880126953125,
           44.477176666259766,
           44.50088882446289,
           44.47437286376953,
           44.46841049194336,
           44.47426986694336,
           44.46412658691406,
           44.47552490234375,
           44.466304779052734,
           44.493629455566406,
           44.48166275024414,
           44.48377990722656,
           44.46281051635742,
           44.460899353027344,
           44.5211067199707,
           44.497947692871094,
           44.47962188720703,
           44.48185729980469,
           44.483482360839844,
           44.482547760009766,
           44.45383834838867,
           44.48053741455078,
           44.4732551574707,
           44.47439193725586,
           44.682003021240234,
           44.56922149658203,
           44.4960823059082,
           44.47026062011719,
           44.544532775878906,
           44.5091667175293,
           44.4594612121582,
           44.51389694213867,
           44.51649475097656,
           44.509307861328125,
           44.48369598388672,
           44.465030670166016,
           44.50604248046875,
           44.4663200378418,
           44.48111343383789,
           44.46260070800781,
           44.44886779785156,
           44.455360412597656,
           44.457984924316406,
           44.45315170288086,
           44.45435333251953,
           44.45286178588867,
           44.47314453125,
           44.451751708984375,
           44.46822738647461,
           44.451663970947266,
           44.45906066894531,
           44.4574089050293,
           44.459510803222656,
           44.456790924072266,
           44.45960235595703,
           44.453834533691406,
           44.46510696411133,
           44.46086120605469,
           44.473628997802734,
           44.46348190307617,
           44.469825744628906,
           44.458229064941406,
           44.46269989013672,
           44.47064208984375,
           44.47301483154297,
           44.45863342285156,
           44.491756439208984,
           44.482601165771484,
           44.49220275878906,
           44.46697235107422,
           44.47736358642578,
           44.503665924072266,
           44.51458740234375,
           44.486995697021484,
           44.473575592041016,
           44.665618896484375,
           44.5229606628418,
           44.47642135620117,
           44.48150634765625,
           44.4936408996582,
           44.48415756225586,
           44.45913314819336,
           44.46843338012695,
           44.45634841918945,
           44.48126983642578,
           44.52056884765625,
           44.495887756347656,
           44.46376419067383,
           44.47751235961914,
           44.48835754394531,
           44.49551010131836,
           44.513736724853516,
           44.47740936279297,
           44.500064849853516,
           44.45948791503906,
           44.487003326416016,
           44.46255111694336,
           44.447025299072266,
           44.46870422363281,
           44.53411865234375,
           44.46356964111328,
           44.461788177490234,
           44.463623046875,
           44.45442581176758,
           44.50010681152344,
           44.47275161743164,
           44.483245849609375,
           44.459686279296875,
           44.47657775878906,
           44.47993087768555,
           44.46692657470703,
           44.45956802368164,
           44.48954772949219,
           44.46900177001953,
           44.47551727294922,
           44.47327423095703,
           44.453895568847656,
           44.45616912841797,
           44.469364166259766,
           44.46066665649414,
           44.46680450439453,
           44.46603775024414,
           44.46079635620117,
           44.49285125732422,
           44.451683044433594,
           44.450775146484375,
           44.46137619018555,
           44.47611999511719,
           44.46807861328125,
           44.47224807739258,
           44.47694778442383,
           44.454532623291016,
           44.47696304321289,
           44.46227264404297,
           44.4527473449707,
           44.47208786010742,
           44.45792007446289,
           44.461219787597656,
           44.455562591552734,
           44.459983825683594,
           44.454227447509766,
           44.46550369262695,
           44.45975112915039,
           44.504249572753906,
           44.486820220947266,
           44.454769134521484,
           44.516510009765625,
           44.522979736328125,
           44.48513412475586,
           44.54097366333008,
           44.59313201904297,
           44.538429260253906,
           44.6655387878418,
           44.51995849609375,
           44.68891143798828,
           44.4721565246582,
           44.47254943847656,
           44.502864837646484,
           44.51723861694336,
           44.491668701171875,
           44.55946350097656,
           44.47168731689453,
           44.589481353759766,
           44.63154602050781,
           44.46895217895508,
           44.48731231689453,
           44.48401641845703,
           44.479949951171875,
           44.47819137573242,
           44.4559440612793,
           44.48551559448242,
           44.50880813598633,
           44.49491882324219,
           44.50886917114258,
           44.46131896972656,
           44.46696853637695,
           44.47116470336914,
           44.4715461730957,
           44.4576301574707,
           44.464935302734375,
           44.582740783691406,
           44.47835922241211,
           44.49962615966797,
           44.51601028442383,
           44.47718048095703,
           44.52570343017578,
           44.54373550415039,
           44.49314498901367,
           44.49758529663086,
           44.519649505615234,
           44.4730339050293,
           44.566200256347656,
           44.550537109375,
           44.46723175048828,
           44.45498275756836,
           44.50216293334961,
           44.492881774902344,
           44.479915618896484,
           44.48945236206055,
           44.509822845458984,
           44.530540466308594,
           44.5230827331543,
           44.64372253417969,
           44.50553894042969,
           44.50131607055664,
           44.47846984863281,
           44.58293151855469,
           44.5180778503418,
           44.577796936035156,
           44.48908615112305,
           44.52588653564453,
           44.5013542175293,
           44.505672454833984,
           44.472843170166016,
           44.516639709472656,
           44.497562408447266,
           44.49275207519531,
           44.586673736572266,
           44.463558197021484,
           44.467464447021484,
           44.47265625,
           44.454307556152344,
           44.46720886230469,
           44.47762680053711,
           44.458255767822266,
           44.461029052734375,
           44.474796295166016,
           44.486045837402344,
           44.550689697265625,
           44.46165084838867,
           44.460906982421875,
           44.47927474975586,
           44.461544036865234,
           44.48359680175781,
           44.491573333740234,
           44.50713348388672,
           44.4700813293457,
           44.54132080078125,
           44.54810333251953,
           44.476436614990234,
           44.46577072143555,
           44.505863189697266,
           44.46952819824219,
           44.49451446533203,
           44.470462799072266,
           44.480812072753906,
           44.483543395996094,
           44.47829055786133,
           44.51334762573242,
           44.46475601196289,
           44.484012603759766,
           44.47214126586914,
           44.46743392944336,
           44.47031021118164,
           44.4833984375,
           44.51875305175781,
           44.473148345947266,
           44.49821090698242,
           44.47553634643555,
           44.46737289428711,
           44.471065521240234,
           44.48619842529297,
           44.49251174926758,
           44.54160690307617,
           44.45980453491211,
           44.47376251220703,
           44.466957092285156,
           44.46928787231445,
           44.49231719970703,
           44.47693634033203,
           44.454769134521484,
           44.47694396972656,
           44.473243713378906,
           44.461334228515625,
           44.489501953125,
           44.46492004394531,
           44.58440017700195,
           44.55337905883789,
           44.455257415771484,
           44.45771408081055,
           44.47077941894531,
           44.47191619873047,
           44.50017166137695,
           44.453895568847656,
           44.47478103637695,
           44.47821044921875,
           44.493221282958984,
           44.45444107055664,
           44.483760833740234,
           44.479827880859375,
           44.474578857421875,
           44.473663330078125,
           44.47029495239258,
           44.48133087158203,
           44.50408935546875,
           44.45791244506836,
           44.47245788574219,
           44.49342727661133,
           44.48833465576172,
           44.48212814331055,
           44.464881896972656,
           44.46226119995117,
           44.47526168823242,
           44.46308898925781,
           44.52838134765625,
           44.52794647216797,
           44.55164337158203,
           44.45690155029297,
           44.45659637451172,
           44.47050476074219,
           44.47097396850586,
           44.4569206237793,
           44.465858459472656,
           44.51057052612305,
           44.50346374511719,
           44.464942932128906,
           44.48413848876953,
           44.48689651489258,
           44.480377197265625,
           44.482574462890625,
           44.470252990722656,
           44.485042572021484,
           44.47683334350586,
           44.48009490966797,
           44.457435607910156,
           44.45365524291992,
           44.46845245361328,
           44.46799087524414,
           44.466007232666016,
           44.4781494140625,
           44.459571838378906,
           44.456050872802734,
           44.46592330932617,
           44.458011627197266,
           44.46179962158203,
           44.470394134521484,
           44.459938049316406,
           44.46452713012695,
           44.45902633666992,
           44.4791145324707,
           44.45613098144531,
           44.45726013183594,
           44.45923614501953,
           44.45310592651367,
           44.45511245727539,
           44.459259033203125,
           44.45370864868164,
           44.45509719848633,
           44.45636749267578,
           44.47010803222656,
           44.46831512451172,
           44.47211456298828,
           44.454322814941406,
           44.46133804321289,
           44.458003997802734,
           44.45726013183594,
           44.458580017089844,
           44.475894927978516,
           44.457420349121094,
           44.470951080322266,
           44.46664047241211,
           44.469024658203125,
           44.49466323852539,
           44.4610481262207,
           44.465553283691406,
           44.483097076416016,
           44.499183654785156,
           44.4619140625,
           44.47567367553711,
           44.47882080078125,
           44.52031707763672,
           44.49387741088867,
           44.458831787109375,
           44.46551513671875,
           44.45676803588867,
           44.462066650390625,
           44.47062683105469,
           44.48164749145508,
           44.48295211791992,
           44.453304290771484,
           44.472408294677734,
           44.4774284362793,
           44.470069885253906,
           44.47163772583008,
           44.479774475097656,
           44.46439743041992,
           44.46169662475586,
           44.45758056640625,
           44.4719352722168,
           44.46603775024414,
           44.45974349975586,
           44.47246170043945,
           44.45796585083008,
           44.4643440246582,
           44.4552116394043,
           44.46854019165039,
           44.454010009765625,
           44.45597457885742,
           44.470340728759766,
           44.451873779296875,
           44.460994720458984,
           44.45845031738281,
           44.455379486083984,
           44.45811080932617,
           44.467899322509766,
           44.45942687988281,
           44.467620849609375,
           44.45851135253906,
           44.46886444091797,
           44.46037292480469,
           44.48389434814453,
           44.47913360595703,
           44.46975326538086,
           44.46638107299805,
           44.46296691894531,
           44.47968673706055,
           44.47189712524414,
           44.452972412109375,
           44.45878601074219,
           44.464420318603516,
           44.472625732421875,
           44.46364974975586,
           44.456424713134766,
           44.468238830566406,
           44.491188049316406,
           44.469642639160156,
           44.49083709716797,
           44.45520782470703,
           44.47890090942383,
           44.4770622253418,
           44.456504821777344,
           44.4755859375,
           44.501304626464844,
           44.474571228027344,
           44.479190826416016,
           44.466712951660156,
           44.50187683105469,
           44.47992706298828,
           44.46318054199219,
           44.47468566894531,
           44.52558898925781,
           44.49091339111328,
           44.49889373779297,
           44.4555549621582,
           44.50189208984375,
           44.467647552490234,
           44.46717071533203,
           44.46482849121094,
           44.45301055908203,
           44.46311569213867,
           44.46736145019531,
           44.46073532104492,
           44.47358703613281,
           44.45817565917969,
           44.46430206298828,
           44.46905517578125,
           44.46912384033203,
           44.47324752807617,
           44.464813232421875,
           44.45658874511719,
           44.45273971557617,
           44.45805740356445,
           44.45769119262695,
           44.463443756103516,
           44.45258331298828,
           44.50053787231445,
           44.4662971496582,
           44.460628509521484,
           44.458316802978516,
           44.471397399902344,
           44.448936462402344,
           44.46051788330078,
           44.45522689819336,
           44.46403503417969,
           44.450836181640625,
           44.45841979980469,
           44.47300720214844,
           44.47236251831055,
           44.47687530517578,
           44.47112274169922,
           44.468448638916016,
           44.456783294677734,
           44.454246520996094,
           44.45634460449219,
           44.45235824584961,
           44.5213737487793,
           44.45114517211914,
           44.47806167602539,
           44.47171401977539,
           44.469871520996094,
           44.52111053466797,
           44.49044418334961,
           44.469520568847656,
           44.46150207519531,
           44.46957015991211,
           44.48723220825195,
           44.45680618286133,
           44.50107192993164,
           44.46479034423828,
           44.45454788208008,
           44.45464324951172,
           44.46870803833008,
           44.45484924316406,
           44.464996337890625,
           44.49036407470703,
           44.500614166259766,
           44.46107482910156,
           44.46428680419922,
           44.452003479003906,
           44.47626876831055,
           44.47427749633789,
           44.4641227722168,
           44.45961380004883,
           44.47426986694336,
           44.473907470703125,
           44.47185134887695,
           44.4871711730957,
           44.45691680908203,
           44.48035430908203,
           44.459205627441406,
           44.479652404785156,
           44.51636505126953,
           44.480674743652344,
           44.45381164550781,
           44.48318862915039,
           44.47337341308594,
           44.653114318847656,
           44.5252571105957,
           44.493568420410156,
           44.47834396362305,
           44.516326904296875,
           44.45972442626953,
           44.53959655761719,
           44.63603210449219,
           44.52858352661133,
           44.5345573425293,
           44.481781005859375,
           44.468414306640625,
           44.478633880615234,
           44.529197692871094,
           44.459415435791016,
           44.467987060546875,
           44.47868347167969,
           44.47230911254883,
           44.46543502807617,
           44.48751449584961,
           44.50346755981445,
           44.49439239501953,
           44.47637176513672,
           44.483272552490234,
           44.47245788574219,
           44.46897506713867,
           44.48383712768555,
           44.47185134887695,
           44.462364196777344,
           44.49943161010742,
           44.4864501953125,
           44.497589111328125,
           44.541168212890625,
           44.49714279174805,
           44.497066497802734,
           44.5002555847168,
           44.46633529663086,
           44.4891471862793,
           44.46929168701172,
           44.48979187011719,
           44.46433639526367,
           44.4605598449707,
           44.485416412353516,
           44.481170654296875,
           44.477745056152344,
           44.51015853881836,
           44.525184631347656,
           44.4882698059082,
           44.520668029785156,
           44.4625129699707,
           44.49863815307617,
           44.53398132324219,
           44.48576354980469,
           44.47486114501953,
           44.58869171142578,
           44.476436614990234,
           44.47438049316406,
           44.48881912231445,
           44.46364974975586,
           44.47565841674805,
           44.45543670654297,
           44.47895050048828,
           44.492427825927734,
           44.52268981933594,
           44.52922439575195,
           44.49488830566406,
           44.50149154663086,
           44.46839904785156,
           44.466217041015625,
           44.4707145690918,
           44.4576530456543,
           44.47901916503906,
           44.47323226928711,
           44.45686340332031,
           44.46497344970703,
           44.46965408325195,
           44.46073913574219,
           44.4738883972168,
           44.47512435913086,
           44.453643798828125,
           44.46925354003906,
           44.45798873901367,
           44.46054458618164,
           44.471282958984375,
           44.47283172607422,
           44.46296691894531,
           44.47255325317383,
           44.473304748535156,
           44.46599578857422,
           44.45584487915039,
           44.45625305175781,
           44.46097946166992,
           44.49595260620117,
           44.485958099365234,
           44.47410583496094,
           44.46609878540039,
           44.474422454833984,
           44.48869705200195,
           44.471168518066406,
           44.48019027709961,
           44.50881576538086,
           44.5202522277832,
           44.462947845458984,
           44.52745056152344,
           44.50712203979492,
           44.51211166381836,
           44.474945068359375,
           44.45734786987305,
           44.45581817626953,
           44.464542388916016,
           44.53303527832031,
           44.45615768432617,
           44.462562561035156,
           44.49502944946289,
           44.481201171875,
           44.473487854003906,
           44.525203704833984,
           44.47983169555664,
           44.47539138793945,
           44.49461364746094,
           44.471317291259766,
           44.46441650390625,
           44.455322265625,
           44.507667541503906,
           44.45283889770508,
           44.47398376464844,
           44.4698600769043,
           44.4554328918457,
           44.47112274169922,
           44.47662353515625,
           44.47509002685547,
           44.514320373535156,
           44.47422790527344,
           44.49272155761719,
           44.46599197387695,
           44.502010345458984,
           44.4861946105957,
           44.47639465332031,
           44.51999282836914,
           44.468910217285156,
           44.46892166137695,
           44.46684265136719,
           44.493160247802734,
           44.589088439941406,
           44.458621978759766,
           44.45224380493164,
           44.48896026611328,
           44.458274841308594,
           44.46320343017578,
           44.5013427734375,
           44.46860885620117,
           44.543479919433594,
           44.50298309326172,
           44.483158111572266,
           44.50505065917969,
           44.476173400878906,
           44.49147415161133,
           44.56716537475586,
           44.5301628112793,
           44.558807373046875,
           44.5097770690918,
           44.487091064453125,
           44.464599609375,
           44.48512268066406,
           44.46672058105469,
           44.47500228881836,
           44.49557876586914,
           44.54469299316406,
           44.470237731933594,
           44.545509338378906,
           44.4957160949707,
           44.76691818237305,
           44.518951416015625,
           44.47667694091797,
           44.48650360107422,
           44.45718002319336,
           44.488746643066406,
           44.46781921386719,
           44.47189712524414,
           44.46757507324219,
           44.48017120361328,
           44.46546936035156,
           44.482025146484375,
           44.45393371582031,
           44.54684829711914,
           44.50190734863281,
           44.463802337646484,
           44.53575897216797,
           44.48884201049805,
           44.56586837768555,
           44.473567962646484,
           44.46078872680664,
           44.47277069091797,
           44.57070541381836,
           44.45498275756836,
           44.460243225097656,
           44.48025131225586,
           44.488807678222656,
           44.48426818847656,
           44.46636199951172,
           44.46437072753906,
           44.49976348876953,
           44.546817779541016,
           44.517887115478516,
           44.488075256347656,
           44.45866012573242,
           44.4995231628418,
           44.507972717285156,
           44.48147964477539,
           44.481231689453125,
           44.47882843017578,
           44.45661926269531,
           44.459747314453125,
           44.45156478881836,
           44.47303009033203,
           44.501243591308594,
           44.47496032714844,
           44.51272964477539,
           44.48314666748047,
           44.49738693237305,
           44.46794128417969,
           44.473670959472656,
           44.459129333496094,
           44.498695373535156,
           44.45486831665039,
           44.451812744140625
          ],
          "coloraxis": "coloraxis",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813
         ],
         "xaxis": "x",
         "y": [
          18.336620330810547,
          17.694942474365234,
          17.795574188232422,
          17.755054473876953,
          17.967819213867188,
          18.177309036254883,
          17.562088012695312,
          17.789081573486328,
          17.65099334716797,
          18.421138763427734,
          18.13860321044922,
          18.222145080566406,
          18.065542221069336,
          17.95406150817871,
          17.891902923583984,
          17.733139038085938,
          17.262056350708008,
          17.19189453125,
          17.363069534301758,
          16.724546432495117,
          17.25326156616211,
          18.278804779052734,
          19.369251251220703,
          19.36037826538086,
          18.064146041870117,
          18.644256591796875,
          18.67110824584961,
          18.619901657104492,
          18.510047912597656,
          19.321208953857422,
          17.930465698242188,
          17.593997955322266,
          19.363109588623047,
          18.260250091552734,
          18.254146575927734,
          18.879804611206055,
          18.611469268798828,
          18.962310791015625,
          17.957324981689453,
          18.80128288269043,
          17.646760940551758,
          18.077213287353516,
          18.762928009033203,
          18.700002670288086,
          17.47397804260254,
          18.206663131713867,
          18.89911651611328,
          16.546995162963867,
          18.666109085083008,
          17.814722061157227,
          17.460071563720703,
          17.59758949279785,
          17.83399200439453,
          16.77459716796875,
          17.685977935791016,
          17.335927963256836,
          17.861297607421875,
          19.439964294433594,
          18.188983917236328,
          19.660930633544922,
          18.453256607055664,
          18.434255599975586,
          18.151180267333984,
          17.230575561523438,
          18.09364128112793,
          17.046119689941406,
          16.785663604736328,
          17.642608642578125,
          17.977222442626953,
          17.831825256347656,
          18.88279914855957,
          18.679250717163086,
          19.071392059326172,
          18.23604965209961,
          17.850902557373047,
          18.10343360900879,
          17.73264503479004,
          19.30821418762207,
          18.9150447845459,
          19.596546173095703,
          19.056076049804688,
          19.260944366455078,
          17.460094451904297,
          18.25765609741211,
          18.091533660888672,
          17.478055953979492,
          17.645092010498047,
          18.489015579223633,
          18.521265029907227,
          17.815465927124023,
          19.034883499145508,
          18.710750579833984,
          17.716690063476562,
          17.917810440063477,
          18.567760467529297,
          18.29084587097168,
          18.58755874633789,
          18.468891143798828,
          18.980098724365234,
          18.203632354736328,
          18.341686248779297,
          17.144678115844727,
          16.755996704101562,
          17.070064544677734,
          18.042530059814453,
          16.67086410522461,
          17.800125122070312,
          17.289691925048828,
          16.427032470703125,
          16.646953582763672,
          16.475505828857422,
          18.23624038696289,
          16.61919593811035,
          16.650217056274414,
          16.884716033935547,
          16.870311737060547,
          16.758787155151367,
          16.156770706176758,
          16.254257202148438,
          16.225669860839844,
          16.386892318725586,
          16.28274917602539,
          16.64020538330078,
          17.55434226989746,
          16.439647674560547,
          17.139902114868164,
          17.416088104248047,
          16.537681579589844,
          16.67456817626953,
          17.18012809753418,
          17.666828155517578,
          16.912960052490234,
          19.50668716430664,
          17.880903244018555,
          18.19656753540039,
          18.487661361694336,
          17.828453063964844,
          19.491640090942383,
          17.803691864013672,
          18.54762077331543,
          18.2905216217041,
          17.707815170288086,
          18.53000259399414,
          17.774051666259766,
          18.32614517211914,
          17.877965927124023,
          19.116979598999023,
          17.73853874206543,
          18.525691986083984,
          17.709396362304688,
          18.54651641845703,
          17.877391815185547,
          18.76744842529297,
          19.01291847229004,
          18.358184814453125,
          18.553775787353516,
          18.225093841552734,
          17.45298194885254,
          17.271839141845703,
          17.395610809326172,
          17.482450485229492,
          17.790451049804688,
          17.65634536743164,
          16.458974838256836,
          17.856643676757812,
          17.109859466552734,
          16.660030364990234,
          17.642929077148438,
          17.145496368408203,
          16.941118240356445,
          16.480554580688477,
          16.788219451904297,
          17.8000545501709,
          17.11517906188965,
          16.659130096435547,
          16.6313419342041,
          17.206897735595703,
          16.611446380615234,
          16.586929321289062,
          16.683670043945312,
          16.65974998474121,
          16.652973175048828,
          17.736696243286133,
          16.51052474975586,
          16.612102508544922,
          17.085676193237305,
          16.383560180664062,
          16.39707374572754,
          16.446060180664062,
          16.496782302856445,
          16.500551223754883,
          16.401290893554688,
          16.608722686767578,
          16.70415687561035,
          16.351444244384766,
          16.576038360595703,
          16.316450119018555,
          16.66676902770996,
          16.874507904052734,
          16.738224029541016,
          16.427824020385742,
          16.401697158813477,
          16.4676456451416,
          16.323627471923828,
          16.488239288330078,
          18.232189178466797,
          18.621477127075195,
          18.30694580078125,
          18.659177780151367,
          19.132923126220703,
          18.76809310913086,
          19.537189483642578,
          18.521947860717773,
          18.652034759521484,
          19.159305572509766,
          17.748830795288086,
          17.597566604614258,
          17.46380043029785,
          18.367841720581055,
          18.490325927734375,
          18.730091094970703,
          19.033710479736328,
          18.472522735595703,
          18.950992584228516,
          19.33096694946289,
          17.266433715820312,
          19.86333465576172,
          17.980487823486328,
          18.705705642700195,
          18.640729904174805,
          19.614063262939453,
          18.95794677734375,
          18.550533294677734,
          18.598148345947266,
          16.798114776611328,
          17.61872100830078,
          16.543563842773438,
          17.744298934936523,
          17.591753005981445,
          16.799427032470703,
          17.962299346923828,
          18.051952362060547,
          18.690399169921875,
          19.11187744140625,
          18.34170913696289,
          18.07896614074707,
          17.82558822631836,
          18.379558563232422,
          18.198026657104492,
          18.459423065185547,
          18.368555068969727,
          17.64801788330078,
          18.754947662353516,
          18.175395965576172,
          18.968189239501953,
          18.184036254882812,
          17.52198600769043,
          15.959159851074219,
          17.47022819519043,
          17.88132667541504,
          17.74264144897461,
          17.842044830322266,
          17.725894927978516,
          17.829044342041016,
          17.769840240478516,
          17.84845542907715,
          17.73722267150879,
          17.85455322265625,
          17.61011505126953,
          17.979286193847656,
          18.044143676757812,
          18.205364227294922,
          18.108869552612305,
          18.078134536743164,
          18.106103897094727,
          17.9273738861084,
          17.99081039428711,
          17.88668441772461,
          18.33664894104004,
          17.92151641845703,
          18.135303497314453,
          17.44373321533203,
          17.443103790283203,
          17.28666877746582,
          17.572040557861328,
          16.973690032958984,
          16.169010162353516,
          16.224714279174805,
          16.160749435424805,
          17.281930923461914,
          18.85869789123535,
          17.65619468688965,
          17.819732666015625,
          17.6640567779541,
          17.805511474609375,
          18.520883560180664,
          18.70466423034668,
          18.46457862854004,
          18.56012535095215,
          18.168310165405273,
          18.380722045898438,
          17.987361907958984,
          18.020263671875,
          17.677579879760742,
          17.58932876586914,
          17.810344696044922,
          17.66101837158203,
          18.34856414794922,
          18.688858032226562,
          18.40506362915039,
          19.098079681396484,
          17.28829574584961,
          18.240995407104492,
          18.1416072845459,
          17.384002685546875,
          18.231103897094727,
          19.005231857299805,
          17.838735580444336,
          18.60013198852539,
          17.832433700561523,
          18.822011947631836,
          18.127840042114258,
          18.465473175048828,
          18.557632446289062,
          19.62204360961914,
          18.05617332458496,
          18.00941276550293,
          16.98884391784668,
          17.07259178161621,
          17.22634506225586,
          16.48468017578125,
          17.02889060974121,
          16.697277069091797,
          18.832874298095703,
          17.742000579833984,
          19.52672004699707,
          18.186723709106445,
          16.02021598815918,
          17.094890594482422,
          17.411630630493164,
          17.026941299438477,
          17.098398208618164,
          16.40319061279297,
          17.877635955810547,
          18.978256225585938,
          19.3422794342041,
          18.207639694213867,
          18.710012435913086,
          18.8819580078125,
          18.125267028808594,
          16.85226058959961,
          17.8778133392334,
          17.1427059173584,
          17.667827606201172,
          17.155860900878906,
          17.83091163635254,
          17.640729904174805,
          18.63743782043457,
          17.780658721923828,
          17.718381881713867,
          18.045833587646484,
          17.7213077545166,
          18.875905990600586,
          18.828357696533203,
          18.68284797668457,
          17.96891975402832,
          17.590003967285156,
          18.935033798217773,
          18.32594871520996,
          18.807846069335938,
          18.738006591796875,
          17.871505737304688,
          17.88632583618164,
          15.97661018371582,
          18.35006332397461,
          18.18184471130371,
          18.60601806640625,
          19.386123657226562,
          18.371532440185547,
          19.112037658691406,
          18.79806137084961,
          18.681621551513672,
          19.074195861816406,
          18.365140914916992,
          17.93204116821289,
          17.08185386657715,
          16.172348022460938,
          16.19860076904297,
          16.19065284729004,
          16.122377395629883,
          16.226261138916016,
          16.186145782470703,
          16.186647415161133,
          16.187503814697266,
          16.192684173583984,
          16.162464141845703,
          16.234766006469727,
          16.207027435302734,
          16.16258430480957,
          16.14791488647461,
          16.222774505615234,
          16.474477767944336,
          16.29513168334961,
          16.112598419189453,
          16.216400146484375,
          16.292165756225586,
          16.131824493408203,
          16.186006546020508,
          16.209482192993164,
          17.01097297668457,
          16.203033447265625,
          16.1851863861084,
          16.48219871520996,
          16.191545486450195,
          16.176441192626953,
          16.444326400756836,
          16.177082061767578,
          16.185155868530273,
          16.42513656616211,
          16.251482009887695,
          16.186986923217773,
          18.709293365478516,
          17.369136810302734,
          19.479740142822266,
          19.440921783447266,
          20.23019027709961,
          16.644784927368164,
          19.131702423095703,
          17.552570343017578,
          18.516544342041016,
          18.243148803710938,
          18.981618881225586,
          19.323942184448242,
          18.85006332397461,
          17.344074249267578,
          18.60475730895996,
          16.90152359008789,
          18.168811798095703,
          16.359683990478516,
          18.586851119995117,
          18.61412239074707,
          17.432109832763672,
          16.993677139282227,
          18.131439208984375,
          16.218618392944336,
          16.233028411865234,
          16.31158447265625,
          16.212623596191406,
          16.154682159423828,
          16.25351333618164,
          16.216026306152344,
          16.086868286132812,
          16.198680877685547,
          17.66390609741211,
          16.664947509765625,
          16.222885131835938,
          16.170217514038086,
          16.54036521911621,
          16.276691436767578,
          17.006832122802734,
          17.15121078491211,
          16.21013641357422,
          16.698673248291016,
          16.5440731048584,
          16.5279598236084,
          16.2327823638916,
          16.67587661743164,
          16.335405349731445,
          16.380414962768555,
          16.267044067382812,
          16.302995681762695,
          16.15517234802246,
          17.62277603149414,
          17.031200408935547,
          16.59332275390625,
          16.247760772705078,
          16.664779663085938,
          16.09249496459961,
          16.226709365844727,
          16.211544036865234,
          16.254764556884766,
          16.209617614746094,
          16.20610237121582,
          16.24087142944336,
          16.226293563842773,
          17.093090057373047,
          18.515352249145508,
          19.6147403717041,
          19.12413215637207,
          18.899389266967773,
          19.310325622558594,
          18.51349449157715,
          18.165634155273438,
          18.212112426757812,
          17.271190643310547,
          18.898029327392578,
          18.849376678466797,
          18.063451766967773,
          19.310989379882812,
          18.524456024169922,
          18.717479705810547,
          18.055885314941406,
          18.53664779663086,
          18.29806137084961,
          17.995162963867188,
          19.02985954284668,
          17.06104850769043,
          17.232677459716797,
          17.802881240844727,
          16.507183074951172,
          16.247295379638672,
          16.54855728149414,
          16.139678955078125,
          16.19995880126953,
          16.168193817138672,
          16.239330291748047,
          16.279369354248047,
          16.13300323486328,
          16.142274856567383,
          16.22743034362793,
          16.250652313232422,
          16.236467361450195,
          16.15155029296875,
          16.267541885375977,
          16.195363998413086,
          16.2254581451416,
          16.158838272094727,
          17.087814331054688,
          16.26466941833496,
          16.13051414489746,
          16.25223731994629,
          16.136859893798828,
          16.136249542236328,
          16.211217880249023,
          16.205425262451172,
          16.208446502685547,
          16.171369552612305,
          16.26792335510254,
          16.235557556152344,
          16.16501235961914,
          16.177265167236328,
          16.17334747314453,
          16.215370178222656,
          16.167110443115234,
          16.229888916015625,
          16.218008041381836,
          16.03998565673828,
          18.152584075927734,
          17.839433670043945,
          17.782005310058594,
          18.444087982177734,
          19.30685043334961,
          19.191360473632812,
          18.681676864624023,
          18.55073356628418,
          17.490917205810547,
          16.63445472717285,
          18.81430435180664,
          19.061683654785156,
          17.9329891204834,
          16.58209991455078,
          16.536476135253906,
          16.20611000061035,
          16.268043518066406,
          16.237350463867188,
          16.16179084777832,
          17.84259605407715,
          17.740211486816406,
          16.140480041503906,
          16.185176849365234,
          16.248676300048828,
          16.197900772094727,
          16.211864471435547,
          16.179744720458984,
          16.25135612487793,
          16.70322036743164,
          16.638660430908203,
          16.740985870361328,
          17.256074905395508,
          17.972795486450195,
          18.572097778320312,
          17.690401077270508,
          17.433429718017578,
          17.52531623840332,
          18.607467651367188,
          17.106807708740234,
          17.76976776123047,
          18.311288833618164,
          18.43471336364746,
          18.86301040649414,
          19.273591995239258,
          18.835609436035156,
          18.620887756347656,
          18.64688491821289,
          18.681713104248047,
          17.99753189086914,
          17.89382553100586,
          19.407665252685547,
          19.502866744995117,
          19.05152702331543,
          19.204090118408203,
          17.687461853027344,
          19.05506134033203,
          18.60511589050293,
          16.531566619873047,
          19.45646095275879,
          17.420896530151367,
          19.585033416748047,
          18.049915313720703,
          18.600326538085938,
          16.99030876159668,
          18.02843475341797,
          18.56389617919922,
          17.885143280029297,
          17.32339096069336,
          18.77604103088379,
          18.514842987060547,
          18.34270477294922,
          18.504989624023438,
          16.49894142150879,
          19.040771484375,
          18.037357330322266,
          18.55061149597168,
          18.491857528686523,
          18.93642807006836,
          19.581308364868164,
          16.408355712890625,
          18.582202911376953,
          18.02508544921875,
          18.8587646484375,
          17.164867401123047,
          16.42839813232422,
          17.205936431884766,
          18.174535751342773,
          16.163366317749023,
          18.772354125976562,
          18.23238182067871,
          19.451335906982422,
          18.462568283081055,
          18.44027328491211,
          18.788856506347656,
          18.06437873840332,
          17.20357894897461,
          17.81649398803711,
          18.435001373291016,
          17.631450653076172,
          18.980215072631836,
          19.525238037109375,
          19.626590728759766,
          18.30673599243164,
          19.54834747314453,
          18.223819732666016,
          18.355247497558594,
          19.088376998901367,
          18.508129119873047,
          19.24837875366211,
          16.581623077392578,
          16.290782928466797,
          16.348222732543945,
          16.14415740966797,
          16.08338737487793,
          17.09133529663086,
          16.471023559570312,
          16.212055206298828,
          16.460346221923828,
          16.22867202758789,
          16.584104537963867,
          16.196353912353516,
          16.555137634277344,
          16.423311233520508,
          16.42871856689453,
          16.19255828857422,
          16.16036605834961,
          16.210830688476562,
          16.250463485717773,
          16.190670013427734,
          16.12028694152832,
          16.143268585205078,
          16.35761833190918,
          16.125154495239258,
          17.909225463867188,
          16.995954513549805,
          16.913850784301758,
          17.672183990478516,
          16.63204574584961,
          17.792539596557617,
          19.282785415649414,
          18.45291519165039,
          19.683032989501953,
          18.32473373413086,
          20.639476776123047,
          18.885744094848633,
          18.324506759643555,
          19.453603744506836,
          19.55855941772461,
          19.354167938232422,
          17.85172462463379,
          17.327083587646484,
          17.715869903564453,
          17.21920394897461,
          18.005069732666016,
          18.105213165283203,
          17.55000114440918,
          17.976964950561523,
          18.817760467529297,
          17.275806427001953,
          16.21401596069336,
          17.471982955932617,
          16.38631248474121,
          16.526113510131836,
          18.115049362182617,
          16.718164443969727,
          16.292369842529297,
          16.15585708618164,
          16.99810028076172,
          17.245559692382812,
          19.262516021728516,
          16.42874526977539,
          17.501602172851562,
          17.34054183959961,
          18.253328323364258,
          17.715009689331055,
          17.62921142578125,
          19.773571014404297,
          18.596593856811523,
          18.940305709838867,
          18.070068359375,
          17.005556106567383,
          18.654624938964844,
          17.087236404418945,
          16.11705780029297,
          16.037931442260742,
          16.119150161743164,
          16.60759162902832,
          17.358549118041992,
          16.86636734008789,
          16.645893096923828,
          18.53099250793457,
          18.014047622680664,
          18.28476905822754,
          19.00014305114746,
          19.284626007080078,
          18.849567413330078,
          19.06951904296875,
          18.264530181884766,
          18.72339630126953,
          18.955493927001953,
          17.819046020507812,
          18.129934310913086,
          18.810264587402344,
          19.83678436279297,
          18.249591827392578,
          19.650365829467773,
          18.705215454101562,
          19.142873764038086,
          18.857942581176758,
          20.026647567749023,
          18.356962203979492,
          19.998886108398438,
          18.85348129272461,
          19.141422271728516,
          18.85740089416504,
          18.87550926208496,
          17.564205169677734,
          17.541645050048828,
          16.481826782226562,
          17.077192306518555,
          17.94755744934082,
          18.86252784729004,
          17.048795700073242,
          18.08436393737793,
          17.719030380249023,
          18.462614059448242,
          18.37413215637207,
          17.38930320739746,
          15.99901294708252,
          17.685993194580078,
          17.27084732055664,
          16.222835540771484,
          16.537107467651367,
          16.415699005126953,
          17.26787757873535,
          16.299072265625,
          16.42059326171875,
          16.62359619140625,
          16.539836883544922,
          16.561336517333984,
          16.355037689208984,
          16.737804412841797,
          18.071779251098633,
          16.6644229888916,
          17.75604820251465,
          17.619853973388672,
          16.28805160522461,
          16.2833309173584,
          17.191646575927734,
          17.030254364013672,
          17.873699188232422,
          17.324140548706055,
          16.38462257385254,
          16.386308670043945,
          16.2495059967041,
          16.455867767333984,
          18.456100463867188,
          18.282493591308594,
          17.331802368164062,
          16.619577407836914,
          16.778112411499023,
          17.252477645874023,
          16.835308074951172,
          16.727785110473633,
          16.681747436523438,
          17.120946884155273,
          16.581010818481445
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Uncertainty"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Epistemic Uncertainty Distribution for CONFF"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Samples"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Final RR Output (BrPM)"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"4b7500f0-e50b-4515-9886-2cc1cb1e27fe\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4b7500f0-e50b-4515-9886-2cc1cb1e27fe\")) {                    Plotly.newPlot(                        \"4b7500f0-e50b-4515-9886-2cc1cb1e27fe\",                        [{\"hovertemplate\":\"Samples=%{x}<br>Final RR Output (BrPM)=%{y}<br>Uncertainty=%{marker.color}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":[44.46677780151367,44.48190689086914,44.493228912353516,44.464759826660156,44.47869110107422,44.48808670043945,44.45536804199219,44.452823638916016,44.47793960571289,44.46826934814453,44.46737289428711,44.45511245727539,44.474124908447266,44.470458984375,44.47135543823242,44.50764083862305,44.51530075073242,44.48397445678711,44.473411560058594,44.455387115478516,44.48299026489258,44.46820068359375,44.46551513671875,44.493507385253906,44.51985168457031,44.48424530029297,44.484439849853516,44.47222900390625,44.50489807128906,44.47018051147461,44.532203674316406,44.51932907104492,44.48004150390625,44.49953079223633,44.45798110961914,44.4657096862793,44.46287536621094,44.499053955078125,44.55548858642578,44.472557067871094,44.46790313720703,44.54537582397461,44.470577239990234,44.45614242553711,44.46287536621094,44.477657318115234,44.45863342285156,44.469940185546875,44.45845031738281,44.48273468017578,44.47230911254883,44.49484634399414,44.47888946533203,44.46012878417969,44.473262786865234,44.498374938964844,44.578277587890625,44.453102111816406,44.47730255126953,44.51901626586914,44.492977142333984,44.502201080322266,44.45880126953125,44.477176666259766,44.50088882446289,44.47437286376953,44.46841049194336,44.47426986694336,44.46412658691406,44.47552490234375,44.466304779052734,44.493629455566406,44.48166275024414,44.48377990722656,44.46281051635742,44.460899353027344,44.5211067199707,44.497947692871094,44.47962188720703,44.48185729980469,44.483482360839844,44.482547760009766,44.45383834838867,44.48053741455078,44.4732551574707,44.47439193725586,44.682003021240234,44.56922149658203,44.4960823059082,44.47026062011719,44.544532775878906,44.5091667175293,44.4594612121582,44.51389694213867,44.51649475097656,44.509307861328125,44.48369598388672,44.465030670166016,44.50604248046875,44.4663200378418,44.48111343383789,44.46260070800781,44.44886779785156,44.455360412597656,44.457984924316406,44.45315170288086,44.45435333251953,44.45286178588867,44.47314453125,44.451751708984375,44.46822738647461,44.451663970947266,44.45906066894531,44.4574089050293,44.459510803222656,44.456790924072266,44.45960235595703,44.453834533691406,44.46510696411133,44.46086120605469,44.473628997802734,44.46348190307617,44.469825744628906,44.458229064941406,44.46269989013672,44.47064208984375,44.47301483154297,44.45863342285156,44.491756439208984,44.482601165771484,44.49220275878906,44.46697235107422,44.47736358642578,44.503665924072266,44.51458740234375,44.486995697021484,44.473575592041016,44.665618896484375,44.5229606628418,44.47642135620117,44.48150634765625,44.4936408996582,44.48415756225586,44.45913314819336,44.46843338012695,44.45634841918945,44.48126983642578,44.52056884765625,44.495887756347656,44.46376419067383,44.47751235961914,44.48835754394531,44.49551010131836,44.513736724853516,44.47740936279297,44.500064849853516,44.45948791503906,44.487003326416016,44.46255111694336,44.447025299072266,44.46870422363281,44.53411865234375,44.46356964111328,44.461788177490234,44.463623046875,44.45442581176758,44.50010681152344,44.47275161743164,44.483245849609375,44.459686279296875,44.47657775878906,44.47993087768555,44.46692657470703,44.45956802368164,44.48954772949219,44.46900177001953,44.47551727294922,44.47327423095703,44.453895568847656,44.45616912841797,44.469364166259766,44.46066665649414,44.46680450439453,44.46603775024414,44.46079635620117,44.49285125732422,44.451683044433594,44.450775146484375,44.46137619018555,44.47611999511719,44.46807861328125,44.47224807739258,44.47694778442383,44.454532623291016,44.47696304321289,44.46227264404297,44.4527473449707,44.47208786010742,44.45792007446289,44.461219787597656,44.455562591552734,44.459983825683594,44.454227447509766,44.46550369262695,44.45975112915039,44.504249572753906,44.486820220947266,44.454769134521484,44.516510009765625,44.522979736328125,44.48513412475586,44.54097366333008,44.59313201904297,44.538429260253906,44.6655387878418,44.51995849609375,44.68891143798828,44.4721565246582,44.47254943847656,44.502864837646484,44.51723861694336,44.491668701171875,44.55946350097656,44.47168731689453,44.589481353759766,44.63154602050781,44.46895217895508,44.48731231689453,44.48401641845703,44.479949951171875,44.47819137573242,44.4559440612793,44.48551559448242,44.50880813598633,44.49491882324219,44.50886917114258,44.46131896972656,44.46696853637695,44.47116470336914,44.4715461730957,44.4576301574707,44.464935302734375,44.582740783691406,44.47835922241211,44.49962615966797,44.51601028442383,44.47718048095703,44.52570343017578,44.54373550415039,44.49314498901367,44.49758529663086,44.519649505615234,44.4730339050293,44.566200256347656,44.550537109375,44.46723175048828,44.45498275756836,44.50216293334961,44.492881774902344,44.479915618896484,44.48945236206055,44.509822845458984,44.530540466308594,44.5230827331543,44.64372253417969,44.50553894042969,44.50131607055664,44.47846984863281,44.58293151855469,44.5180778503418,44.577796936035156,44.48908615112305,44.52588653564453,44.5013542175293,44.505672454833984,44.472843170166016,44.516639709472656,44.497562408447266,44.49275207519531,44.586673736572266,44.463558197021484,44.467464447021484,44.47265625,44.454307556152344,44.46720886230469,44.47762680053711,44.458255767822266,44.461029052734375,44.474796295166016,44.486045837402344,44.550689697265625,44.46165084838867,44.460906982421875,44.47927474975586,44.461544036865234,44.48359680175781,44.491573333740234,44.50713348388672,44.4700813293457,44.54132080078125,44.54810333251953,44.476436614990234,44.46577072143555,44.505863189697266,44.46952819824219,44.49451446533203,44.470462799072266,44.480812072753906,44.483543395996094,44.47829055786133,44.51334762573242,44.46475601196289,44.484012603759766,44.47214126586914,44.46743392944336,44.47031021118164,44.4833984375,44.51875305175781,44.473148345947266,44.49821090698242,44.47553634643555,44.46737289428711,44.471065521240234,44.48619842529297,44.49251174926758,44.54160690307617,44.45980453491211,44.47376251220703,44.466957092285156,44.46928787231445,44.49231719970703,44.47693634033203,44.454769134521484,44.47694396972656,44.473243713378906,44.461334228515625,44.489501953125,44.46492004394531,44.58440017700195,44.55337905883789,44.455257415771484,44.45771408081055,44.47077941894531,44.47191619873047,44.50017166137695,44.453895568847656,44.47478103637695,44.47821044921875,44.493221282958984,44.45444107055664,44.483760833740234,44.479827880859375,44.474578857421875,44.473663330078125,44.47029495239258,44.48133087158203,44.50408935546875,44.45791244506836,44.47245788574219,44.49342727661133,44.48833465576172,44.48212814331055,44.464881896972656,44.46226119995117,44.47526168823242,44.46308898925781,44.52838134765625,44.52794647216797,44.55164337158203,44.45690155029297,44.45659637451172,44.47050476074219,44.47097396850586,44.4569206237793,44.465858459472656,44.51057052612305,44.50346374511719,44.464942932128906,44.48413848876953,44.48689651489258,44.480377197265625,44.482574462890625,44.470252990722656,44.485042572021484,44.47683334350586,44.48009490966797,44.457435607910156,44.45365524291992,44.46845245361328,44.46799087524414,44.466007232666016,44.4781494140625,44.459571838378906,44.456050872802734,44.46592330932617,44.458011627197266,44.46179962158203,44.470394134521484,44.459938049316406,44.46452713012695,44.45902633666992,44.4791145324707,44.45613098144531,44.45726013183594,44.45923614501953,44.45310592651367,44.45511245727539,44.459259033203125,44.45370864868164,44.45509719848633,44.45636749267578,44.47010803222656,44.46831512451172,44.47211456298828,44.454322814941406,44.46133804321289,44.458003997802734,44.45726013183594,44.458580017089844,44.475894927978516,44.457420349121094,44.470951080322266,44.46664047241211,44.469024658203125,44.49466323852539,44.4610481262207,44.465553283691406,44.483097076416016,44.499183654785156,44.4619140625,44.47567367553711,44.47882080078125,44.52031707763672,44.49387741088867,44.458831787109375,44.46551513671875,44.45676803588867,44.462066650390625,44.47062683105469,44.48164749145508,44.48295211791992,44.453304290771484,44.472408294677734,44.4774284362793,44.470069885253906,44.47163772583008,44.479774475097656,44.46439743041992,44.46169662475586,44.45758056640625,44.4719352722168,44.46603775024414,44.45974349975586,44.47246170043945,44.45796585083008,44.4643440246582,44.4552116394043,44.46854019165039,44.454010009765625,44.45597457885742,44.470340728759766,44.451873779296875,44.460994720458984,44.45845031738281,44.455379486083984,44.45811080932617,44.467899322509766,44.45942687988281,44.467620849609375,44.45851135253906,44.46886444091797,44.46037292480469,44.48389434814453,44.47913360595703,44.46975326538086,44.46638107299805,44.46296691894531,44.47968673706055,44.47189712524414,44.452972412109375,44.45878601074219,44.464420318603516,44.472625732421875,44.46364974975586,44.456424713134766,44.468238830566406,44.491188049316406,44.469642639160156,44.49083709716797,44.45520782470703,44.47890090942383,44.4770622253418,44.456504821777344,44.4755859375,44.501304626464844,44.474571228027344,44.479190826416016,44.466712951660156,44.50187683105469,44.47992706298828,44.46318054199219,44.47468566894531,44.52558898925781,44.49091339111328,44.49889373779297,44.4555549621582,44.50189208984375,44.467647552490234,44.46717071533203,44.46482849121094,44.45301055908203,44.46311569213867,44.46736145019531,44.46073532104492,44.47358703613281,44.45817565917969,44.46430206298828,44.46905517578125,44.46912384033203,44.47324752807617,44.464813232421875,44.45658874511719,44.45273971557617,44.45805740356445,44.45769119262695,44.463443756103516,44.45258331298828,44.50053787231445,44.4662971496582,44.460628509521484,44.458316802978516,44.471397399902344,44.448936462402344,44.46051788330078,44.45522689819336,44.46403503417969,44.450836181640625,44.45841979980469,44.47300720214844,44.47236251831055,44.47687530517578,44.47112274169922,44.468448638916016,44.456783294677734,44.454246520996094,44.45634460449219,44.45235824584961,44.5213737487793,44.45114517211914,44.47806167602539,44.47171401977539,44.469871520996094,44.52111053466797,44.49044418334961,44.469520568847656,44.46150207519531,44.46957015991211,44.48723220825195,44.45680618286133,44.50107192993164,44.46479034423828,44.45454788208008,44.45464324951172,44.46870803833008,44.45484924316406,44.464996337890625,44.49036407470703,44.500614166259766,44.46107482910156,44.46428680419922,44.452003479003906,44.47626876831055,44.47427749633789,44.4641227722168,44.45961380004883,44.47426986694336,44.473907470703125,44.47185134887695,44.4871711730957,44.45691680908203,44.48035430908203,44.459205627441406,44.479652404785156,44.51636505126953,44.480674743652344,44.45381164550781,44.48318862915039,44.47337341308594,44.653114318847656,44.5252571105957,44.493568420410156,44.47834396362305,44.516326904296875,44.45972442626953,44.53959655761719,44.63603210449219,44.52858352661133,44.5345573425293,44.481781005859375,44.468414306640625,44.478633880615234,44.529197692871094,44.459415435791016,44.467987060546875,44.47868347167969,44.47230911254883,44.46543502807617,44.48751449584961,44.50346755981445,44.49439239501953,44.47637176513672,44.483272552490234,44.47245788574219,44.46897506713867,44.48383712768555,44.47185134887695,44.462364196777344,44.49943161010742,44.4864501953125,44.497589111328125,44.541168212890625,44.49714279174805,44.497066497802734,44.5002555847168,44.46633529663086,44.4891471862793,44.46929168701172,44.48979187011719,44.46433639526367,44.4605598449707,44.485416412353516,44.481170654296875,44.477745056152344,44.51015853881836,44.525184631347656,44.4882698059082,44.520668029785156,44.4625129699707,44.49863815307617,44.53398132324219,44.48576354980469,44.47486114501953,44.58869171142578,44.476436614990234,44.47438049316406,44.48881912231445,44.46364974975586,44.47565841674805,44.45543670654297,44.47895050048828,44.492427825927734,44.52268981933594,44.52922439575195,44.49488830566406,44.50149154663086,44.46839904785156,44.466217041015625,44.4707145690918,44.4576530456543,44.47901916503906,44.47323226928711,44.45686340332031,44.46497344970703,44.46965408325195,44.46073913574219,44.4738883972168,44.47512435913086,44.453643798828125,44.46925354003906,44.45798873901367,44.46054458618164,44.471282958984375,44.47283172607422,44.46296691894531,44.47255325317383,44.473304748535156,44.46599578857422,44.45584487915039,44.45625305175781,44.46097946166992,44.49595260620117,44.485958099365234,44.47410583496094,44.46609878540039,44.474422454833984,44.48869705200195,44.471168518066406,44.48019027709961,44.50881576538086,44.5202522277832,44.462947845458984,44.52745056152344,44.50712203979492,44.51211166381836,44.474945068359375,44.45734786987305,44.45581817626953,44.464542388916016,44.53303527832031,44.45615768432617,44.462562561035156,44.49502944946289,44.481201171875,44.473487854003906,44.525203704833984,44.47983169555664,44.47539138793945,44.49461364746094,44.471317291259766,44.46441650390625,44.455322265625,44.507667541503906,44.45283889770508,44.47398376464844,44.4698600769043,44.4554328918457,44.47112274169922,44.47662353515625,44.47509002685547,44.514320373535156,44.47422790527344,44.49272155761719,44.46599197387695,44.502010345458984,44.4861946105957,44.47639465332031,44.51999282836914,44.468910217285156,44.46892166137695,44.46684265136719,44.493160247802734,44.589088439941406,44.458621978759766,44.45224380493164,44.48896026611328,44.458274841308594,44.46320343017578,44.5013427734375,44.46860885620117,44.543479919433594,44.50298309326172,44.483158111572266,44.50505065917969,44.476173400878906,44.49147415161133,44.56716537475586,44.5301628112793,44.558807373046875,44.5097770690918,44.487091064453125,44.464599609375,44.48512268066406,44.46672058105469,44.47500228881836,44.49557876586914,44.54469299316406,44.470237731933594,44.545509338378906,44.4957160949707,44.76691818237305,44.518951416015625,44.47667694091797,44.48650360107422,44.45718002319336,44.488746643066406,44.46781921386719,44.47189712524414,44.46757507324219,44.48017120361328,44.46546936035156,44.482025146484375,44.45393371582031,44.54684829711914,44.50190734863281,44.463802337646484,44.53575897216797,44.48884201049805,44.56586837768555,44.473567962646484,44.46078872680664,44.47277069091797,44.57070541381836,44.45498275756836,44.460243225097656,44.48025131225586,44.488807678222656,44.48426818847656,44.46636199951172,44.46437072753906,44.49976348876953,44.546817779541016,44.517887115478516,44.488075256347656,44.45866012573242,44.4995231628418,44.507972717285156,44.48147964477539,44.481231689453125,44.47882843017578,44.45661926269531,44.459747314453125,44.45156478881836,44.47303009033203,44.501243591308594,44.47496032714844,44.51272964477539,44.48314666748047,44.49738693237305,44.46794128417969,44.473670959472656,44.459129333496094,44.498695373535156,44.45486831665039,44.451812744140625],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"type\":\"scatter\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0,51.0,52.0,53.0,54.0,55.0,56.0,57.0,58.0,59.0,60.0,61.0,62.0,63.0,64.0,65.0,66.0,67.0,68.0,69.0,70.0,71.0,72.0,73.0,74.0,75.0,76.0,77.0,78.0,79.0,80.0,81.0,82.0,83.0,84.0,85.0,86.0,87.0,88.0,89.0,90.0,91.0,92.0,93.0,94.0,95.0,96.0,97.0,98.0,99.0,100.0,101.0,102.0,103.0,104.0,105.0,106.0,107.0,108.0,109.0,110.0,111.0,112.0,113.0,114.0,115.0,116.0,117.0,118.0,119.0,120.0,121.0,122.0,123.0,124.0,125.0,126.0,127.0,128.0,129.0,130.0,131.0,132.0,133.0,134.0,135.0,136.0,137.0,138.0,139.0,140.0,141.0,142.0,143.0,144.0,145.0,146.0,147.0,148.0,149.0,150.0,151.0,152.0,153.0,154.0,155.0,156.0,157.0,158.0,159.0,160.0,161.0,162.0,163.0,164.0,165.0,166.0,167.0,168.0,169.0,170.0,171.0,172.0,173.0,174.0,175.0,176.0,177.0,178.0,179.0,180.0,181.0,182.0,183.0,184.0,185.0,186.0,187.0,188.0,189.0,190.0,191.0,192.0,193.0,194.0,195.0,196.0,197.0,198.0,199.0,200.0,201.0,202.0,203.0,204.0,205.0,206.0,207.0,208.0,209.0,210.0,211.0,212.0,213.0,214.0,215.0,216.0,217.0,218.0,219.0,220.0,221.0,222.0,223.0,224.0,225.0,226.0,227.0,228.0,229.0,230.0,231.0,232.0,233.0,234.0,235.0,236.0,237.0,238.0,239.0,240.0,241.0,242.0,243.0,244.0,245.0,246.0,247.0,248.0,249.0,250.0,251.0,252.0,253.0,254.0,255.0,256.0,257.0,258.0,259.0,260.0,261.0,262.0,263.0,264.0,265.0,266.0,267.0,268.0,269.0,270.0,271.0,272.0,273.0,274.0,275.0,276.0,277.0,278.0,279.0,280.0,281.0,282.0,283.0,284.0,285.0,286.0,287.0,288.0,289.0,290.0,291.0,292.0,293.0,294.0,295.0,296.0,297.0,298.0,299.0,300.0,301.0,302.0,303.0,304.0,305.0,306.0,307.0,308.0,309.0,310.0,311.0,312.0,313.0,314.0,315.0,316.0,317.0,318.0,319.0,320.0,321.0,322.0,323.0,324.0,325.0,326.0,327.0,328.0,329.0,330.0,331.0,332.0,333.0,334.0,335.0,336.0,337.0,338.0,339.0,340.0,341.0,342.0,343.0,344.0,345.0,346.0,347.0,348.0,349.0,350.0,351.0,352.0,353.0,354.0,355.0,356.0,357.0,358.0,359.0,360.0,361.0,362.0,363.0,364.0,365.0,366.0,367.0,368.0,369.0,370.0,371.0,372.0,373.0,374.0,375.0,376.0,377.0,378.0,379.0,380.0,381.0,382.0,383.0,384.0,385.0,386.0,387.0,388.0,389.0,390.0,391.0,392.0,393.0,394.0,395.0,396.0,397.0,398.0,399.0,400.0,401.0,402.0,403.0,404.0,405.0,406.0,407.0,408.0,409.0,410.0,411.0,412.0,413.0,414.0,415.0,416.0,417.0,418.0,419.0,420.0,421.0,422.0,423.0,424.0,425.0,426.0,427.0,428.0,429.0,430.0,431.0,432.0,433.0,434.0,435.0,436.0,437.0,438.0,439.0,440.0,441.0,442.0,443.0,444.0,445.0,446.0,447.0,448.0,449.0,450.0,451.0,452.0,453.0,454.0,455.0,456.0,457.0,458.0,459.0,460.0,461.0,462.0,463.0,464.0,465.0,466.0,467.0,468.0,469.0,470.0,471.0,472.0,473.0,474.0,475.0,476.0,477.0,478.0,479.0,480.0,481.0,482.0,483.0,484.0,485.0,486.0,487.0,488.0,489.0,490.0,491.0,492.0,493.0,494.0,495.0,496.0,497.0,498.0,499.0,500.0,501.0,502.0,503.0,504.0,505.0,506.0,507.0,508.0,509.0,510.0,511.0,512.0,513.0,514.0,515.0,516.0,517.0,518.0,519.0,520.0,521.0,522.0,523.0,524.0,525.0,526.0,527.0,528.0,529.0,530.0,531.0,532.0,533.0,534.0,535.0,536.0,537.0,538.0,539.0,540.0,541.0,542.0,543.0,544.0,545.0,546.0,547.0,548.0,549.0,550.0,551.0,552.0,553.0,554.0,555.0,556.0,557.0,558.0,559.0,560.0,561.0,562.0,563.0,564.0,565.0,566.0,567.0,568.0,569.0,570.0,571.0,572.0,573.0,574.0,575.0,576.0,577.0,578.0,579.0,580.0,581.0,582.0,583.0,584.0,585.0,586.0,587.0,588.0,589.0,590.0,591.0,592.0,593.0,594.0,595.0,596.0,597.0,598.0,599.0,600.0,601.0,602.0,603.0,604.0,605.0,606.0,607.0,608.0,609.0,610.0,611.0,612.0,613.0,614.0,615.0,616.0,617.0,618.0,619.0,620.0,621.0,622.0,623.0,624.0,625.0,626.0,627.0,628.0,629.0,630.0,631.0,632.0,633.0,634.0,635.0,636.0,637.0,638.0,639.0,640.0,641.0,642.0,643.0,644.0,645.0,646.0,647.0,648.0,649.0,650.0,651.0,652.0,653.0,654.0,655.0,656.0,657.0,658.0,659.0,660.0,661.0,662.0,663.0,664.0,665.0,666.0,667.0,668.0,669.0,670.0,671.0,672.0,673.0,674.0,675.0,676.0,677.0,678.0,679.0,680.0,681.0,682.0,683.0,684.0,685.0,686.0,687.0,688.0,689.0,690.0,691.0,692.0,693.0,694.0,695.0,696.0,697.0,698.0,699.0,700.0,701.0,702.0,703.0,704.0,705.0,706.0,707.0,708.0,709.0,710.0,711.0,712.0,713.0,714.0,715.0,716.0,717.0,718.0,719.0,720.0,721.0,722.0,723.0,724.0,725.0,726.0,727.0,728.0,729.0,730.0,731.0,732.0,733.0,734.0,735.0,736.0,737.0,738.0,739.0,740.0,741.0,742.0,743.0,744.0,745.0,746.0,747.0,748.0,749.0,750.0,751.0,752.0,753.0,754.0,755.0,756.0,757.0,758.0,759.0,760.0,761.0,762.0,763.0,764.0,765.0,766.0,767.0,768.0,769.0,770.0,771.0,772.0,773.0,774.0,775.0,776.0,777.0,778.0,779.0,780.0,781.0,782.0,783.0,784.0,785.0,786.0,787.0,788.0,789.0,790.0,791.0,792.0,793.0,794.0,795.0,796.0,797.0,798.0,799.0,800.0,801.0,802.0,803.0,804.0,805.0,806.0,807.0,808.0,809.0,810.0,811.0,812.0,813.0],\"xaxis\":\"x\",\"y\":[18.336620330810547,17.694942474365234,17.795574188232422,17.755054473876953,17.967819213867188,18.177309036254883,17.562088012695312,17.789081573486328,17.65099334716797,18.421138763427734,18.13860321044922,18.222145080566406,18.065542221069336,17.95406150817871,17.891902923583984,17.733139038085938,17.262056350708008,17.19189453125,17.363069534301758,16.724546432495117,17.25326156616211,18.278804779052734,19.369251251220703,19.36037826538086,18.064146041870117,18.644256591796875,18.67110824584961,18.619901657104492,18.510047912597656,19.321208953857422,17.930465698242188,17.593997955322266,19.363109588623047,18.260250091552734,18.254146575927734,18.879804611206055,18.611469268798828,18.962310791015625,17.957324981689453,18.80128288269043,17.646760940551758,18.077213287353516,18.762928009033203,18.700002670288086,17.47397804260254,18.206663131713867,18.89911651611328,16.546995162963867,18.666109085083008,17.814722061157227,17.460071563720703,17.59758949279785,17.83399200439453,16.77459716796875,17.685977935791016,17.335927963256836,17.861297607421875,19.439964294433594,18.188983917236328,19.660930633544922,18.453256607055664,18.434255599975586,18.151180267333984,17.230575561523438,18.09364128112793,17.046119689941406,16.785663604736328,17.642608642578125,17.977222442626953,17.831825256347656,18.88279914855957,18.679250717163086,19.071392059326172,18.23604965209961,17.850902557373047,18.10343360900879,17.73264503479004,19.30821418762207,18.9150447845459,19.596546173095703,19.056076049804688,19.260944366455078,17.460094451904297,18.25765609741211,18.091533660888672,17.478055953979492,17.645092010498047,18.489015579223633,18.521265029907227,17.815465927124023,19.034883499145508,18.710750579833984,17.716690063476562,17.917810440063477,18.567760467529297,18.29084587097168,18.58755874633789,18.468891143798828,18.980098724365234,18.203632354736328,18.341686248779297,17.144678115844727,16.755996704101562,17.070064544677734,18.042530059814453,16.67086410522461,17.800125122070312,17.289691925048828,16.427032470703125,16.646953582763672,16.475505828857422,18.23624038696289,16.61919593811035,16.650217056274414,16.884716033935547,16.870311737060547,16.758787155151367,16.156770706176758,16.254257202148438,16.225669860839844,16.386892318725586,16.28274917602539,16.64020538330078,17.55434226989746,16.439647674560547,17.139902114868164,17.416088104248047,16.537681579589844,16.67456817626953,17.18012809753418,17.666828155517578,16.912960052490234,19.50668716430664,17.880903244018555,18.19656753540039,18.487661361694336,17.828453063964844,19.491640090942383,17.803691864013672,18.54762077331543,18.2905216217041,17.707815170288086,18.53000259399414,17.774051666259766,18.32614517211914,17.877965927124023,19.116979598999023,17.73853874206543,18.525691986083984,17.709396362304688,18.54651641845703,17.877391815185547,18.76744842529297,19.01291847229004,18.358184814453125,18.553775787353516,18.225093841552734,17.45298194885254,17.271839141845703,17.395610809326172,17.482450485229492,17.790451049804688,17.65634536743164,16.458974838256836,17.856643676757812,17.109859466552734,16.660030364990234,17.642929077148438,17.145496368408203,16.941118240356445,16.480554580688477,16.788219451904297,17.8000545501709,17.11517906188965,16.659130096435547,16.6313419342041,17.206897735595703,16.611446380615234,16.586929321289062,16.683670043945312,16.65974998474121,16.652973175048828,17.736696243286133,16.51052474975586,16.612102508544922,17.085676193237305,16.383560180664062,16.39707374572754,16.446060180664062,16.496782302856445,16.500551223754883,16.401290893554688,16.608722686767578,16.70415687561035,16.351444244384766,16.576038360595703,16.316450119018555,16.66676902770996,16.874507904052734,16.738224029541016,16.427824020385742,16.401697158813477,16.4676456451416,16.323627471923828,16.488239288330078,18.232189178466797,18.621477127075195,18.30694580078125,18.659177780151367,19.132923126220703,18.76809310913086,19.537189483642578,18.521947860717773,18.652034759521484,19.159305572509766,17.748830795288086,17.597566604614258,17.46380043029785,18.367841720581055,18.490325927734375,18.730091094970703,19.033710479736328,18.472522735595703,18.950992584228516,19.33096694946289,17.266433715820312,19.86333465576172,17.980487823486328,18.705705642700195,18.640729904174805,19.614063262939453,18.95794677734375,18.550533294677734,18.598148345947266,16.798114776611328,17.61872100830078,16.543563842773438,17.744298934936523,17.591753005981445,16.799427032470703,17.962299346923828,18.051952362060547,18.690399169921875,19.11187744140625,18.34170913696289,18.07896614074707,17.82558822631836,18.379558563232422,18.198026657104492,18.459423065185547,18.368555068969727,17.64801788330078,18.754947662353516,18.175395965576172,18.968189239501953,18.184036254882812,17.52198600769043,15.959159851074219,17.47022819519043,17.88132667541504,17.74264144897461,17.842044830322266,17.725894927978516,17.829044342041016,17.769840240478516,17.84845542907715,17.73722267150879,17.85455322265625,17.61011505126953,17.979286193847656,18.044143676757812,18.205364227294922,18.108869552612305,18.078134536743164,18.106103897094727,17.9273738861084,17.99081039428711,17.88668441772461,18.33664894104004,17.92151641845703,18.135303497314453,17.44373321533203,17.443103790283203,17.28666877746582,17.572040557861328,16.973690032958984,16.169010162353516,16.224714279174805,16.160749435424805,17.281930923461914,18.85869789123535,17.65619468688965,17.819732666015625,17.6640567779541,17.805511474609375,18.520883560180664,18.70466423034668,18.46457862854004,18.56012535095215,18.168310165405273,18.380722045898438,17.987361907958984,18.020263671875,17.677579879760742,17.58932876586914,17.810344696044922,17.66101837158203,18.34856414794922,18.688858032226562,18.40506362915039,19.098079681396484,17.28829574584961,18.240995407104492,18.1416072845459,17.384002685546875,18.231103897094727,19.005231857299805,17.838735580444336,18.60013198852539,17.832433700561523,18.822011947631836,18.127840042114258,18.465473175048828,18.557632446289062,19.62204360961914,18.05617332458496,18.00941276550293,16.98884391784668,17.07259178161621,17.22634506225586,16.48468017578125,17.02889060974121,16.697277069091797,18.832874298095703,17.742000579833984,19.52672004699707,18.186723709106445,16.02021598815918,17.094890594482422,17.411630630493164,17.026941299438477,17.098398208618164,16.40319061279297,17.877635955810547,18.978256225585938,19.3422794342041,18.207639694213867,18.710012435913086,18.8819580078125,18.125267028808594,16.85226058959961,17.8778133392334,17.1427059173584,17.667827606201172,17.155860900878906,17.83091163635254,17.640729904174805,18.63743782043457,17.780658721923828,17.718381881713867,18.045833587646484,17.7213077545166,18.875905990600586,18.828357696533203,18.68284797668457,17.96891975402832,17.590003967285156,18.935033798217773,18.32594871520996,18.807846069335938,18.738006591796875,17.871505737304688,17.88632583618164,15.97661018371582,18.35006332397461,18.18184471130371,18.60601806640625,19.386123657226562,18.371532440185547,19.112037658691406,18.79806137084961,18.681621551513672,19.074195861816406,18.365140914916992,17.93204116821289,17.08185386657715,16.172348022460938,16.19860076904297,16.19065284729004,16.122377395629883,16.226261138916016,16.186145782470703,16.186647415161133,16.187503814697266,16.192684173583984,16.162464141845703,16.234766006469727,16.207027435302734,16.16258430480957,16.14791488647461,16.222774505615234,16.474477767944336,16.29513168334961,16.112598419189453,16.216400146484375,16.292165756225586,16.131824493408203,16.186006546020508,16.209482192993164,17.01097297668457,16.203033447265625,16.1851863861084,16.48219871520996,16.191545486450195,16.176441192626953,16.444326400756836,16.177082061767578,16.185155868530273,16.42513656616211,16.251482009887695,16.186986923217773,18.709293365478516,17.369136810302734,19.479740142822266,19.440921783447266,20.23019027709961,16.644784927368164,19.131702423095703,17.552570343017578,18.516544342041016,18.243148803710938,18.981618881225586,19.323942184448242,18.85006332397461,17.344074249267578,18.60475730895996,16.90152359008789,18.168811798095703,16.359683990478516,18.586851119995117,18.61412239074707,17.432109832763672,16.993677139282227,18.131439208984375,16.218618392944336,16.233028411865234,16.31158447265625,16.212623596191406,16.154682159423828,16.25351333618164,16.216026306152344,16.086868286132812,16.198680877685547,17.66390609741211,16.664947509765625,16.222885131835938,16.170217514038086,16.54036521911621,16.276691436767578,17.006832122802734,17.15121078491211,16.21013641357422,16.698673248291016,16.5440731048584,16.5279598236084,16.2327823638916,16.67587661743164,16.335405349731445,16.380414962768555,16.267044067382812,16.302995681762695,16.15517234802246,17.62277603149414,17.031200408935547,16.59332275390625,16.247760772705078,16.664779663085938,16.09249496459961,16.226709365844727,16.211544036865234,16.254764556884766,16.209617614746094,16.20610237121582,16.24087142944336,16.226293563842773,17.093090057373047,18.515352249145508,19.6147403717041,19.12413215637207,18.899389266967773,19.310325622558594,18.51349449157715,18.165634155273438,18.212112426757812,17.271190643310547,18.898029327392578,18.849376678466797,18.063451766967773,19.310989379882812,18.524456024169922,18.717479705810547,18.055885314941406,18.53664779663086,18.29806137084961,17.995162963867188,19.02985954284668,17.06104850769043,17.232677459716797,17.802881240844727,16.507183074951172,16.247295379638672,16.54855728149414,16.139678955078125,16.19995880126953,16.168193817138672,16.239330291748047,16.279369354248047,16.13300323486328,16.142274856567383,16.22743034362793,16.250652313232422,16.236467361450195,16.15155029296875,16.267541885375977,16.195363998413086,16.2254581451416,16.158838272094727,17.087814331054688,16.26466941833496,16.13051414489746,16.25223731994629,16.136859893798828,16.136249542236328,16.211217880249023,16.205425262451172,16.208446502685547,16.171369552612305,16.26792335510254,16.235557556152344,16.16501235961914,16.177265167236328,16.17334747314453,16.215370178222656,16.167110443115234,16.229888916015625,16.218008041381836,16.03998565673828,18.152584075927734,17.839433670043945,17.782005310058594,18.444087982177734,19.30685043334961,19.191360473632812,18.681676864624023,18.55073356628418,17.490917205810547,16.63445472717285,18.81430435180664,19.061683654785156,17.9329891204834,16.58209991455078,16.536476135253906,16.20611000061035,16.268043518066406,16.237350463867188,16.16179084777832,17.84259605407715,17.740211486816406,16.140480041503906,16.185176849365234,16.248676300048828,16.197900772094727,16.211864471435547,16.179744720458984,16.25135612487793,16.70322036743164,16.638660430908203,16.740985870361328,17.256074905395508,17.972795486450195,18.572097778320312,17.690401077270508,17.433429718017578,17.52531623840332,18.607467651367188,17.106807708740234,17.76976776123047,18.311288833618164,18.43471336364746,18.86301040649414,19.273591995239258,18.835609436035156,18.620887756347656,18.64688491821289,18.681713104248047,17.99753189086914,17.89382553100586,19.407665252685547,19.502866744995117,19.05152702331543,19.204090118408203,17.687461853027344,19.05506134033203,18.60511589050293,16.531566619873047,19.45646095275879,17.420896530151367,19.585033416748047,18.049915313720703,18.600326538085938,16.99030876159668,18.02843475341797,18.56389617919922,17.885143280029297,17.32339096069336,18.77604103088379,18.514842987060547,18.34270477294922,18.504989624023438,16.49894142150879,19.040771484375,18.037357330322266,18.55061149597168,18.491857528686523,18.93642807006836,19.581308364868164,16.408355712890625,18.582202911376953,18.02508544921875,18.8587646484375,17.164867401123047,16.42839813232422,17.205936431884766,18.174535751342773,16.163366317749023,18.772354125976562,18.23238182067871,19.451335906982422,18.462568283081055,18.44027328491211,18.788856506347656,18.06437873840332,17.20357894897461,17.81649398803711,18.435001373291016,17.631450653076172,18.980215072631836,19.525238037109375,19.626590728759766,18.30673599243164,19.54834747314453,18.223819732666016,18.355247497558594,19.088376998901367,18.508129119873047,19.24837875366211,16.581623077392578,16.290782928466797,16.348222732543945,16.14415740966797,16.08338737487793,17.09133529663086,16.471023559570312,16.212055206298828,16.460346221923828,16.22867202758789,16.584104537963867,16.196353912353516,16.555137634277344,16.423311233520508,16.42871856689453,16.19255828857422,16.16036605834961,16.210830688476562,16.250463485717773,16.190670013427734,16.12028694152832,16.143268585205078,16.35761833190918,16.125154495239258,17.909225463867188,16.995954513549805,16.913850784301758,17.672183990478516,16.63204574584961,17.792539596557617,19.282785415649414,18.45291519165039,19.683032989501953,18.32473373413086,20.639476776123047,18.885744094848633,18.324506759643555,19.453603744506836,19.55855941772461,19.354167938232422,17.85172462463379,17.327083587646484,17.715869903564453,17.21920394897461,18.005069732666016,18.105213165283203,17.55000114440918,17.976964950561523,18.817760467529297,17.275806427001953,16.21401596069336,17.471982955932617,16.38631248474121,16.526113510131836,18.115049362182617,16.718164443969727,16.292369842529297,16.15585708618164,16.99810028076172,17.245559692382812,19.262516021728516,16.42874526977539,17.501602172851562,17.34054183959961,18.253328323364258,17.715009689331055,17.62921142578125,19.773571014404297,18.596593856811523,18.940305709838867,18.070068359375,17.005556106567383,18.654624938964844,17.087236404418945,16.11705780029297,16.037931442260742,16.119150161743164,16.60759162902832,17.358549118041992,16.86636734008789,16.645893096923828,18.53099250793457,18.014047622680664,18.28476905822754,19.00014305114746,19.284626007080078,18.849567413330078,19.06951904296875,18.264530181884766,18.72339630126953,18.955493927001953,17.819046020507812,18.129934310913086,18.810264587402344,19.83678436279297,18.249591827392578,19.650365829467773,18.705215454101562,19.142873764038086,18.857942581176758,20.026647567749023,18.356962203979492,19.998886108398438,18.85348129272461,19.141422271728516,18.85740089416504,18.87550926208496,17.564205169677734,17.541645050048828,16.481826782226562,17.077192306518555,17.94755744934082,18.86252784729004,17.048795700073242,18.08436393737793,17.719030380249023,18.462614059448242,18.37413215637207,17.38930320739746,15.99901294708252,17.685993194580078,17.27084732055664,16.222835540771484,16.537107467651367,16.415699005126953,17.26787757873535,16.299072265625,16.42059326171875,16.62359619140625,16.539836883544922,16.561336517333984,16.355037689208984,16.737804412841797,18.071779251098633,16.6644229888916,17.75604820251465,17.619853973388672,16.28805160522461,16.2833309173584,17.191646575927734,17.030254364013672,17.873699188232422,17.324140548706055,16.38462257385254,16.386308670043945,16.2495059967041,16.455867767333984,18.456100463867188,18.282493591308594,17.331802368164062,16.619577407836914,16.778112411499023,17.252477645874023,16.835308074951172,16.727785110473633,16.681747436523438,17.120946884155273,16.581010818481445],\"yaxis\":\"y\"}],                        {\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Uncertainty\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"legend\":{\"tracegroupgap\":0},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Epistemic Uncertainty Distribution for CONFF\"},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Samples\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Final RR Output (BrPM)\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4b7500f0-e50b-4515-9886-2cc1cb1e27fe');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if input_conf == 'confb':\n",
    "    fig1 = px.scatter(data_confb,x = 'Samples', y=\"Final RR Output (BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper(),\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    fig1.show()\n",
    "\n",
    "if input_conf == 'confa':\n",
    "    fig1 = px.scatter(data_confa,x = 'Samples', y=\"Final RR Output (BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper(),\n",
    "                   color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    fig1.show()\n",
    "\n",
    "if input_conf == 'confd':\n",
    "    fig1 = px.scatter(data_confd,x = 'Samples', y=\"Final RR Output (BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper(),\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "\n",
    "    fig1.show()\n",
    "     \n",
    "\n",
    "if input_conf == 'conff':\n",
    "    fig1 = px.scatter(data_conff,x = 'Samples', y=\"Final RR Output (BrPM)\",title=\"Epistemic Uncertainty Distribution for \"+input_conf.upper(),\n",
    "                     color=\"Uncertainty\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "    fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9080546 2.907976  2.9080667 2.9078608 2.907557  2.9080975 2.9079158\n",
      " 2.90812   2.9074328 2.9076324 2.9080744 2.9081922 2.9078772 2.9081495\n",
      " 2.9080036 2.9078884 2.9077709 2.908204  2.9077172 2.907881  2.9077952\n",
      " 2.9078233 2.9077148 2.9078646 2.9080367 2.9078712 2.9080536 2.9079971\n",
      " 2.908127  2.9077287 2.907987  2.9081438 2.907537  2.9083064 2.9080641\n",
      " 2.9077883 2.9080374 2.907685  2.907985  2.9078214 2.9077034 2.907869\n",
      " 2.9073744 2.9080222 2.9080722 2.907897  2.9077444 2.9080179 2.9081514\n",
      " 2.9082894 2.9079783 2.9082003 2.9079075 2.907746  2.9074621 2.9080975\n",
      " 2.907859  2.9080853 2.9079874 2.9079437 2.9075978 2.9077804 2.9080675\n",
      " 2.9081733 2.9079113 2.9081914 2.9080307 2.9080467 2.9078658 2.9079692\n",
      " 2.9079387 2.9080584 2.9080863 2.9080586 2.907853  2.908178  2.9081724\n",
      " 2.9081018 2.908371  2.9080606 2.9081655 2.907804  2.9080324 2.9080184\n",
      " 2.9081328 2.9081216 2.9077845 2.9078639 2.9076734 2.9074996 2.9071968\n",
      " 2.9080303 2.907887  2.9075458 2.9079056 2.9083006 2.9083233 2.9082735\n",
      " 2.9079301 2.9076486 2.908114  2.9078777 2.9080741 2.9081237 2.9075704\n",
      " 2.908083  2.907953  2.9081836 2.9080913 2.9076686 2.9077325 2.9074416\n",
      " 2.9076738 2.9079154 2.907889  2.908112  2.9077716 2.9076533 2.9072316\n",
      " 2.907937  2.9080112 2.90724   2.9058945 2.9070027 2.9058437 2.9009569\n",
      " 2.8687868 2.8204103]\n",
      "[2.9098637]\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confc' or input_conf == 'confe':\n",
    "    entropy = scipy.stats.entropy(output_copy,base=10)\n",
    "    print(entropy)\n",
    "    \n",
    "if input_conf == 'confb' or input_conf == 'confa':\n",
    "    entropy = scipy.stats.entropy(output_copy,base=10)\n",
    "    print(entropy)\n",
    "\n",
    "if input_conf == 'confd' or input_conf == 'conff':\n",
    "    entropy = scipy.stats.entropy(output_copy,base=10)\n",
    "    entropy_rr = scipy.stats.entropy(output_copy_rr,base=10)\n",
    "    print(entropy)\n",
    "    print(entropy_rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_NLL(y, mu, sigma, reduce=False):\n",
    "    #import pdb;pdb.set_trace()\n",
    "    ax = list(range(1, len(y.shape)))\n",
    "\n",
    "    logprob = -tf.math.log(sigma) - 0.5*tf.math.log(2*np.pi) - 0.5*((y-mu)/sigma)**2\n",
    "    loss = tf.reduce_mean(-logprob, axis=ax)\n",
    "    return tf.reduce_mean(loss) if reduce else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negetive Log Liklihood for Respiration Signal for conff is [ 0.61837894  2.8192515   0.2987863   0.51293564  0.83118916  0.4283404\n",
      "  0.9056243   0.8256352   0.82632726  1.1020368   1.3653611   1.5968177\n",
      "  0.57669604  1.4653394   0.74467826  1.0439922   0.30402917  2.1981764\n",
      "  1.8298641   0.15996939  0.4156931   0.754079    1.1117139   0.16363059\n",
      "  0.21159811  2.3680704   1.5983613   5.3721657   8.580663    4.6150675\n",
      "  3.1825252   2.3123121   1.93842     6.0655746   0.9312668   1.0137538\n",
      "  0.36341888  1.6199031   9.843379    1.3176281   0.7291973   3.0434713\n",
      "  2.7442746   1.1025488   3.4261646   3.394413    1.6031837   2.1909225\n",
      "  3.3949647   3.3376212   2.3705745   5.0564384   4.1700563   4.256546\n",
      "  2.106236    4.6108      2.690773    2.3493795   2.2124846   4.3942842\n",
      "  1.1367131   4.5493145   4.520647    3.6125777   2.684256    3.1188176\n",
      "  2.8177505   7.004591    1.7644224   3.1322863   3.4611442   2.0727792\n",
      "  1.7554009   0.7433741   2.8142803   0.77045214  4.516413    4.366583\n",
      "  3.4706714   0.96334296  5.932683    4.8336535   4.7192726   3.247982\n",
      "  5.0169225   2.6532109   6.574256    4.9100246   3.822544    9.413664\n",
      "  8.988521    8.126942    6.694939    3.5560412   5.446253   11.064729\n",
      "  6.835485    5.834489    8.293301    2.9549992   9.431265    5.9195113\n",
      "  3.3330455   1.5800931   4.7995605   4.8597946   0.62528324  2.0286794\n",
      "  4.56417     1.3899583   4.0016737   1.8204007   3.422655    4.71162\n",
      "  4.0642614   2.7135477   3.819991    1.5956371   2.5502448   1.9375643\n",
      "  1.7733412   4.836526    0.7408917   2.815351    5.1029873   1.8140335\n",
      "  0.6618969   2.99253     2.0304532   2.2290845   3.7060027   1.8751562\n",
      "  3.251965    0.9898366   1.9140079   4.7197576   5.2964373   2.5426602\n",
      "  2.4893966   4.169134    5.5760083   5.4923735   4.535519    4.8446355\n",
      "  4.2429204   5.2662983   1.6105876   1.7054759   2.490715    3.7973955\n",
      "  2.9813778   2.6038947   1.7726995   3.9072845   2.7459502   1.4745231\n",
      "  7.5942984   2.6308694   2.5412936   7.786469    2.8363965   3.5767975\n",
      "  1.3783759   5.634207    3.0724213   4.7190995   3.4620645   3.6241343\n",
      "  6.170291    3.7083395   2.465488    2.0129502   3.4032779   3.7299545\n",
      "  2.7704868   4.107595    2.844359    3.4022148   2.2763753   3.774451\n",
      "  3.33177     1.6179831   2.2553334   3.9506052   2.5079956   4.012699\n",
      "  1.1520342   5.0056505   2.013969    5.2442794   2.1528778   1.7672112\n",
      "  1.8595674   1.748885    1.5500019   2.8490095   2.7241652   0.3426537\n",
      "  1.1828161   0.81704664  2.1678076   2.0204768   2.6207604   1.2798841\n",
      "  5.5523906   2.5952644   2.4148576   2.9876852   1.9521536   4.394164\n",
      "  3.247795    2.7477372   2.0513797   1.9986604   0.4169547   0.2829231\n",
      "  2.069095    2.3782697   3.056587    3.003522    3.082509    3.0879693\n",
      "  0.8784373   1.7656028   1.4752771   1.4767176   1.8049332   3.672032\n",
      "  2.6826954   2.8506258   2.9548907   5.2275076   1.8032389   2.1680222\n",
      "  1.3855898   2.1289911   1.272259    2.553102    0.4260256   2.856814\n",
      "  2.341875    4.004126    1.5469434   4.1204104   0.5439956   1.118675\n",
      "  1.4967036   1.0718544   1.6216158   0.30883303  3.6739829   1.4448603\n",
      "  0.9830382   0.70195127  3.9048955   1.2676711   0.22822031  2.9466214\n",
      "  1.0643466   0.11967773  0.05464431  0.04665299  0.25619316  0.57270944\n",
      "  0.63486373  0.90306187  0.7088945   0.34568188  0.10647629  1.0821291\n",
      "  0.2610644   0.80526376  0.21260431  0.6766023   0.8020525   0.0801587\n",
      "  0.24437259  0.16543253  0.09566236  3.5362911   1.7714214   1.7968313\n",
      "  2.2743316   3.1026285   1.9756988   0.7948313   2.4894946   3.7543864\n",
      "  1.176504    1.4478737   0.9721861   1.51808     1.0975873   2.188352\n",
      "  0.5567754   1.7783203   0.77930397  1.5592462   1.2146987   1.3965586\n",
      "  2.5362298   1.8252668   1.3433689   1.3486907   0.7324227   2.779266\n",
      "  2.524457    3.9606535   2.0681586   1.6211998   2.2504778   4.8998156\n",
      "  2.3195684   0.4768226   3.1511574   0.7244057   1.8740926   0.77990687\n",
      "  0.9878332   2.8001642   1.6824312   1.42511     3.974743    2.422143\n",
      "  1.547725    2.879875    2.5605898   4.053336    1.9734467   1.4377964\n",
      "  1.4219892   3.9984772   2.8572462   2.1970696   1.3720012   1.2228261\n",
      "  2.5065918   2.9701095   2.7062988   6.960845    1.3737929   0.7000132\n",
      "  1.0922205   2.3924382   2.074595    1.4070963   0.7963985   0.65949637\n",
      "  0.99804044  2.8286126   5.5165615   8.460178    2.5779972   4.2719336\n",
      "  2.001399    1.5291715   2.6991034   1.9254141   1.9498005   0.83214957\n",
      "  0.7559452   1.8992184   1.2651405   0.6258336   1.9188468   5.015487\n",
      "  2.6067562   7.0454855   6.2050686   2.2774332   2.2812524   1.3656361\n",
      "  2.1745486   1.4294239   1.1098206   1.6720608   1.536524    0.70484984\n",
      "  1.9302402   0.4011764   3.283319    1.8564239   0.18895954  0.9308825\n",
      "  0.6293121   7.3840027   6.0434885   2.5562186   2.433997    3.764072\n",
      "  6.78864     1.915798    2.3555295   3.6319342   4.917726    1.7110957\n",
      "  2.046536    1.9517506   3.1678586   3.40042     1.8922193   2.867071\n",
      "  1.1892279   1.0155995   2.6746066   1.5695252   2.9323754   1.5974844\n",
      "  1.4000978   1.201378    2.3602293   0.99592376  2.4716048   3.2339096\n",
      "  2.357755    3.7600107   2.2240481   2.2585728   5.814032    5.817461\n",
      "  3.6254835   4.4274077   5.5504274   2.7254863   0.40195185  6.9666696\n",
      "  3.1603134   1.7106717   3.8525023   4.5097237   0.6191769   1.2565228\n",
      "  0.80658925  2.7062976   5.314872    2.550605    5.0706816   9.822309\n",
      "  5.770987    1.7360771   9.124092    8.656324    8.866285    3.9022534\n",
      "  1.0435929   4.0006657   0.87206125  2.2708826   1.4307384   3.2112195\n",
      "  1.4068234   1.3871381   3.1530833   2.274007    0.54691064  1.8653114\n",
      "  3.7242455   1.3724108   1.0418742   4.0544596   1.1366645   2.3417616\n",
      "  0.98819566  1.0206842   1.8964826   1.368756    0.61777043  1.2312214\n",
      "  1.1863341   0.83902454  0.770789    0.2638284   2.1340952   1.9273726\n",
      "  2.5483873   2.7751362   1.4222944   0.35888386  1.2653472   0.7361506\n",
      "  1.505575    2.3887112   0.7041777   1.886642    0.9583961   3.5516434\n",
      "  4.236874    2.6122036   1.6768533   2.1168566   1.4031776   1.1779804\n",
      "  1.2423631   1.4741597   0.62880445  0.8910628   1.5048163   0.5578432\n",
      "  0.85438156  3.0991971   2.679631    0.6984581   0.6578562   1.542913\n",
      "  1.4800496   0.902884    1.0382692   0.8505555   3.349735    3.300033\n",
      "  1.8885069   3.8426404   3.3861878   1.7111973   1.1134286   0.72813773\n",
      "  1.7468241   1.0679834   1.9662299   1.2708764   2.3575094   2.189593\n",
      "  2.364223    2.3574822   2.1139333   1.1240242   1.8750894   3.9490838\n",
      "  1.8685553   2.2270498   1.1002346   1.7408636   6.952099    1.6446898\n",
      "  1.1065079   0.90771323  1.380744    1.1668723   1.5405157   1.921947\n",
      "  0.5603807   1.9345326   1.2801185   0.903466    1.0084989   1.5346708\n",
      "  3.0226703   2.5021415   3.1165571   2.6812294   1.0753306   1.0627263\n",
      "  0.68354845  0.8552536   2.661799    1.9916196   2.3855934   2.1777883\n",
      "  1.3265351   3.475861    1.2233247   1.0186288   0.66558844  0.8417127\n",
      "  0.8465994   1.4068977   1.0669569   5.3012857   0.47453558 -0.05437006\n",
      "  0.46009207  0.19081219 -0.34053588  0.18244861 -0.36290252  1.9963553\n",
      "  0.05588977 -0.1104708   0.6014888   1.3939259   0.7957014   1.3057768\n",
      "  0.08059687  4.0687327   0.7406903   1.2902303   1.3004179   3.4993267\n",
      "  0.5216488   0.77843714  1.6389917   4.4022803   7.1389904   7.189497\n",
      "  8.91438     2.1980283   3.5528111   9.281683   11.137716   17.943972\n",
      "  8.526388    3.9444096   2.3924165   1.1409523   0.55769914 -0.04656659\n",
      "  1.493365    2.8462887   0.35689873  2.730202    1.3449955   2.1955805\n",
      "  2.7642026   1.1056796   1.2105243   2.9546697   0.7002504   2.598731\n",
      "  1.8886356   1.2020903   2.3319035   1.9333851  -0.3105532  -0.19689965\n",
      "  2.1939197   0.21954823 -0.15800983  0.3984921  -0.10556758  0.4943139\n",
      "  1.7333256   0.64505106  0.7391077   2.1417842   7.8569036   0.7622802\n",
      "  9.320045    4.2946773   4.298401    0.48385793  5.1204653  12.393234\n",
      " 10.165783   17.39849    15.322592    4.7682333   2.2970338   1.2981008\n",
      "  1.354548    3.3423629   5.979007    2.4599845   5.0651894   2.929472\n",
      "  5.8187957   1.0205314   8.016551    3.1292462   0.9721258   0.20784293\n",
      "  1.9003356   2.0918968   0.82749623  0.29826656  1.247201    1.2687098\n",
      "  0.9994986   1.9997721   0.13403842  2.2309313   1.7425709   1.1167221\n",
      "  0.69253546 -0.2395017   0.02955756 -0.23222044  3.3631854   3.222835\n",
      "  1.3080864   2.1738038   0.81237483  1.3671775   0.6598015   1.4687881\n",
      "  2.8965561   4.7363005   3.1312218   2.424633    3.0546844   2.049492\n",
      "  1.6198006   1.7744813   2.4696255   3.0369081   3.2971942   1.193166\n",
      "  4.167281    1.4680159   3.2777462  -0.327337    2.4448216   1.6602291\n",
      "  1.1537886   1.1214588   1.3549988   3.5341294   0.9498475   0.65762687\n",
      "  1.3733652   1.2263775   1.1814241   1.2804134   1.5116456   1.8578308\n",
      "  1.8589208   0.85884917  0.22437024  0.63741356  1.658638    1.3043541\n",
      "  1.0751936   0.801232    0.06806234  0.9482082  -0.1506117   0.5212958\n",
      "  1.3696189   0.82327545  2.2092934   2.3742754  -0.17887673  1.0105261\n",
      "  0.23909329  1.3480306   0.7452318   2.139189    1.1745148   0.72548974\n",
      "  2.1914196   0.17364821  5.532052    2.0376005   2.1951604   0.7832292\n",
      "  1.6283364   1.4651171   2.8858585   1.5381887   1.5621698   3.113778\n",
      "  1.6076034   4.0218735   1.3772929   1.444491    0.25655788 -0.08722705\n",
      "  0.77456045  0.24259987 -0.02449965  0.93057066  0.6289839   0.19527237\n",
      "  1.8036822   0.2279868   5.0099697   0.98552626  1.2459233   4.037645\n",
      "  1.5909526   1.2048239   2.2373283   0.7300081   0.61271715  0.60512245\n",
      "  0.43288055  0.7157674   0.43978673  0.90995336  0.02168083  0.5188707\n",
      "  6.021448    0.7033426   0.22865446 -0.10684221 -0.06769466  0.7900144\n",
      "  0.4872278  -0.20800635  0.13813028 -0.35255235  0.7616024   0.78551215\n",
      "  1.7334586   2.1985586   1.307638    1.0593846   0.19846204 -0.08344654\n",
      "  0.08387057 -0.2531213   0.05220282  0.04686221  0.07187471  0.06814302\n",
      "  0.46795675  1.3066769   0.11007847 -0.44236308  0.59558725  2.1176531\n",
      "  1.5474356   2.0816653   0.03691614  1.4547577 ]\n",
      "Average negetive Log Liklihood  for Respiration Signal for conff is 2.3399465084075928\n",
      "Negetive Log Liklihood for Respiration Rate for conff is [2.9021063 2.818257  2.9984493 2.9253666 2.8477414 2.965534  3.0199192\n",
      " 2.9032257 2.8876598 2.9299488 2.9001794 2.9461553 2.8584633 2.948786\n",
      " 2.8970838 2.8183918 2.9231958 2.9051356 2.846875  2.9826214 2.9827235\n",
      " 2.8997092 2.8965507 2.8315346 3.0110824 2.816867  2.8254778 2.8166685\n",
      " 2.8618007 2.8433046 2.8569834 3.310018  2.841442  2.8178022 3.1574414\n",
      " 3.538978  2.845019  3.0342536 3.3485565 2.9046    3.2422843 2.8938007\n",
      " 3.5447037 2.9121919 2.878936  2.834077  2.8163707 3.307734  2.848581\n",
      " 3.07237   3.1092632 2.900393  3.3334045 2.8186553 2.8196983 2.8367183\n",
      " 2.89272   2.8394783 3.081481  2.8438008 3.1109807 2.8169558 2.8276532\n",
      " 3.2991996 3.0047612 2.9259725 3.3669877 2.8271492 4.3025227 3.5565705\n",
      " 3.8508253 2.8171444 2.8692863 2.8299322 2.9761534 3.4292836 2.832583\n",
      " 2.8253355 2.8259614 2.820151  2.8576388 3.6005394 2.822736  2.8200636\n",
      " 3.2948816 3.8638265 3.108835  2.902293  2.8232055 2.9212248 2.8628812\n",
      " 3.0821912 3.0660543 2.8378565 2.8270705 2.8219235 2.940009  2.9025705\n",
      " 2.8374968 3.0301034 2.8165061 2.948311  2.8225374 3.2615552 2.816999\n",
      " 3.246604  3.277094  2.8188503 2.9239879 2.868822  2.9542623 3.225519\n",
      " 2.8176045 2.8164566 2.8907847 2.9399102 2.8162737 2.90583   2.8936057\n",
      " 2.9338484 2.8165371 2.8414078 2.8233807 2.8974156 2.8417094 2.8602135\n",
      " 2.8163965 2.9058688 2.8190553 2.8249846 2.8205616 2.8295987 2.926901\n",
      " 2.8867466 3.2981117 3.2311726 2.889431  2.8218563 2.8345442 3.0349407\n",
      " 2.8177009 2.8385468 2.8196623 2.8516185 2.863809  3.1062694 2.9655397\n",
      " 4.353101  3.127314  3.3986242 3.2074711 3.0952485 3.745061  3.9294586\n",
      " 2.9670274 3.0765343 2.8532667 2.8894494 2.8877864 2.9685392 2.8856223\n",
      " 3.0401108 3.115259  2.8547533 2.9734864 2.945852  2.8177617 2.865361\n",
      " 3.0320816 3.0576684 2.8367705 2.922674  2.941918  2.9093716 2.8167884\n",
      " 2.816478  2.915547  2.8408875 2.8925693 3.1139305 2.959546  2.9861503\n",
      " 2.8698013 2.8806884 2.8168373 3.0935688 2.904241  3.0336092 2.908309\n",
      " 3.1424952 3.167861  3.1310182 2.9942408 2.884617  2.8165839 2.8170507\n",
      " 2.8969417 2.847604  2.8615215 3.0432985 2.8483455 2.8689167 2.8243322\n",
      " 3.1580353 3.0549276 2.8235261 3.1750953 2.8800316 2.8962913 2.9606562\n",
      " 3.022919  3.0346777 2.8440015 2.8960724 2.823646  3.0216286 2.8722062\n",
      " 2.92475   2.8425467 2.8179624 2.8351521 2.8705676 2.8697917 2.816365\n",
      " 2.9775167 2.8498144 2.9457576 2.8442504 2.846488  2.8360777 2.8767753\n",
      " 3.0796955 2.8165755 3.0718093 3.367815  2.9798424 2.8503797 3.2493517\n",
      " 2.817334  2.883324  2.8217874 2.8199263 2.9545655 2.9741201 3.077307\n",
      " 3.5215845 3.0688426 3.0011942 3.0506396 3.2504625 2.9355648 2.8275297\n",
      " 2.9862053 3.0959485 2.817854  2.853395  2.9715638 2.917035  2.8546526\n",
      " 2.9431806 3.0862782 3.1106346 3.0239036 2.962449  3.0204449 2.9192867\n",
      " 2.8380263 2.9256132 2.9505205 2.821801  2.8891954 2.8963346 2.8917694\n",
      " 2.9577742 2.9226584 2.8166294 2.9353662 2.9903371 2.8343058 2.821719\n",
      " 3.1568978 2.962761  3.0315804 3.0471344 2.9048073 2.9503753 2.8168685\n",
      " 2.9471416 2.938736  2.8764946 2.8178878 2.878029  2.8167164 2.8165956\n",
      " 2.9357662 2.837842  2.818561  2.8320704 2.8495333 2.8173573 2.8183455\n",
      " 2.8550127 2.8163955 2.8192701 2.8922055 2.8357487 2.8268282 2.8190029\n",
      " 2.992055  2.816475  2.8999436 3.0370855 2.9545238 2.8175206 3.07548\n",
      " 3.0145702 2.8321915 3.0477927 2.821223  3.5999746 3.0699935 3.1495082\n",
      " 2.9726732 2.8973303 2.881127  2.8273609 2.8687162 2.8463266 2.994427\n",
      " 2.891771  3.2319422 3.1143167 2.9799163 2.8228989 2.9208376 2.8957098\n",
      " 2.8225906 2.8312356 2.89562   3.102412  2.8345547 2.8700151 3.1200018\n",
      " 2.8307815 2.8427732 2.8282166 2.8870435 2.8201637 2.8909035 3.0221171\n",
      " 2.8445446 4.319162  2.8163974 2.8206792 2.9714174 2.8606222 2.8359115\n",
      " 3.1161523 2.8243074 3.2324772 2.8849514 2.927895  2.8304973 2.8718932\n",
      " 2.8256934 2.968823  2.9248893 3.0626884 3.0476847 2.8370087 2.8395398\n",
      " 2.8230057 3.269404  2.8300388 3.085419  2.8391335 2.8277628 2.8259025\n",
      " 2.8379207 2.9161801 2.8661466 2.8226047 2.8186612 2.840191  2.931197\n",
      " 2.8852148 3.5053146 3.4275646 3.331038  3.1811068 2.9215517 2.8193564\n",
      " 2.8473887 2.8521254 3.0177658 2.8214061 3.9833202 2.8440917 2.8239543\n",
      " 2.896784  2.8869894 2.9920864 2.81648   2.9175856 3.4975731 3.0003598\n",
      " 2.9543183 2.8166142 2.8569257 2.8453226 3.0611165 3.1035066 3.0707352\n",
      " 3.2473726 2.9070883 2.8834386 2.8227804 2.8319998 2.8809085 2.8743863\n",
      " 2.819421  2.8831902 2.8238215 2.8777351 2.9894657 2.834751  2.860198\n",
      " 2.948795  3.1332119 2.8199427 2.8300188 2.920106  2.8580954 2.8913307\n",
      " 2.8176208 2.8190126 2.959395  2.922251  2.8232498 2.8166535 3.2784367\n",
      " 3.148055  2.852353  2.8351173 2.8729074 2.96074   2.8765216 2.9623313\n",
      " 2.8250005 2.8597567 2.8263724 2.848298  2.891317  2.8534024 2.81878\n",
      " 2.864132  3.0230808 2.8385336 2.8779647 3.0206249 2.8503282 3.0442038\n",
      " 2.8162446 2.8529496 2.8365083 2.825528  2.9902048 3.2318227 2.8239686\n",
      " 2.842552  2.8226142 2.8348904 3.0522027 3.3886073 2.8181233 3.196261\n",
      " 2.846524  2.8255339 2.84952   3.0848231 3.2562013 2.9710279 2.968995\n",
      " 2.9363613 2.9833515 2.8211455 2.8599176 2.9885733 2.948276  2.8825276\n",
      " 2.8245451 3.135395  2.8242106 2.9938436 2.8167055 2.8300493 3.525185\n",
      " 2.8342586 3.3511896 2.9060762 2.876129  3.1202497 3.0500674 2.990956\n",
      " 2.8485525 2.8721077 2.8516042 3.0527499 2.913213  2.8367598 2.8485315\n",
      " 2.8273559 3.027754  3.0429335 3.2571979 3.4208179 3.0234313 3.404047\n",
      " 3.1305456 3.1435122 2.8181007 2.89527   2.9134107 2.8187668 2.9312677\n",
      " 2.8345397 3.5077167 2.9386554 3.0444634 3.1800427 3.2753265 3.2616181\n",
      " 3.261677  2.8365507 3.0119426 3.6940467 3.2870169 3.6823144 3.1195712\n",
      " 2.951856  3.0639453 3.064326  3.3582714 3.0984263 4.0413275 3.22165\n",
      " 2.9925354 2.9512687 3.2784257 3.0144632 3.2252135 2.8364837 3.0527723\n",
      " 2.8361077 2.8169448 2.8363564 2.8702197 2.8190372 3.0520015 2.840675\n",
      " 2.990025  2.8172226 2.9089985 2.8163314 2.9030652 2.8423522 3.0753891\n",
      " 2.9339619 2.89475   2.95022   2.945234  3.1190205 3.1223497 3.2025685\n",
      " 3.037766  3.2324955 2.9434152 3.0175295 2.8889198 2.8235743 2.8197753\n",
      " 2.8168504 2.9792435 2.9799962 2.817816  2.8368056 3.0013597 2.8170686\n",
      " 2.902087  2.8544376 2.81809   2.816959  2.832147  2.8422549 3.3723335\n",
      " 2.896735  2.8975077 2.8721018 2.9505508 2.9152942 3.0108607 2.8871582\n",
      " 2.8948915 3.0190477 2.8260188 2.9020634 2.9178078 2.9298208 3.4380865\n",
      " 2.8755307 2.8266404 2.8688626 2.8209229 3.1135924 2.8208294 2.9226866\n",
      " 3.0336995 2.9662714 2.865846  2.8672416 2.9314976 2.8235953 2.980817\n",
      " 3.0212367 3.0393364 2.8633456 3.2839224 2.816585  2.9009588 2.8370025\n",
      " 2.9068632 3.939105  3.0555747 3.0957663 3.9987643 2.8168955 3.2566578\n",
      " 3.6839368 3.7427402 3.535694  3.19809   3.085461  3.674714  3.1887383\n",
      " 3.245826  3.1682944 2.8211164 2.8646152 2.8288937 2.836321  2.8345141\n",
      " 2.8340855 2.8261216 2.8313444 2.9052424 2.9240048 2.9212332 2.9388695\n",
      " 2.9390337 3.279763  3.602322  2.8865173 2.8167384 2.8732347 2.8273566\n",
      " 2.8229265 2.8172438 2.8322604 3.33742   2.8422148 3.0249047 3.6140018\n",
      " 3.1762724 3.5786054 3.0668945 3.2842278 2.9194942 2.816989  2.9190621\n",
      " 2.9448547 2.8920236 3.0746808 2.9506679 2.8873856 2.8232875 2.8457873\n",
      " 2.831739  2.9015949 3.3049574 2.8664749 3.375913  3.0224051 2.8367343\n",
      " 3.0943718 3.3143651 2.8279788 2.8296885 2.8408484 2.8756316 3.1298342\n",
      " 2.835542  2.816628  3.06185   2.9602313 2.882793  3.0589106 2.9775481\n",
      " 2.816626  3.0805905 2.8229709 2.9959073 2.9270573 2.957822  2.8630977\n",
      " 2.8231795 2.9883296 2.8359077 2.8536599 2.8323474 2.9709592 3.0480194\n",
      " 2.9964697 3.0238173 3.7965786 3.1278858 3.0778878 3.1221085 3.0098362\n",
      " 2.8420293 2.8839774 2.8274422 2.9737148 2.927538  2.9743633 2.8170817\n",
      " 3.0564165 3.1479435 2.8607147 2.946719  2.9007792 2.950021  2.8173423\n",
      " 2.9079661 3.1863236 2.832635  2.8175497 2.8863535 3.0885081 2.8366508\n",
      " 2.9462695 2.970418  2.9169536 3.0084221 2.9253473 3.7198162 2.8768861\n",
      " 2.9414876 3.1451592 2.8496158 2.8368127 3.128271  3.1375055 3.3683453\n",
      " 2.849532  2.8260663 3.374796  2.8884292 2.8636847 3.1295586 2.9512239\n",
      " 3.1223722 2.8253098 2.8174899 2.8207002 2.9829216 2.9968045 2.9704256\n",
      " 2.962725  2.9615781 3.0373192 2.8190293 2.8446243 3.2686167 3.057525\n",
      " 3.5040133 3.4063125 2.980186  3.1769433 3.3745506 2.904713  2.8221638\n",
      " 2.8918161 2.8192844 2.9062994 2.956941  2.8814886 3.1981182 2.8588998\n",
      " 2.9498618 3.0133438 3.287119  3.419156  3.5271177 3.080432  2.9417489\n",
      " 2.835487  4.06761   3.4705894 2.9401789 2.8665397 3.2229118 2.9770937\n",
      " 3.0294886 2.834053 ]\n",
      "Average negetive Log Liklihood  for Respiration Rate for conff is 2.98344349861145\n"
     ]
    }
   ],
   "source": [
    "if input_conf == 'confc' or input_conf == 'confe':\n",
    "    nll = Gaussian_NLL(y_test_data, output_copy, std_dev, reduce=False)\n",
    "    negetive_log = nll.numpy()\n",
    "    avg_nll = np.mean(negetive_log)\n",
    "    print(\"Negetive Log Liklihood for {} is {}\".format(input_conf,negetive_log))\n",
    "    print(\"Average negetive Log Liklihood for {} is {}\".format(input_conf,avg_nll))\n",
    "\n",
    "if input_conf == 'confb' or input_conf == 'confa':\n",
    "    nll = Gaussian_NLL(x_test_ref_rr, output_copy, std_dev, reduce=False)\n",
    "    negetive_log = nll.numpy()\n",
    "    avg_nll = np.mean(negetive_log)\n",
    "    print(\"Negetive Log Liklihood for {} is {}\".format(input_conf,negetive_log))\n",
    "    print(\"Average negetive Log Liklihood for {} is {}\".format(input_conf,avg_nll))\n",
    "\n",
    "if input_conf == 'confd' or input_conf == 'conff':\n",
    "    nll = Gaussian_NLL(y_test_data, output_copy, std_dev, reduce=False)\n",
    "    nll_rr = Gaussian_NLL(x_test_ref_rr, output_copy_rr, std_dev_rr, reduce=False)\n",
    "    negetive_log = nll.numpy()\n",
    "    negetive_log_rr = nll_rr.numpy()\n",
    "    avg_nll = np.mean(negetive_log)\n",
    "    avg_nll_rr = np.mean(negetive_log_rr)\n",
    "    print(\"Negetive Log Liklihood for Respiration Signal for {} is {}\".format(input_conf,negetive_log))\n",
    "    print(\"Average negetive Log Liklihood  for Respiration Signal for {} is {}\".format(input_conf,avg_nll))\n",
    "    print(\"Negetive Log Liklihood for Respiration Rate for {} is {}\".format(input_conf,negetive_log_rr))\n",
    "    print(\"Average negetive Log Liklihood  for Respiration Rate for {} is {}\".format(input_conf,avg_nll_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1683118 , 0.16106164, 0.2272147 , ..., 0.12728226, 0.05112832,\n",
       "        0.03411922],\n",
       "       [0.20649146, 0.03515371, 0.20822583, ..., 0.07047421, 0.11992398,\n",
       "        0.13658431],\n",
       "       [0.20557544, 0.20193163, 0.15814261, ..., 0.1281244 , 0.12970267,\n",
       "        0.13755938],\n",
       "       ...,\n",
       "       [0.03350988, 0.15199444, 0.1576383 , ..., 0.12987614, 0.09289921,\n",
       "        0.03471817],\n",
       "       [0.15371953, 0.24395168, 0.03846487, ..., 0.0748873 , 0.15755397,\n",
       "        0.03333334],\n",
       "       [0.2045297 , 0.14980611, 0.21057352, ..., 0.13065577, 0.1188025 ,\n",
       "        0.13658431]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
